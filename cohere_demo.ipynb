{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixes a bug with asyncio and jupyter\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.sitemap import SitemapLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ClientSession._request() got an unexpected keyword argument 'verify'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m sitemap_loader\u001b[39m.\u001b[39mrequests_kwargs \u001b[39m=\u001b[39m {}\n\u001b[1;32m      6\u001b[0m \u001b[39m# sitemap_loader.scrape_all()\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m docs \u001b[39m=\u001b[39m sitemap_loader\u001b[39m.\u001b[39;49mload()\n",
      "File \u001b[0;32m~/Projects/cohere_demo/venv/lib/python3.11/site-packages/langchain/document_loaders/sitemap.py:134\u001b[0m, in \u001b[0;36mSitemapLoader.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    132\u001b[0m         els \u001b[39m=\u001b[39m elblocks[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocknum]\n\u001b[0;32m--> 134\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscrape_all([el[\u001b[39m\"\u001b[39;49m\u001b[39mloc\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mstrip() \u001b[39mfor\u001b[39;49;00m el \u001b[39min\u001b[39;49;00m els \u001b[39mif\u001b[39;49;00m \u001b[39m\"\u001b[39;49m\u001b[39mloc\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39min\u001b[39;49;00m el])\n\u001b[1;32m    136\u001b[0m \u001b[39mreturn\u001b[39;00m [\n\u001b[1;32m    137\u001b[0m     Document(\n\u001b[1;32m    138\u001b[0m         page_content\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparsing_function(results[i]),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(results))\n\u001b[1;32m    142\u001b[0m ]\n",
      "File \u001b[0;32m~/Projects/cohere_demo/venv/lib/python3.11/site-packages/langchain/document_loaders/web_base.py:163\u001b[0m, in \u001b[0;36mWebBaseLoader.scrape_all\u001b[0;34m(self, urls, parser)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fetch all urls, then return soups for all results.\"\"\"\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mbs4\u001b[39;00m \u001b[39mimport\u001b[39;00m BeautifulSoup\n\u001b[0;32m--> 163\u001b[0m results \u001b[39m=\u001b[39m asyncio\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfetch_all(urls))\n\u001b[1;32m    164\u001b[0m final_results \u001b[39m=\u001b[39m []\n\u001b[1;32m    165\u001b[0m \u001b[39mfor\u001b[39;00m i, result \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(results):\n",
      "File \u001b[0;32m~/Projects/cohere_demo/venv/lib/python3.11/site-packages/nest_asyncio.py:35\u001b[0m, in \u001b[0;36m_patch_asyncio.<locals>.run\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m     33\u001b[0m task \u001b[39m=\u001b[39m asyncio\u001b[39m.\u001b[39mensure_future(main)\n\u001b[1;32m     34\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 35\u001b[0m     \u001b[39mreturn\u001b[39;00m loop\u001b[39m.\u001b[39;49mrun_until_complete(task)\n\u001b[1;32m     36\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     37\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m task\u001b[39m.\u001b[39mdone():\n",
      "File \u001b[0;32m~/Projects/cohere_demo/venv/lib/python3.11/site-packages/nest_asyncio.py:90\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m f\u001b[39m.\u001b[39mdone():\n\u001b[1;32m     88\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m     89\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mEvent loop stopped before Future completed.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 90\u001b[0m \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39;49mresult()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/futures.py:203\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__log_traceback \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 203\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\u001b[39m.\u001b[39mwith_traceback(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception_tb)\n\u001b[1;32m    204\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/tasks.py:267\u001b[0m, in \u001b[0;36mTask.__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    264\u001b[0m     \u001b[39mif\u001b[39;00m exc \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    265\u001b[0m         \u001b[39m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[1;32m    266\u001b[0m         \u001b[39m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m         result \u001b[39m=\u001b[39m coro\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    268\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    269\u001b[0m         result \u001b[39m=\u001b[39m coro\u001b[39m.\u001b[39mthrow(exc)\n",
      "File \u001b[0;32m~/Projects/cohere_demo/venv/lib/python3.11/site-packages/langchain/document_loaders/web_base.py:143\u001b[0m, in \u001b[0;36mWebBaseLoader.fetch_all\u001b[0;34m(self, urls)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    141\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39masyncio\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm_asyncio\n\u001b[0;32m--> 143\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mawait\u001b[39;00m tqdm_asyncio\u001b[39m.\u001b[39mgather(\n\u001b[1;32m    144\u001b[0m         \u001b[39m*\u001b[39mtasks, desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFetching pages\u001b[39m\u001b[39m\"\u001b[39m, ascii\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, mininterval\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m    145\u001b[0m     )\n\u001b[1;32m    146\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[1;32m    147\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mFor better logging of progress, `pip install tqdm`\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Projects/cohere_demo/venv/lib/python3.11/site-packages/tqdm/asyncio.py:79\u001b[0m, in \u001b[0;36mtqdm_asyncio.gather\u001b[0;34m(cls, loop, timeout, total, *fs, **tqdm_kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[39mreturn\u001b[39;00m i, \u001b[39mawait\u001b[39;00m f\n\u001b[1;32m     78\u001b[0m ifs \u001b[39m=\u001b[39m [wrap_awaitable(i, f) \u001b[39mfor\u001b[39;00m i, f \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(fs)]\n\u001b[0;32m---> 79\u001b[0m res \u001b[39m=\u001b[39m [\u001b[39mawait\u001b[39;00m f \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mas_completed(ifs, loop\u001b[39m=\u001b[39mloop, timeout\u001b[39m=\u001b[39mtimeout,\n\u001b[1;32m     80\u001b[0m                                          total\u001b[39m=\u001b[39mtotal, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtqdm_kwargs)]\n\u001b[1;32m     81\u001b[0m \u001b[39mreturn\u001b[39;00m [i \u001b[39mfor\u001b[39;00m _, i \u001b[39min\u001b[39;00m \u001b[39msorted\u001b[39m(res)]\n",
      "File \u001b[0;32m~/Projects/cohere_demo/venv/lib/python3.11/site-packages/tqdm/asyncio.py:79\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[39mreturn\u001b[39;00m i, \u001b[39mawait\u001b[39;00m f\n\u001b[1;32m     78\u001b[0m ifs \u001b[39m=\u001b[39m [wrap_awaitable(i, f) \u001b[39mfor\u001b[39;00m i, f \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(fs)]\n\u001b[0;32m---> 79\u001b[0m res \u001b[39m=\u001b[39m [\u001b[39mawait\u001b[39;00m f \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mas_completed(ifs, loop\u001b[39m=\u001b[39mloop, timeout\u001b[39m=\u001b[39mtimeout,\n\u001b[1;32m     80\u001b[0m                                          total\u001b[39m=\u001b[39mtotal, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtqdm_kwargs)]\n\u001b[1;32m     81\u001b[0m \u001b[39mreturn\u001b[39;00m [i \u001b[39mfor\u001b[39;00m _, i \u001b[39min\u001b[39;00m \u001b[39msorted\u001b[39m(res)]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/tasks.py:605\u001b[0m, in \u001b[0;36mas_completed.<locals>._wait_for_one\u001b[0;34m()\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    603\u001b[0m     \u001b[39m# Dummy value from _on_timeout().\u001b[39;00m\n\u001b[1;32m    604\u001b[0m     \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mTimeoutError\n\u001b[0;32m--> 605\u001b[0m \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39;49mresult()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/futures.py:203\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__log_traceback \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 203\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\u001b[39m.\u001b[39mwith_traceback(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception_tb)\n\u001b[1;32m    204\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/tasks.py:269\u001b[0m, in \u001b[0;36mTask.__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    267\u001b[0m         result \u001b[39m=\u001b[39m coro\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    268\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 269\u001b[0m         result \u001b[39m=\u001b[39m coro\u001b[39m.\u001b[39mthrow(exc)\n\u001b[1;32m    270\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m    271\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_must_cancel:\n\u001b[1;32m    272\u001b[0m         \u001b[39m# Task is cancelled right before coro stops.\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/cohere_demo/venv/lib/python3.11/site-packages/tqdm/asyncio.py:76\u001b[0m, in \u001b[0;36mtqdm_asyncio.gather.<locals>.wrap_awaitable\u001b[0;34m(i, f)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39mwrap_awaitable\u001b[39m(i, f):\n\u001b[0;32m---> 76\u001b[0m     \u001b[39mreturn\u001b[39;00m i, \u001b[39mawait\u001b[39;00m f\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/futures.py:287\u001b[0m, in \u001b[0;36mFuture.__await__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdone():\n\u001b[1;32m    286\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_asyncio_future_blocking \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 287\u001b[0m     \u001b[39myield\u001b[39;00m \u001b[39mself\u001b[39m  \u001b[39m# This tells Task to wait for completion.\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdone():\n\u001b[1;32m    289\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mawait wasn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt used with future\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/tasks.py:339\u001b[0m, in \u001b[0;36mTask.__wakeup\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__wakeup\u001b[39m(\u001b[39mself\u001b[39m, future):\n\u001b[1;32m    338\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 339\u001b[0m         future\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m    340\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m    341\u001b[0m         \u001b[39m# This may also be a cancellation.\u001b[39;00m\n\u001b[1;32m    342\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__step(exc)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/futures.py:203\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__log_traceback \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 203\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\u001b[39m.\u001b[39mwith_traceback(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception_tb)\n\u001b[1;32m    204\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/tasks.py:267\u001b[0m, in \u001b[0;36mTask.__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    264\u001b[0m     \u001b[39mif\u001b[39;00m exc \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    265\u001b[0m         \u001b[39m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[1;32m    266\u001b[0m         \u001b[39m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m         result \u001b[39m=\u001b[39m coro\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    268\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    269\u001b[0m         result \u001b[39m=\u001b[39m coro\u001b[39m.\u001b[39mthrow(exc)\n",
      "File \u001b[0;32m~/Projects/cohere_demo/venv/lib/python3.11/site-packages/langchain/document_loaders/web_base.py:131\u001b[0m, in \u001b[0;36mWebBaseLoader._fetch_with_rate_limit\u001b[0;34m(self, url, semaphore)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39m_fetch_with_rate_limit\u001b[39m(\n\u001b[1;32m    128\u001b[0m     \u001b[39mself\u001b[39m, url: \u001b[39mstr\u001b[39m, semaphore: asyncio\u001b[39m.\u001b[39mSemaphore\n\u001b[1;32m    129\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m    130\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mwith\u001b[39;00m semaphore:\n\u001b[0;32m--> 131\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mawait\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fetch(url)\n",
      "File \u001b[0;32m~/Projects/cohere_demo/venv/lib/python3.11/site-packages/langchain/document_loaders/web_base.py:112\u001b[0m, in \u001b[0;36mWebBaseLoader._fetch\u001b[0;34m(self, url, retries, cooldown, backoff)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(retries):\n\u001b[1;32m    111\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 112\u001b[0m         \u001b[39masync\u001b[39;00m \u001b[39mwith\u001b[39;00m session\u001b[39m.\u001b[39;49mget(\n\u001b[1;32m    113\u001b[0m             url, headers\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mheaders, verify\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverify\n\u001b[1;32m    114\u001b[0m         ) \u001b[39mas\u001b[39;00m response:\n\u001b[1;32m    115\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mawait\u001b[39;00m response\u001b[39m.\u001b[39mtext()\n\u001b[1;32m    116\u001b[0m     \u001b[39mexcept\u001b[39;00m aiohttp\u001b[39m.\u001b[39mClientConnectionError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Projects/cohere_demo/venv/lib/python3.11/site-packages/aiohttp/client.py:922\u001b[0m, in \u001b[0;36mClientSession.get\u001b[0;34m(self, url, allow_redirects, **kwargs)\u001b[0m\n\u001b[1;32m    917\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\n\u001b[1;32m    918\u001b[0m     \u001b[39mself\u001b[39m, url: StrOrURL, \u001b[39m*\u001b[39m, allow_redirects: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any\n\u001b[1;32m    919\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_RequestContextManager\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    920\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Perform HTTP GET request.\"\"\"\u001b[39;00m\n\u001b[1;32m    921\u001b[0m     \u001b[39mreturn\u001b[39;00m _RequestContextManager(\n\u001b[0;32m--> 922\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(hdrs\u001b[39m.\u001b[39;49mMETH_GET, url, allow_redirects\u001b[39m=\u001b[39;49mallow_redirects, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    923\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: ClientSession._request() got an unexpected keyword argument 'verify'"
     ]
    }
   ],
   "source": [
    "sitemap_loader = SitemapLoader(web_path=\"https://langchain.readthedocs.io/sitemap.xml\" )\n",
    "\n",
    "# sitemap_loader.requests_per_second = 2\n",
    "# Optional: avoid `[SSL: CERTIFICATE_VERIFY_FAILED]` issue\n",
    "sitemap_loader.requests_kwargs = {}\n",
    "# sitemap_loader.scrape_all()\n",
    "\n",
    "docs = sitemap_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-16' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /Users/Misbah/Projects/cohere_demo/venv/lib/python3.11/site-packages/tqdm/asyncio.py:75> exception=TypeError(\"ClientSession._request() got an unexpected keyword argument 'verify'\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/tasks.py\", line 269, in __step\n",
      "    result = coro.throw(exc)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Misbah/Projects/cohere_demo/venv/lib/python3.11/site-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Misbah/Projects/cohere_demo/venv/lib/python3.11/site-packages/langchain/document_loaders/web_base.py\", line 131, in _fetch_with_rate_limit\n",
      "    return await self._fetch(url)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Misbah/Projects/cohere_demo/venv/lib/python3.11/site-packages/langchain/document_loaders/web_base.py\", line 112, in _fetch\n",
      "    async with session.get(\n",
      "               ^^^^^^^^^^^^\n",
      "  File \"/Users/Misbah/Projects/cohere_demo/venv/lib/python3.11/site-packages/aiohttp/client.py\", line 922, in get\n",
      "    self._request(hdrs.METH_GET, url, allow_redirects=allow_redirects, **kwargs)\n",
      "TypeError: ClientSession._request() got an unexpected keyword argument 'verify'\n",
      "Fetching pages:   0%|          | 0/3 [12:19<?, ?it/s]\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-17' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /Users/Misbah/Projects/cohere_demo/venv/lib/python3.11/site-packages/tqdm/asyncio.py:75> exception=TypeError(\"ClientSession._request() got an unexpected keyword argument 'verify'\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/tasks.py\", line 269, in __step\n",
      "    result = coro.throw(exc)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Misbah/Projects/cohere_demo/venv/lib/python3.11/site-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Misbah/Projects/cohere_demo/venv/lib/python3.11/site-packages/langchain/document_loaders/web_base.py\", line 131, in _fetch_with_rate_limit\n",
      "    return await self._fetch(url)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Misbah/Projects/cohere_demo/venv/lib/python3.11/site-packages/langchain/document_loaders/web_base.py\", line 112, in _fetch\n",
      "    async with session.get(\n",
      "               ^^^^^^^^^^^^\n",
      "  File \"/Users/Misbah/Projects/cohere_demo/venv/lib/python3.11/site-packages/aiohttp/client.py\", line 922, in get\n",
      "    self._request(hdrs.METH_GET, url, allow_redirects=allow_redirects, **kwargs)\n",
      "TypeError: ClientSession._request() got an unexpected keyword argument 'verify'\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-24' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /Users/Misbah/Projects/cohere_demo/venv/lib/python3.11/site-packages/tqdm/asyncio.py:75> exception=TypeError(\"ClientSession._request() got an unexpected keyword argument 'verify'\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/tasks.py\", line 269, in __step\n",
      "    result = coro.throw(exc)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Misbah/Projects/cohere_demo/venv/lib/python3.11/site-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Misbah/Projects/cohere_demo/venv/lib/python3.11/site-packages/langchain/document_loaders/web_base.py\", line 131, in _fetch_with_rate_limit\n",
      "    return await self._fetch(url)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Misbah/Projects/cohere_demo/venv/lib/python3.11/site-packages/langchain/document_loaders/web_base.py\", line 112, in _fetch\n",
      "    async with session.get(\n",
      "               ^^^^^^^^^^^^\n",
      "  File \"/Users/Misbah/Projects/cohere_demo/venv/lib/python3.11/site-packages/aiohttp/client.py\", line 922, in get\n",
      "    self._request(hdrs.METH_GET, url, allow_redirects=allow_redirects, **kwargs)\n",
      "TypeError: ClientSession._request() got an unexpected keyword argument 'verify'\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-25' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /Users/Misbah/Projects/cohere_demo/venv/lib/python3.11/site-packages/tqdm/asyncio.py:75> exception=TypeError(\"ClientSession._request() got an unexpected keyword argument 'verify'\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/tasks.py\", line 269, in __step\n",
      "    result = coro.throw(exc)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Misbah/Projects/cohere_demo/venv/lib/python3.11/site-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Misbah/Projects/cohere_demo/venv/lib/python3.11/site-packages/langchain/document_loaders/web_base.py\", line 131, in _fetch_with_rate_limit\n",
      "    return await self._fetch(url)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Misbah/Projects/cohere_demo/venv/lib/python3.11/site-packages/langchain/document_loaders/web_base.py\", line 112, in _fetch\n",
      "    async with session.get(\n",
      "               ^^^^^^^^^^^^\n",
      "  File \"/Users/Misbah/Projects/cohere_demo/venv/lib/python3.11/site-packages/aiohttp/client.py\", line 922, in get\n",
      "    self._request(hdrs.METH_GET, url, allow_redirects=allow_redirects, **kwargs)\n",
      "TypeError: ClientSession._request() got an unexpected keyword argument 'verify'\n",
      "Fetching pages:   0%|          | 0/3 [09:28<?, ?it/s]\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-32' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /Users/Misbah/Projects/cohere_demo/venv/lib/python3.11/site-packages/tqdm/asyncio.py:75> exception=TypeError(\"ClientSession._request() got an unexpected keyword argument 'verify'\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/tasks.py\", line 269, in __step\n",
      "    result = coro.throw(exc)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Misbah/Projects/cohere_demo/venv/lib/python3.11/site-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Misbah/Projects/cohere_demo/venv/lib/python3.11/site-packages/langchain/document_loaders/web_base.py\", line 131, in _fetch_with_rate_limit\n",
      "    return await self._fetch(url)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Misbah/Projects/cohere_demo/venv/lib/python3.11/site-packages/langchain/document_loaders/web_base.py\", line 112, in _fetch\n",
      "    async with session.get(\n",
      "               ^^^^^^^^^^^^\n",
      "  File \"/Users/Misbah/Projects/cohere_demo/venv/lib/python3.11/site-packages/aiohttp/client.py\", line 922, in get\n",
      "    self._request(hdrs.METH_GET, url, allow_redirects=allow_redirects, **kwargs)\n",
      "TypeError: ClientSession._request() got an unexpected keyword argument 'verify'\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-30' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /Users/Misbah/Projects/cohere_demo/venv/lib/python3.11/site-packages/tqdm/asyncio.py:75> exception=TypeError(\"ClientSession._request() got an unexpected keyword argument 'verify'\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/tasks.py\", line 269, in __step\n",
      "    result = coro.throw(exc)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Misbah/Projects/cohere_demo/venv/lib/python3.11/site-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Misbah/Projects/cohere_demo/venv/lib/python3.11/site-packages/langchain/document_loaders/web_base.py\", line 131, in _fetch_with_rate_limit\n",
      "    return await self._fetch(url)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Misbah/Projects/cohere_demo/venv/lib/python3.11/site-packages/langchain/document_loaders/web_base.py\", line 112, in _fetch\n",
      "    async with session.get(\n",
      "               ^^^^^^^^^^^^\n",
      "  File \"/Users/Misbah/Projects/cohere_demo/venv/lib/python3.11/site-packages/aiohttp/client.py\", line 922, in get\n",
      "    self._request(hdrs.METH_GET, url, allow_redirects=allow_redirects, **kwargs)\n",
      "TypeError: ClientSession._request() got an unexpected keyword argument 'verify'\n",
      "Fetching pages:   0%|          | 0/3 [08:00<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"The Cohere Platform\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to ContentGuides and ConceptsAPI ReferenceRelease NotesLLMUDashboardDocumentationPlaygroundCommunityLog InDashboardDocumentationPlaygroundCommunityLog InGuides and ConceptsAPI ReferenceRelease NotesLLMUSearchGet StartedThe Cohere PlatformIntroduction to Large Language ModelsPlayground OverviewQuickstart TutorialsGoing LiveIntegrationsLearnKey ConceptsEmbeddingsPrompt EngineeringTokensGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-pCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model MetricsMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported LanguagesRerankingReranking Best PracticesGenerating FeedbackIntroductory GuidesSemantic SearchContent ModerationEntity ExtractionText ClassificationText Classification (Classify)Text Classification (Embed)Co.summarize (Beta)Co.rerank (Beta)Responsible UseOverviewUsage GuidelinesModel LimitationsData StatementModelsSecurityEnvironmental ImpactLLM UniversityWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?Module 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language ModelsModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text RepresentationModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere's Command ModelConclusion - Text GenerationAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLPAppendix 2: Building AppsApp ExamplesThe Cohere PlatformSuggest EditsCohere offers an API to add cutting-edge language processing to any system. Cohere trains massive language models and puts them behind a simple API. Moreover, through training, users can create massive models customized to their use case and trained on their data. This way, Cohere handles the complexities of collecting massive amounts of text data, the ever evolving neural network architectures, distributed training, and serving models around the clock.\\nCohere offers access to both generation models (through the generate endpoint) and\\nrepresentation models (through the embed endpoint which returns an embedding vector for the input text).\\nTwo major categories of large language models are generative language models (like GPT2 and GPT3) and representation language models (like BERT). Cohere offers variants of both types.\\nUse Cases\\nHere are a few examples of language understanding systems that can be built on top of large language models.\\nSummarize\\nLarge language models present a breakthrough in text generation. For the first time in history, we have software programs that can write text that sounds like it’s written by humans. These capabilities open doors to use cases like summarization or paraphrasing.\\nLanguage models can be instructed to generate useful summaries or paraphrases of input text by guiding them using a task description in the prompt.\\nA summarization prompt in the Cohere playground shows this output (in bold):\\n  Example summarization prompt and generation. Stop sequence is specified as the period to limit the output to one sentence.\\nLarge language models can be adapted to new tasks with impressive speed. For tasks which appear in the training data (i.e. documents on the web), language models can successfully summarize text without being shown any examples at all.\\nTwo strategies you can experiment with generative language models are prompt engineering and training (which creates a custom model based on your dataset).\\nSummarization uses the Co.summarize endpoint.\\n📘New to Cohere?Get Started now and get unprecedented access to world-class Generation and Representation models with billions of parameters.\\nClassify\\nClassification is one of the most common use cases in language processing. Building systems on top of language models can automate language-based tasks and save time and energy.\\nDevelopers can build classifiers on top of Cohere’s language models. These classifiers can automate language tasks and workflows.\\nThere's more than one way to build a classifier on top of Cohere's language models. It's worth experimenting to see which method works best for your use case. The simpler methods can get you quick results, while the more advanced methods need more data and will lead to better results.\\nOn the simpler side are methods like using the Classify endpoint for classification. More industrial-grade classifiers can be built by fitting a classifier on top of the embed endpoint (see: Embedding endpoint for classification).\\nSemantic Similarity\\nThink of how many repeated questions have to be answered by a customer service agent every day. Language models are capable of judging text similarity and determining if an incoming question is similar to questions already answered in the FAQ section.\\nA similarity score can be computed through our embeddings by calculating the\\ncosine similarity of two embeddings.\\nThere are multiple things your system can do once it receives the similarity scores — one possible next action is to simply show the answer to the most similar question (if above a certain similarity threshold). Another possible next action is to make that suggestion to a customer service agent.Updated 14 days ago Table of Contents\\n\\nUse Cases\\n\\nSummarize\\nClassify\\nSemantic Similarity\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\", metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/the-cohere-platform', 'title': 'The Cohere Platform', 'description': 'Use the API to generate completions, distill text into semantically meaningful vectors, and more. Get state-of-the-art natural language processing without the need for expensive supercomputing infrastructure.', 'language': 'en'}),\n",
       " Document(page_content=\"Introduction to Large Language Models\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to ContentGuides and ConceptsAPI ReferenceRelease NotesLLMUDashboardDocumentationPlaygroundCommunityLog InDashboardDocumentationPlaygroundCommunityLog InGuides and ConceptsAPI ReferenceRelease NotesLLMUSearchGet StartedThe Cohere PlatformIntroduction to Large Language ModelsPlayground OverviewQuickstart TutorialsGoing LiveIntegrationsLearnKey ConceptsEmbeddingsPrompt EngineeringTokensGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-pCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model MetricsMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported LanguagesRerankingReranking Best PracticesGenerating FeedbackIntroductory GuidesSemantic SearchContent ModerationEntity ExtractionText ClassificationText Classification (Classify)Text Classification (Embed)Co.summarize (Beta)Co.rerank (Beta)Responsible UseOverviewUsage GuidelinesModel LimitationsData StatementModelsSecurityEnvironmental ImpactLLM UniversityWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?Module 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language ModelsModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text RepresentationModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere's Command ModelConclusion - Text GenerationAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLPAppendix 2: Building AppsApp ExamplesIntroduction to Large Language ModelsSuggest EditsLanguage is important. It’s how we learn about the world (e.g. news, searching the web or Wikipedia), and also how we shape it (e.g. agreements, laws, or messages). Language is also how we connect and communicate — as people, and as groups and companies.\\nDespite the rapid evolution of software, computers remain limited in their ability to deal with language. Software is great at searching for exact matches in text, but often fails at more advanced uses of language — ones that humans employ on a daily basis.\\nThere’s a clear need for more intelligent tools that better understand language.\\nLarge Language Models\\nA recent breakthrough in artificial intelligence (AI) is the introduction of language processing technologies that enable us to build more intelligent systems with a richer understanding of language than ever before. Large pre-trained Transformer language models, or simply large language models, vastly extend the capabilities of what systems are able to do with text.\\nLarge language models are computer programs that open new possibilities of text understanding and generation in software systems.\\nConsider this: adding language models to empower Google Search was noted as “representing the biggest leap forward in the past five years, and one of the biggest leaps forward in the history of Search“. Microsoft also uses such models for every query in the Bing search engine.\\nDespite the utility of these models, training and deploying them effectively is resource intensive in its requirements of data, compute, and engineering resources.Updated 23 days ago Table of Contents\\nLarge Language Models\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\", metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/introduction-to-large-language-models', 'title': 'Introduction to Large Language Models', 'description': 'Use the API to generate completions, distill text into semantically meaningful vectors, and more. Get state-of-the-art natural language processing without the need for expensive supercomputing infrastructure.', 'language': 'en'}),\n",
       " Document(page_content='Playground Overview\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to ContentGuides and ConceptsAPI ReferenceRelease NotesLLMUDashboardDocumentationPlaygroundCommunityLog InDashboardDocumentationPlaygroundCommunityLog InGuides and ConceptsAPI ReferenceRelease NotesLLMUSearchGet StartedThe Cohere PlatformIntroduction to Large Language ModelsPlayground OverviewQuickstart TutorialsGoing LiveIntegrationsLearnKey ConceptsEmbeddingsPrompt EngineeringTokensGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-pCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model MetricsMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported LanguagesRerankingReranking Best PracticesGenerating FeedbackIntroductory GuidesSemantic SearchContent ModerationEntity ExtractionText ClassificationText Classification (Classify)Text Classification (Embed)Co.summarize (Beta)Co.rerank (Beta)Responsible UseOverviewUsage GuidelinesModel LimitationsData StatementModelsSecurityEnvironmental ImpactLLM UniversityWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?Module 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language ModelsModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text RepresentationModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere\\'s Command ModelConclusion - Text GenerationAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLPAppendix 2: Building AppsApp ExamplesPlayground OverviewSuggest EditsWhat is the Playground?\\nThe Cohere Playground is a visual interface for users to test Cohere\\'s large language models without writing a single line of code. To familiarize yourself with our endpoints, we recommend clicking the Generate or Calculate button on each endpoint page and observing the outputs. Use the Playground to test your use cases and when you\\'re ready to start building, simply click Export Code to add Cohere\\'s functionality to your application.\\nUsing the Playground\\nGenerate\\nGenerate produces natural language text in response to an input prompt. As seen in the screenshot below, we supplied the model with a prompt, \"Given a product and keywords, this program will generate exciting product descriptions. Here are some examples:\" and gave two examples of a product and keywords. The bolded text was generated by the model.\\n\\n\\nTo write inputs that produce the best results for your use case, read our Prompt Engineering guide.\\nTry tinkering with different temperature and token-picking settings to alter the model\\'s output behaviour.\\nTo further improve your generations or to get the model to focus on generating text about a specific topic, try uploading a sample text to train the model. If you\\'re interested in training a model, please submit a Full Access request from your Cohere Dashboard.\\n\\nTry asking the model to do any of the following:\\n\\nSummarize a paragraph of text\\nGenerate SEO tags for a blog post\\nProduce some questions for your next trivia night\\nProvide ideas of what to do in your city this weekend\\n\\nIn each case, give the model a few examples your desired output.\\nAdditionally, note the Show Likelihood button withinAdvanced Parameters. This feature outputs the likelihood that each token would be generated by the model in the given sequence, as well as the average log-likelihood of each token in the input. Token likelihoods can be retrieved from our Generate endpoint.\\nThe log-likelihood is useful for evaluating model performance, especially when testing user-trained models. If you\\'re interested in training a model, please submit a Full Access request from your Cohere Dashboard.\\nEmbed\\nUsing Embed in the Playground enables users to assign numerical representations to strings and visualize comparative meaning on a 2-dimensional plane. Phrases similar in meaning should ideally be closer together on this visualization. Add a couple of your own phrases and see if the Playground visualization feels accurate to you.\\n\\nCohere’s embeddings can be used to train a semantic classifier out of the box, saving users countless hours gathering data to train a model themselves.\\nClassify\\nCohere’s Classify endpoint enables users to create a classifier from a few labeled examples.\\n\\nSelecting the Right Model Size\\nLarger models are more capable of complex tasks but smaller models have faster response times and are less expensive. Here is a rough guideline for which model size to use for various tasks:\\nGeneration models\\ncommand\\nCommand is the most capable generative model and can perform any task other models can with better results. This model is well suited for challenging tasks including complex extraction, rewriting, question-answering, summarization, conversation, and brainstorming.\\ncommand-light\\nCommand Light provides a great tradeoff between power and speed. Use this model to power tasks like generating marketing ad-copy, extracting key entities from text, or powering conversational agents.\\nRepresentation models\\nembed-english-v2.0\\nEmbed is our most capable representation model and can perform any tasks other models can with better results. The large model performs better at few shot classification tasks in both single label and multi-label scenarios. Large embeddings have 4096 dimensions.\\nembed-english-light-v2.0\\nEmbed Light is our fastest model, and has the lightest storage requirements. Small embeddings have 1024 dimensions.\\nembed-multilingual-v2.0\\nWe currently have a single multilingual representation model available on out platform. The embeddings have 768 dimensions.Updated 23 days ago Table of Contents\\n\\nWhat is the Playground?\\n\\n\\nUsing the Playground\\n\\nGenerate\\nEmbed\\nClassify\\n\\n\\n\\nSelecting the Right Model Size\\n\\nGeneration models\\nRepresentation models\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n', metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/playground-overview', 'title': 'Playground Overview', 'description': 'Use the API to generate completions, distill text into semantically meaningful vectors, and more. Get state-of-the-art natural language processing without the need for expensive supercomputing infrastructure.', 'language': 'en'}),\n",
       " Document(page_content=\"Quickstart Tutorials\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to ContentGuides and ConceptsAPI ReferenceRelease NotesLLMUDashboardDocumentationPlaygroundCommunityLog InDashboardDocumentationPlaygroundCommunityLog InGuides and ConceptsAPI ReferenceRelease NotesLLMUSearchGet StartedThe Cohere PlatformIntroduction to Large Language ModelsPlayground OverviewQuickstart TutorialsGoing LiveIntegrationsLearnKey ConceptsEmbeddingsPrompt EngineeringTokensGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-pCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model MetricsMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported LanguagesRerankingReranking Best PracticesGenerating FeedbackIntroductory GuidesSemantic SearchContent ModerationEntity ExtractionText ClassificationText Classification (Classify)Text Classification (Embed)Co.summarize (Beta)Co.rerank (Beta)Responsible UseOverviewUsage GuidelinesModel LimitationsData StatementModelsSecurityEnvironmental ImpactLLM UniversityWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?Module 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language ModelsModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text RepresentationModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere's Command ModelConclusion - Text GenerationAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLPAppendix 2: Building AppsApp ExamplesQuickstart TutorialsSuggest EditsCohere's API is created to help you build natural language understanding and generation into your production with a few lines of code. Our Quickstart Tutorials will show you how to implement our API from zero-to-one in under 5 minutes. \\n\\n1. Customer SupportCustomer support tickets can come from all directions, and manually analyzing and routing information is an overwhelming job. A text classification system can help support teams accelerate this process.  Here is an example of classifying customer emails to an insurance company into four categories: Finding policy details, Change account settings, Filing a claim and viewing status, and Cancelling coverage.\\n\\n\\n\\n\\n2. Intent Recognition\\nChatbots are designed to understand and respond to human language. They need to be able to understand the text they hear and understand the context of the conversation. They also need to be able to respond to people’s questions and comments in a meaningful way. To accomplish this, chatbots must be able to recognize specific intents that people express in conversation.Here is an example of classifying the intent of customer inquiries on an eCommerce website into three categories: Shipping and handling policy, Start return or exchange, or Track order.\\n\\n\\n\\n\\n3. Sentiment AnalysisSentiment analysis is a type of classification task that analyzes the tone of a piece of text. It is used in a variety of different ways, or example, on social media comments and customer reviews. It is commonly used to see how people feel about their products or company, but it can also be used to help businesses understand how different trends in the economy may impact their business.Here is an example of classifying the sentiments of customer feedback about a product into three categories: Positive, Negative, or Neutral.\\n\\n\\n\\n4. Text SummarizationThe goal of text summarization is to condense the original text into a shorter version that retains the most important information. In this example, we want to summarize a passage from a news article into its main point.\\n\\n\\n\\n5. Toxicity DetectionThe internet is dominated by user-generated content. While it provides an avenue for online platforms to grow, it is a bane for content moderators managing them. It is impossible for humans to manually moderate all the user content that is created. This is why an automated solution is needed, such as in flagging for toxic content.Here is an example of classifying online user comments for toxicity into two categories: Toxic or Not Toxic.\\nUpdated 23 days ago \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\", metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/quick-start-guides', 'title': 'Quickstart Tutorials', 'description': 'Use the API to generate completions, distill text into semantically meaningful vectors, and more. Get state-of-the-art natural language processing without the need for expensive supercomputing infrastructure.', 'language': 'en'}),\n",
       " Document(page_content='Going Live\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to ContentGuides and ConceptsAPI ReferenceRelease NotesLLMUDashboardDocumentationPlaygroundCommunityLog InDashboardDocumentationPlaygroundCommunityLog InGuides and ConceptsAPI ReferenceRelease NotesLLMUSearchGet StartedThe Cohere PlatformIntroduction to Large Language ModelsPlayground OverviewQuickstart TutorialsGoing LiveIntegrationsLearnKey ConceptsEmbeddingsPrompt EngineeringTokensGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-pCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model MetricsMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported LanguagesRerankingReranking Best PracticesGenerating FeedbackIntroductory GuidesSemantic SearchContent ModerationEntity ExtractionText ClassificationText Classification (Classify)Text Classification (Embed)Co.summarize (Beta)Co.rerank (Beta)Responsible UseOverviewUsage GuidelinesModel LimitationsData StatementModelsSecurityEnvironmental ImpactLLM UniversityWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?Module 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language ModelsModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text RepresentationModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere\\'s Command ModelConclusion - Text GenerationAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLPAppendix 2: Building AppsApp ExamplesGoing LiveSuggest EditsGoing Live\\nUpon registration, every Cohere user receives a free, rate-limited Trial key to use with our endpoints. If you find that you are running against the Trial key rate limit or want to serve Cohere in production, this page details the process of upgrading to a Production key and going live.\\nTrial Key Limitations\\nTrial keys are rate-limited depending on the endpoint you want to use:\\nEndpointCalls per MinuteCo.Generate, Co.Summarize5All other endpoints100\\nIf you’d like to use Cohere’s endpoints in a production application or require higher throughput from our endpoints for your usage, you can upgrade to a Production key.\\nWith a Trial Key:\\nOrganizations can still have unlimited trial keys in the free tier.\\nThere is a defined usage limit on all the development API keys per minute (all keys add up to that rate limit).\\nWhen a developer/org reaches a rate limit, they will receive an error that they have exceeded the limit/minute.\\nPlayground usage counts toward your Trial key rate limit.\\nIf calls exceed the throttling we throw an error that says “Trial keys are throttled.\" Please upgrade your API key or contact us directly on Discord.\\nTrial keys are free to use even after you upgrade to a Production key.\\nProduction Key Specifications\\nProduction keys for all endpoints are rate-limited at 10,000 calls per minute and are intended for serving Cohere in a public-facing application and testing purposes. Usage of Production keys is metered at price points which can be found on our pricing page.\\nTo get a Production key, you will need to complete a few steps in our Go to Production workflow. You can start the process by navigating to the Billing and Usage page in your Cohere dashboard as the Admin of your organization (or asking your organization Admin to complete these steps). From there, click on the Get your Production key button to start the process.\\n\\nThe process takes less than 3 minutes to finish, and enables you to generate a Production key that you can use to serve Cohere APIs in production. If you deploy without completing the Go to Production workflow, your API key may be temporarily or permanently revoked.\\nGo to Production\\nYou must acknowledge Cohere’s SaaS Agreement and Terms of Service. Your organization must also read and recognize our Model Limitations, Model Cards, and Data Statement.\\nYou will be asked if your usage of Cohere API involves any of the sensitive use cases outlined in our Usage Guidelines. Following your acknowledgement of our terms, you will be able to generate and use a Production key immediately. However, if you indicate your usage involves a sensitive use case, your Production key may be rate limited the same as a Trial key until our Safety team reaches out and manually approves your use case. Reviews on sensitive use cases will take no longer than 48 hours.\\nTrack Incidents\\nNavigate to our status page which features information including a summary status indicator, component statuses, unresolved incidents, status history, and any upcoming or in-progress scheduled maintenance. We recommend subscribing for updates with an email or phone number to receive notifications whenever Cohere creates, updates or resolves an incident.Updated 23 days ago Table of Contents\\nGoing Live\\nTrial Key Limitations\\nProduction Key Specifications\\nGo to Production\\nTrack Incidents\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n', metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/going-live', 'title': 'Going Live', 'description': 'Use the API to generate completions, distill text into semantically meaningful vectors, and more. Get state-of-the-art natural language processing without the need for expensive supercomputing infrastructure.', 'language': 'en'}),\n",
       " Document(page_content=\"Integrations\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to ContentGuides and ConceptsAPI ReferenceRelease NotesLLMUDashboardDocumentationPlaygroundCommunityLog InDashboardDocumentationPlaygroundCommunityLog InGuides and ConceptsAPI ReferenceRelease NotesLLMUSearchGet StartedThe Cohere PlatformIntroduction to Large Language ModelsPlayground OverviewQuickstart TutorialsGoing LiveIntegrationsLearnKey ConceptsEmbeddingsPrompt EngineeringTokensGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-pCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model MetricsMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported LanguagesRerankingReranking Best PracticesGenerating FeedbackIntroductory GuidesSemantic SearchContent ModerationEntity ExtractionText ClassificationText Classification (Classify)Text Classification (Embed)Co.summarize (Beta)Co.rerank (Beta)Responsible UseOverviewUsage GuidelinesModel LimitationsData StatementModelsSecurityEnvironmental ImpactLLM UniversityWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?Module 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language ModelsModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text RepresentationModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere's Command ModelConclusion - Text GenerationAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLPAppendix 2: Building AppsApp ExamplesIntegrationsUse Cohere's models with the tools you love.Suggest Edits\\nQdrant is an open-source vector similarity search engine and vector database. It provides a production-ready service with a convenient API to store, search, and manage points - vectors with an additional payload. Qdrant is tailored to extended filtering support. It makes it useful for all sorts of neural-network or semantic-based matching, faceted search, and other applications.\\nQdrant is written in Rust, which makes it fast and reliable even under high load.\\nLearn More\\n\\n\\nWeaviate is an open source vector search engine that stores both objects and vectors, allowing for combining vector search with structured filtering.\\nThe text2vec-cohere module allows you to use Cohere embeddings directly in the Weaviate vector search engine as a vectorization module.\\nLearn More\\n\\n\\nThe Pinecone vector database makes it easy to build high-performance vector search applications. Use Cohere to generate language embeddings, then store them in Pinecone and use them for Semantic Search.\\nLearn More\\n\\n\\nCohere offers optimized containers that enable low latency inference on a diverse set of hardware accelerators available on AWS, providing different cost and performance points for Sagemaker customers.\\nLearn More\\n\\n\\nIntegrate the Surge AI labeling platform into your Cohere workflow.\\nLearn More\\n\\n\\nUse Scale's labelled datasets with Cohere's Large Language Models.\\nLearn More\\n\\n\\nMilvus is a highly flexible, reliable, and blazing-fast cloud-native, open-source vector database. It powers embedding similarity search and AI applications and strives to make vector databases accessible to every organization. Milvus is a graduated-stage project of the LF AI & Data Foundation.\\nLearn More\\n\\n\\nZilliz Cloud is a cloud-native vector database that stores, indexes, and searches for billions of embedding vectors to power enterprise-grade similarity search, recommender systems, anomaly detection, and more. Zilliz Cloud provides a fully-managed Milvus service, made by the creators of Milvus that allows for easy integration with vectorizers from Cohere and other popular models. Purpose-built to solve the challenge of managing billions of embeddings, Zilliz Cloud makes it easy to build applications for scale.\\nLearn MoreUpdated 22 days ago \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\", metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/integrations', 'title': 'Integrations', 'description': \"Use Cohere's models with the tools you love.\", 'language': 'en'}),\n",
       " Document(page_content='Embeddings\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to ContentGuides and ConceptsAPI ReferenceRelease NotesLLMUDashboardDocumentationPlaygroundCommunityLog InDashboardDocumentationPlaygroundCommunityLog InGuides and ConceptsAPI ReferenceRelease NotesLLMUSearchGet StartedThe Cohere PlatformIntroduction to Large Language ModelsPlayground OverviewQuickstart TutorialsGoing LiveIntegrationsLearnKey ConceptsEmbeddingsPrompt EngineeringTokensGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-pCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model MetricsMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported LanguagesRerankingReranking Best PracticesGenerating FeedbackIntroductory GuidesSemantic SearchContent ModerationEntity ExtractionText ClassificationText Classification (Classify)Text Classification (Embed)Co.summarize (Beta)Co.rerank (Beta)Responsible UseOverviewUsage GuidelinesModel LimitationsData StatementModelsSecurityEnvironmental ImpactLLM UniversityWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?Module 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language ModelsModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text RepresentationModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere\\'s Command ModelConclusion - Text GenerationAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLPAppendix 2: Building AppsApp ExamplesEmbeddingsSuggest EditsEmbeddings are a way to represent the meaning of text as a list of numbers. This is useful because once text is in this form, it can be compared to other text for similarity. Using a simple comparison function, we can calculate a similarity score for two embeddings to figure out whether two texts are talking about similar things.\\nIn the example below, the embeddings for two similar phrases have a high similarity score, and the embeddings for two unrelated phrases have a low similarity score:\\nPythonimport cohere\\nimport numpy as np\\n\\nco = cohere.Client(\"YOUR_API_KEY\")\\n\\n# get the embeddings\\nphrases = [\"i love soup\", \"soup is my favorite\", \"london is far away\"]\\n(soup1, soup2, london) = co.embed(phrases).embeddings\\n\\n# compare them\\ndef calculate_similarity(a, b):\\n  return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\\n\\ncalculate_similarity(soup1, soup2) # 0.9 - very similar!\\ncalculate_similarity(soup1, london) # 0.3 - not similar!\\n\\nTurning text into embeddings.\\nApplications\\n\\nBuild a Frequently Asked Questions bot that compares the customer question for similarity to an existing collection of frequently asked questions.\\nEfficiently cluster large amounts of text, using k-means clustering, for example. The embeddings can also be visualized using projection techniques such as PCA, UMAP, or t-SNE. This can be helpful when trying to visualize large amounts of unstructured text.\\nPerform semantic search over text in a database\\nPair with a downstream classifier like a random forest or an SVM to perform binary or multi-class classification or tasks such as sentiment classification or toxicity detection.\\n\\nHow Embeddings are Obtained\\nFor short texts (shorter than 512 tokens), we return embeddings obtained by averaging the contextualized embeddings of each token in the text, following Reimers and Gurevych. The final embedding thus captures semantic information about the entirety of the text. For texts longer than 512 tokens, we will truncate your inputs to the maximum context length.Updated 22 days ago Table of Contents\\nApplications\\nHow Embeddings are Obtained\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n', metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/embeddings', 'title': 'Embeddings', 'description': 'Use the API to generate completions, distill text into semantically meaningful vectors, and more. Get state-of-the-art natural language processing without the need for expensive supercomputing infrastructure.', 'language': 'en'}),\n",
       " Document(page_content='Prompt Engineering\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to ContentGuides and ConceptsAPI ReferenceRelease NotesLLMUDashboardDocumentationPlaygroundCommunityLog InDashboardDocumentationPlaygroundCommunityLog InGuides and ConceptsAPI ReferenceRelease NotesLLMUSearchGet StartedThe Cohere PlatformIntroduction to Large Language ModelsPlayground OverviewQuickstart TutorialsGoing LiveIntegrationsLearnKey ConceptsEmbeddingsPrompt EngineeringTokensGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-pCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model MetricsMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported LanguagesRerankingReranking Best PracticesGenerating FeedbackIntroductory GuidesSemantic SearchContent ModerationEntity ExtractionText ClassificationText Classification (Classify)Text Classification (Embed)Co.summarize (Beta)Co.rerank (Beta)Responsible UseOverviewUsage GuidelinesModel LimitationsData StatementModelsSecurityEnvironmental ImpactLLM UniversityWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?Module 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language ModelsModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text RepresentationModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere\\'s Command ModelConclusion - Text GenerationAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLPAppendix 2: Building AppsApp ExamplesPrompt EngineeringSuggest EditsHere, we discuss a few principles and techniques for writing prompts (inputs for our models) that will help you get the best generations for your task. Choosing the right temperature can also have a big influence on generation quality. We discuss temperature separately here.\\n\\nMain Principles\\nWe find that there are two main ideas to keep in mind while designing prompts for our models.\\n1. A prompt guides the model to generate useful output\\nIf you need a summary of an article, for example, a large language model trained on enough data can generate a summary if you guide it as such:\\nThis prompt has two components: the text you want summarized, and the task description.\\n2. Try multiple formulations of your prompt to get the best generations\\nWhen using generate, it is useful to try a range of different prompts for the problem you are trying to solve. Different formulations of the same prompt which might sound similar to humans can lead to generations that are quite different from each other. This might happen, for instance, because our models have learned that the different formulations are actually used in very different contexts and for different purposes. Below we give a number of examples that we\\'ve found to work particularly well for different tasks.\\nIn the summarization example, if “In summary,” doesn’t lead to a good generation, we may want to try “To summarize in plain language,“ or “The main point to take from this article is that”.\\nAdditionally, you can also use the likelihood feature in the playground to see if there are particular words, phrases, or structures that the model has trouble understanding. However, keep in mind that the average likelihood of tokens will always be high at the beginning of the sequence. The model might assign low likelihood to the first time you introduce a novel concept or name, but once it has seen it once it can readily use it in the generation. You can also use the likelihood capability to see if there is any spelling or punctuation that is creating issues for tokenization.\\n3. Describe the task and the general setting\\nIt\\'s often useful to include additional components of the task description, naturally these tend to come after the input text we\\'re trying to process.\\nProvide the model with enough context. For example, we can describe the summarization task in more detail before the article.\\nExample: shaping the task we need the model to do in natural language can use text both before and after the input text we aim to process.\\nLet\\'s consider a few more aspects of this by looking at a different example. Suppose that you would like to use our models to assist your customer satisfaction department by automatically generating plausible responses to customer requests (note: the generations are not to be sent to the customers, this is only a simulation).\\nA customer contacts your company with the following question:\\nHi, I\\'d like a refund for the coffee maker I ordered. Would that be possible?\\n\\nHow do we design a prompt around this to get useful generations for the agent interacting with the customer? Let\\'s begin with telling our model what the general setting is and what the remainder of the prompt is going to contain:\\nThis is a conversation between a customer and a polite, helpful customer service agent.\\nQuestion of the customer: Hi, I\\'d like a refund for the coffee maker I ordered. Would that be possible?\\n\\nGreat, we\\'ve told our model about what to expect and have made it clear that our query is a question of the customer. Next, let\\'s show the model the beginning of the response we would like to give the customer.\\nResponse by the customer service agent: Hello, thank you for reaching out to us. Yes,\\n\\nNote how we\\'ve stated clearly that the next sentence is a response to the question, that it comes from a customer service agent, and that we want to give a positive answer. Putting this all together, we obtain the following prompt:\\nThis is a conversation between a customer and a polite, helpful customer service agent.\\nQuestion of the customer: Hi, I\\'d like a refund for the coffee maker I ordered. Would that be possible?\\nResponse by the customer service agent: Hello, thank you for reaching out to us. Yes,\\n\\nCertain components of prompts (like input and output indicators) are useful in describing a desired task to the model, especially when including multiple examples in the prompt (as the next figures will show).\\nFeeding this into our Medium model multiple times we get the following completions:\\n\\nYes, we are able to accept returns if the product is unused and unopened.\\nYes, we are happy to refund your purchase. However, we do require you to return the item to our store for a full refund.\\nYes, we can do that. Please send us a message with your name, phone number, and the reason for the refund. We will get back to you as soon as possible.\\n\\nNote that even though this is a simplified example we get plausible completions from the baseline model using only a small number of customer service interactions! This could be further improved by finetuning it on examples of how you would like the model to handle specific questions and requests.\\n4. Show the model what you would like to see\\nAdding examples to a prompt is one of the key ways to achieving good generations. Examples demonstrate to the model the type of output we target.\\nGive a few examples of the types of generations you want. This is called few-shot learning. Let\\'s look at an example. Say, you\\'d like to use our models to classify whether a movie review is positive, negative or neutral. Imagine that you feed the following prompt into our model:\\nReview: \"I really enjoyed this movie!\"\\nThis sentiment of this review is\\n\\nAn actual generation based on this prompt by our Medium model reads:\\nThis sentiment of this review is apt, considering the movie\\'s plot,\\n\\nClearly, there are generations that our model sees as likely that are not the type of generation we\\'d like to get.\\nExamples in the prompt should include both an example input and the output we want the model emulate.\\nPutting this all together and feeding this new prompt into the Medium Generation model, we reliably get the generation positive.\\nThis is a movie review sentiment classifier.\\nReview: \"I loved this movie!\"\\nThis review is positive.\\nReview: \"I don\\'t know, it was ok I guess..\"\\nThis review is neutral.\\nReview: \"What a waste of time, would not recommend this movie.\"\\nThis review is negative.\\nReview: \"I really enjoyed this movie!\"\\nThis review is\\n\\nA simpler version of this prompt can be visualized like this:\\nAn example bringing together the various components of a prompt. We can also repeat the task description with each example to emphasize the instruction to the model.\\nFew-shot generations will generally work better with our larger models. You can use the likelihood endpoint to see how uncertain the model is about the correct answers given in the examples.\\nIf the command format does not work, try structuring as prose. An intuitive way to interact with the generate models is to give commands to the model about the type of generation that you want e.g. Give a list of artistic professions:. However, since much of the text that our models have seen is internet articles, sometimes this way of writing will be misunderstood. Try rephrasing the command into prose in a way such that the model will give the desired output:\\nThe table lists the following professions as artistic careers:\\n1. Painter\\n2.\\n\\nIn general, you may want to experiment with different styles of writing until you get something that works. Examples include writing in the style of a news article, a blog post, or a dialogue.\\nExamples\\nHere we showcase how we can use to apply the principles above by looking at two specific tasks: generating keywords based on a given passage and generating additional examples given a few existing examples.\\nKeyword generation: Let\\'s imagine that we have text passages that we\\'d like to automatically tag with the most relevant concepts appearing in the text.\\nBy combining a number of the techniques discussed above, we can generate just that! First, we state what the setting for this prompt is at the beginning of the prompt. Then we show the model two examples of what we want it to do: label a passage from John von Neumann\\'s Wikipedia page with the label \"John von Neumann\", and label a paragraph from the Wikipedia page on Feminism with the label \"Feminism\". Lastly, we give the model a passage from the Wikipedia page on Python.\\nThis is a bot that automatically finds the most important keyword for a given text passage.\\n\\nText: \"John von Neumann (/vɒn ˈnɔɪmən/; Hungarian: Neumann János Lajos, pronounced [ˈnɒjmɒn ˈjaːnoʃ ˈlɒjoʃ]; December 28, 1903 – February 8, 1957) was a Hungarian-American mathematician, physicist, computer scientist, engineer and polymath. Von Neumann was generally regarded as the foremost mathematician of his time[2] and said to be \"the last representative of the great mathematicians\".[3] He integrated pure and applied sciences.\"\\n\\nMost important key word: \"John von Neumann\"\\n\\nText: \"Some scholars consider feminist campaigns to be a main force behind major historical societal changes for women\\'s rights, particularly in the West, where they are near-universally credited with achieving women\\'s suffrage, gender-neutral language, reproductive rights for women (including access to contraceptives and abortion), and the right to enter into contracts and own property.[9] Although feminist advocacy is, and has been, mainly focused on women\\'s rights, some feminists argue for the inclusion of men\\'s liberation within its aims, because they believe that men are also harmed by traditional gender roles.[10] Feminist theory, which emerged from feminist movements, aims to understand the nature of gender inequality by examining women\\'s social roles and lived experience; feminist theorists have developed theories in a variety of disciplines in order to respond to issues concerning gender.\"\\n\\nMost important key word:  \"Feminism\"\\n\\nText: \"Guido van Rossum began working on Python in the late 1980s, as a successor to the ABC programming language, and first released it in 1991 as Python 0.9.0.[31] Python 2.0 was released in 2000 and introduced new features, such as list comprehensions and a garbage collection system using reference counting and was discontinued with version 2.7.18 in 2020.[32] Python 3.0 was released in 2008 and was a major revision of the language that is not completely backward-compatible and much Python 2 code does not run unmodified on Python 3.\"\\n\\nMost important key word:\\n\\nThis prompt reliably generates \"Python\" as an answer – while sometimes also returning \"Guido van Rossum\", another plausible option.\\nExample generation. A common task is to try to get the model to generate examples according to some description. Formulating the prompt as a list in the following style tends to work well.\\nThis is a list of ideas for blog posts for tourists visiting Toronto:\\n\\n1. The best sights to see in Toronto\\n2. My favourite walks in Toronto\\n\\nwhich then gives us generations like:\\n3. An overview of Toronto\\n4. Toronto events\\n5. Restaurants in Toronto\\n6. Shopping in Toronto\\n7. Travel tips for Toronto\\n8. Sightseeing in Toronto\\n9. What to do in Toronto\\n\\nUpdated 22 days ago Table of Contents\\n\\nMain Principles\\n\\n1. A prompt guides the model to generate useful output\\n2. Try multiple formulations of your prompt to get the best generations\\n3. Describe the task and the general setting\\n4. Show the model what you would like to see\\n\\n\\n\\nExamples\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n', metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/prompt-engineering', 'title': 'Prompt Engineering', 'description': 'Use the API to generate completions, distill text into semantically meaningful vectors, and more. Get state-of-the-art natural language processing without the need for expensive supercomputing infrastructure.', 'language': 'en'}),\n",
       " Document(page_content='Tokens\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to ContentGuides and ConceptsAPI ReferenceRelease NotesLLMUDashboardDocumentationPlaygroundCommunityLog InDashboardDocumentationPlaygroundCommunityLog InGuides and ConceptsAPI ReferenceRelease NotesLLMUSearchGet StartedThe Cohere PlatformIntroduction to Large Language ModelsPlayground OverviewQuickstart TutorialsGoing LiveIntegrationsLearnKey ConceptsEmbeddingsPrompt EngineeringTokensGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-pCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model MetricsMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported LanguagesRerankingReranking Best PracticesGenerating FeedbackIntroductory GuidesSemantic SearchContent ModerationEntity ExtractionText ClassificationText Classification (Classify)Text Classification (Embed)Co.summarize (Beta)Co.rerank (Beta)Responsible UseOverviewUsage GuidelinesModel LimitationsData StatementModelsSecurityEnvironmental ImpactLLM UniversityWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?Module 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language ModelsModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text RepresentationModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere\\'s Command ModelConclusion - Text GenerationAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLPAppendix 2: Building AppsApp ExamplesTokensSuggest EditsOur language models understand \"tokens\" rather than characters or bytes. One token can be a part of a word, an entire word, or punctuation. Very common words like \"water\" will have their own unique tokens. A longer, less frequent word might be encoded into 2-3 tokens, e.g. \"waterfall\" gets encoded into two tokens, one for \"water\" and one for \"fall\". Note that tokenization is sensitive to whitespace and capitalization.\\nHere are some references to calibrate how many tokens are in a text:\\n\\none word tends to be about 2-3 tokens\\na verse of a song is about 128 tokens\\nthis short article has about 300 tokens\\n\\nThe number of tokens per word depends on the complexity of the text. Simple text may approach 1 token per word on average, while complex texts may use less common words that require 3-4 tokens per word on average. Our representation models are currently limited to processing sequences with a maximum length of 4096 tokens. Generation models support up to 2048 tokens.\\nOur vocabulary of tokens is created using Byte Pair Encoding.\\nTurning text into tokens.\\nHow to pick max_tokens when sampling\\nThe easiest way to determine a good number of tokens is to guess and check using our playground. It is common to request more tokens than required and then run additional processing to retrieve the desired output.Updated 22 days ago Table of Contents\\nHow to pick max_tokens when sampling\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n', metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/tokens', 'title': 'Tokens', 'description': 'Use the API to generate completions, distill text into semantically meaningful vectors, and more. Get state-of-the-art natural language processing without the need for expensive supercomputing infrastructure.', 'language': 'en'}),\n",
       " Document(page_content='Command Nightly\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to ContentGuides and ConceptsAPI ReferenceRelease NotesLLMUDashboardDocumentationPlaygroundCommunityLog InDashboardDocumentationPlaygroundCommunityLog InGuides and ConceptsAPI ReferenceRelease NotesLLMUSearchGet StartedThe Cohere PlatformIntroduction to Large Language ModelsPlayground OverviewQuickstart TutorialsGoing LiveIntegrationsLearnKey ConceptsEmbeddingsPrompt EngineeringTokensGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-pCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model MetricsMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported LanguagesRerankingReranking Best PracticesGenerating FeedbackIntroductory GuidesSemantic SearchContent ModerationEntity ExtractionText ClassificationText Classification (Classify)Text Classification (Embed)Co.summarize (Beta)Co.rerank (Beta)Responsible UseOverviewUsage GuidelinesModel LimitationsData StatementModelsSecurityEnvironmental ImpactLLM UniversityWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?Module 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language ModelsModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text RepresentationModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere\\'s Command ModelConclusion - Text GenerationAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLPAppendix 2: Building AppsApp ExamplesCommand NightlySuggest Edits🚧This model is in active development. Our team is pushing hard to ensure command is safe, and helpful for our users. As you experiment with the model and run into issues, please help us by flagging it to our team by emailing us at [email\\xa0protected]\\nCommand is Cohere\\'s generative model that responds well with instruction-like prompts, and is available in two sizes: command-light and command. The command model demonstrates better performance, and command-light is a great option for developers who require fast response, like those building chatbots. \\nTo reduce the turnaround time for releases, we have nightly versions of command available. This means that every week, you can expect the performance of command-nightly-* to improve.\\n📘If you were previously using the command-xlarge-20221108 model, you will now be redirected to the command-nightly model. Please note that access to the command-xlarge-20221108 model will be discontinued after January 30, 2023. The command-nightly model has shown enhancements in all generative tasks, and we anticipate you will notice an improvement.\\nExample Prompts\\n\\nPrompt: Write me a poem about Leetcode.\\n\\nCompletion:\\nI am a leetcode problem,\\nI am here to trouble you,\\nI will give you a headache,\\nAnd make you want to cry.\\n–\\n\\nPrompt: Extract the name of the vendor from the invoice: PURCHASE #0521 NIKE XXX3846.  \\nCompletion: Nike is the vendor.\\n\\nGet Started\\nSet up\\nInstall the SDK, if you haven\\'t already.\\npip install cohere\\nThen, set up the Cohere client.\\nPythonimport cohere  \\nco = cohere.Client(api_key)\\n\\nCreate prompt\\nPythonprompt = \"Write an introductory paragraph for a blog post about language models.\"\\n\\nGenerate text\\nPythonresponse = co.generate(  \\n    model=\\'command-nightly\\',  \\n    prompt = prompt,  \\n    max_tokens=200,  \\n    temperature=0.750)\\n  intro_paragraph = response.generations[0].text\\n\\nFAQ\\nCan users train Command?\\nUsers cannot train Command in OS at this time. However, our team can handle this on a case by case basis. Please email [email\\xa0protected] if you’re interested in training this model.\\nWhere can I leave feedback about Cohere\\'s generative models?\\nPlease leave feedback in #product-updates on Discord.Updated 22 days ago Table of Contents\\n\\nExample Prompts\\n\\n\\nGet Started\\n\\nSet up\\nCreate prompt\\nGenerate text\\n\\n\\n\\nFAQ\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n', metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/command-beta', 'title': 'Command Nightly', 'description': \"🚧This model is in active development. Our team is pushing hard to ensure command is safe, and helpful for our users. As you experiment with the model and run into issues, please help us by flagging it to our team by emailing us at team@cohere.com.Command is Cohere's generative model that responds w...\", 'language': 'en'}),\n",
       " Document(page_content=\"Likelihood\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to ContentGuides and ConceptsAPI ReferenceRelease NotesLLMUDashboardDocumentationPlaygroundCommunityLog InDashboardDocumentationPlaygroundCommunityLog InGuides and ConceptsAPI ReferenceRelease NotesLLMUSearchGet StartedThe Cohere PlatformIntroduction to Large Language ModelsPlayground OverviewQuickstart TutorialsGoing LiveIntegrationsLearnKey ConceptsEmbeddingsPrompt EngineeringTokensGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-pCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model MetricsMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported LanguagesRerankingReranking Best PracticesGenerating FeedbackIntroductory GuidesSemantic SearchContent ModerationEntity ExtractionText ClassificationText Classification (Classify)Text Classification (Embed)Co.summarize (Beta)Co.rerank (Beta)Responsible UseOverviewUsage GuidelinesModel LimitationsData StatementModelsSecurityEnvironmental ImpactLLM UniversityWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?Module 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language ModelsModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text RepresentationModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere's Command ModelConclusion - Text GenerationAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLPAppendix 2: Building AppsApp ExamplesLikelihoodSuggest EditsOur models learn to model language by reading text scraped from the internet. Given a sentence, such as I like to bake cookies, the model is asked to repeatedly predict what the next token [?] is:\\nI [?]\\nI like [?]\\nI like to [?]\\nI like to bake [?]\\nI like to bake cookies\\n\\nThe model learns that the word to is quite likely to follow the word like in English, and that the word cookies is likely to follow the word bake.\\nIntuition\\nThe likelihood of a token can be thought of as a number (typically between -15 and 0) that quantifies a model's level of surprise that this token was used in a sentence. If a token has a low likelihood, it means the model did not expect this token to be used. Conversely, if a token has a high likelihood, the model was confident that it would be used. For example, using our Large model, the likelihood of 'to' from the sentence 'I like to' is roughly -1.5. This is quite high and means that the model was fairly confident that the tokens I like would be followed by the token to.. Similarly, the likelihood of cookies from the sentence I like to bake cookies is roughly -3.5, a bit lower than the previous example (which makes intuitive sense: brownies or cake would have also been reasonable options), but still quite high. However, if we change the sentence to I like to bake chairs then the likelihood of the token chairs is considerably lower, at around -14. This means the model is extremely surprised at its use within the sentence.\\nLikelihood of a tokenUpdated 22 days ago What’s NextLikelihood EvaluationTable of Contents\\nIntuition\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\", metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/likelihood', 'title': 'Likelihood', 'description': 'Use the API to generate completions, distill text into semantically meaningful vectors, and more. Get state-of-the-art natural language processing without the need for expensive supercomputing infrastructure.', 'language': 'en'}),\n",
       " Document(page_content=\"Number of Generations\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to ContentGuides and ConceptsAPI ReferenceRelease NotesLLMUDashboardDocumentationPlaygroundCommunityLog InDashboardDocumentationPlaygroundCommunityLog InGuides and ConceptsAPI ReferenceRelease NotesLLMUSearchGet StartedThe Cohere PlatformIntroduction to Large Language ModelsPlayground OverviewQuickstart TutorialsGoing LiveIntegrationsLearnKey ConceptsEmbeddingsPrompt EngineeringTokensGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-pCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model MetricsMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported LanguagesRerankingReranking Best PracticesGenerating FeedbackIntroductory GuidesSemantic SearchContent ModerationEntity ExtractionText ClassificationText Classification (Classify)Text Classification (Embed)Co.summarize (Beta)Co.rerank (Beta)Responsible UseOverviewUsage GuidelinesModel LimitationsData StatementModelsSecurityEnvironmental ImpactLLM UniversityWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?Module 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language ModelsModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text RepresentationModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere's Command ModelConclusion - Text GenerationAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLPAppendix 2: Building AppsApp ExamplesNumber of GenerationsSuggest EditsWhen you call the Generate endpoint, you have the option to generate multiple generations in a single call. This is done by setting the num_generations parameter.\\nGenerating multiple outputs in a single API call.\\nThe model’s outputs will vary depending on the generation settings you have specified, such as temperature, top-k, and top-p.\\nEach generation comes with its set of likelihood values, which consists of:\\n\\nThe likelihood of each generated token\\nThe average likelihood of all generated tokens. \\n\\nExample\\nThis example uses the input: “This curved gaming monitor delivers ...”\\nThe output generated with a maximum token set of 4 and sorted by average token likelihood are:\\nLikelihoodText-0.96a truly immersive experience-1.11a virtually seamless view-1.70the ultimate viewing experience-2.15a 144Hz rapid-2.44a comfortable and stylish\\nYou can use these outputs in a number of ways, for example, by selecting the one with the highest likelihood as the final output or by presenting these as options in your application.Updated 22 days ago Table of Contents\\nExample\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\", metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/number-of-generations', 'title': 'Number of Generations', 'description': 'Use the API to generate completions, distill text into semantically meaningful vectors, and more. Get state-of-the-art natural language processing without the need for expensive supercomputing infrastructure.', 'language': 'en'}),\n",
       " Document(page_content='Temperature\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to ContentGuides and ConceptsAPI ReferenceRelease NotesLLMUDashboardDocumentationPlaygroundCommunityLog InDashboardDocumentationPlaygroundCommunityLog InGuides and ConceptsAPI ReferenceRelease NotesLLMUSearchGet StartedThe Cohere PlatformIntroduction to Large Language ModelsPlayground OverviewQuickstart TutorialsGoing LiveIntegrationsLearnKey ConceptsEmbeddingsPrompt EngineeringTokensGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-pCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model MetricsMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported LanguagesRerankingReranking Best PracticesGenerating FeedbackIntroductory GuidesSemantic SearchContent ModerationEntity ExtractionText ClassificationText Classification (Classify)Text Classification (Embed)Co.summarize (Beta)Co.rerank (Beta)Responsible UseOverviewUsage GuidelinesModel LimitationsData StatementModelsSecurityEnvironmental ImpactLLM UniversityWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?Module 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language ModelsModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text RepresentationModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere\\'s Command ModelConclusion - Text GenerationAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLPAppendix 2: Building AppsApp ExamplesTemperatureSuggest EditsSampling from generation models incorporates randomness, so that the same prompt may yield different outputs each time you hit \"generate\". Temperature is a number used to tune the degree of randomness.\\nHow to pick temperature when sampling\\nA lower temperature means less randomness; a temperature of 0 will always yield the same output. Lower temperatures (less than 1) are more appropriate when performing tasks that have a \"correct\" answer, like question answering or summarization. If the model starts repeating itself this is a sign that the temperature is too low.\\nHigh temperature means more randomness, which can help the model give more creative outputs. If the model starts going off topic or giving non-sensical outputs, this is a sign that the temperature is too high.\\nAdjusting the temperature setting\\nTemperature can be tuned for different problems, but most people will find that a temperature of 1 is a good starting point.\\nAs sequences get longer, the model naturally becomes more confident in its predictions, so you can raise the temperature much higher for long prompts without going off topic. In contrast, using high temperatures on short prompts can lead to outputs being very unstable.Updated 22 days ago Table of Contents\\nHow to pick temperature when sampling\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n', metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/temperature', 'title': 'Temperature', 'description': 'Use the API to generate completions, distill text into semantically meaningful vectors, and more. Get state-of-the-art natural language processing without the need for expensive supercomputing infrastructure.', 'language': 'en'}),\n",
       " Document(page_content='Top-k & Top-p\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to ContentGuides and ConceptsAPI ReferenceRelease NotesLLMUDashboardDocumentationPlaygroundCommunityLog InDashboardDocumentationPlaygroundCommunityLog InGuides and ConceptsAPI ReferenceRelease NotesLLMUSearchGet StartedThe Cohere PlatformIntroduction to Large Language ModelsPlayground OverviewQuickstart TutorialsGoing LiveIntegrationsLearnKey ConceptsEmbeddingsPrompt EngineeringTokensGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-pCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model MetricsMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported LanguagesRerankingReranking Best PracticesGenerating FeedbackIntroductory GuidesSemantic SearchContent ModerationEntity ExtractionText ClassificationText Classification (Classify)Text Classification (Embed)Co.summarize (Beta)Co.rerank (Beta)Responsible UseOverviewUsage GuidelinesModel LimitationsData StatementModelsSecurityEnvironmental ImpactLLM UniversityWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?Module 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language ModelsModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text RepresentationModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere\\'s Command ModelConclusion - Text GenerationAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLPAppendix 2: Building AppsApp ExamplesTop-k & Top-pSuggest EditsThe method of picking output tokens is a key concept in text generation with language models. There are several methods (also called decoding strategies) for picking the output token and two of the leading ones are top-k sampling and top-p sampling.\\nLet’s look at the example where the input to the model is the prompt The name of that country is the:\\nExample output of a generation language model.\\nThe output token in this case, United, was picked in the last step of processing -- after the language model has processed the input and calculated a likelihood score for every token in its vocabulary. This score indicates the likelihood that it will be the next token in the sentence (based on all the text the model was trained on).\\nThe model calculates a likelihood for each token in its vocabulary. The decoding strategy then picks one as the output.\\n1. Pick the top token: greedy decoding\\nYou can see in this example that we picked the token with the highest likelihood, ‘United’.\\nAlways picking the highest scoring token is called \"Greedy Decoding\". It\\'s useful but has some drawbacks.\\nGreedy decoding is a reasonable strategy but has some drawbacks such as outputs with repetitive loops of text. Think of the suggestions in your smartphone\\'s auto-suggest. When you continually pick the highest suggested word, it may devolve into repeated sentences.\\n2. Pick from amongst the top tokens: top-k\\nAnother commonly used strategy is to sample from a shortlist of the top 3 tokens. This approach allows the other high-scoring tokens a chance of being picked. The randomness introduced by this sampling helps the quality of generation in a lot of scenarios.\\nAdding some randomness helps make output text more natural. In top-3 decoding, we first shortlist three tokens then sample one of them considering their likelihood scores.\\nMore broadly, choosing the top three tokens means setting the top-k parameter to 3. Changing the top-k parameter sets the size of the shortlist the model samples from as it outputs each token. Setting top-k to 1 gives us greedy decoding.\\nAdjusting to the top-k setting.\\n3. Pick from amongst the top tokens whose probabilities add up to 15%: top-p\\nThe difficulty of selecting the best top-k value opens the door for a popular decoding strategy that dynamically sets the size of the shortlist of tokens. This method, called Nucleus Sampling, shortlists the top tokens whose sum of likelihoods does not exceed a certain value. A toy example with a top-p value of 0.15 could look like this:\\nIn top-p, the size of the shortlist is dynamically selected based on the sum of likelihood scores reaching some threshold.\\nTop-p is usually set to a high value (like 0.75) with the purpose of limiting the long tail of low-probability tokens that may be sampled. We can use both top-k and top-p together. If both k and p are enabled, p acts after k.Updated 22 days ago Table of Contents\\n1. Pick the top token: greedy decoding\\n2. Pick from amongst the top tokens: top-k\\n3. Pick from amongst the top tokens whose probabilities add up to 15%: top-p\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n', metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/controlling-generation-with-top-k-top-p', 'title': 'Top-k & Top-p', 'description': 'Use the API to generate completions, distill text into semantically meaningful vectors, and more. Get state-of-the-art natural language processing without the need for expensive supercomputing infrastructure.', 'language': 'en'}),\n",
       " Document(page_content=\"Training Custom Models\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to ContentGuides and ConceptsAPI ReferenceRelease NotesLLMUDashboardDocumentationPlaygroundCommunityLog InDashboardDocumentationPlaygroundCommunityLog InGuides and ConceptsAPI ReferenceRelease NotesLLMUSearchGet StartedThe Cohere PlatformIntroduction to Large Language ModelsPlayground OverviewQuickstart TutorialsGoing LiveIntegrationsLearnKey ConceptsEmbeddingsPrompt EngineeringTokensGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-pCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model MetricsMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported LanguagesRerankingReranking Best PracticesGenerating FeedbackIntroductory GuidesSemantic SearchContent ModerationEntity ExtractionText ClassificationText Classification (Classify)Text Classification (Embed)Co.summarize (Beta)Co.rerank (Beta)Responsible UseOverviewUsage GuidelinesModel LimitationsData StatementModelsSecurityEnvironmental ImpactLLM UniversityWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?Module 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language ModelsModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text RepresentationModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere's Command ModelConclusion - Text GenerationAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLPAppendix 2: Building AppsApp ExamplesTraining Custom ModelsSuggest EditsAn Overview of Model Training\\nCohere's platform gives you the ability to train a Large Language Model (LLM) and customize it with a dataset to excel at a specific task. Custom models can lead to some of the best performing NLP models for a wide number of tasks.\\nIn this article, we look at training a generation model. See here for training a representation model.\\nCustom models use training data to turn a baseline model into a fine-tuned model.\\nWhen to Train a Custom Model\\nTraining large language models is recommended when you want to teach the model a new task like  or specific domain knowledge like the different gaits of a horse or your company's unique knowledge base. Common knowledge, like the colour of the sky, does not require training. Training is also helpful for generating or understanding data in a specific writing style or format.\\nIntuition\\nLet's take a representation model as an example, where we finetune a model for a classification task with training data consisting of three classes.\\nTo get an idea of how a representation model performs, we can project the embeddings it generates on a 2-dimensional plot, as per the image below. This image was taken from actual model outputs in the Playground.\\nThe distance between two data points represents how semantically similar they are—the closer they are, the more similar they are, and vice versa. A good model will have a clear separation between classes. To test the model, here we have fifteen data points, five for each class, in which the classes are unknown to the model.\\nWith a baseline model (left plot), we get a good separation between classes, which shows that it can perform well in this task.\\nBut with a custom model (right plot), the separation becomes even more apparent. Similar data points are now pushed even closer together and further apart from the rest. This indicates that the model has adapted to the additional data it received during training, hence is more likely to perform even better in this task.\\nIn real applications, this makes a huge difference. One example is a toxicity classifier to help content moderators automatically flag toxic content on their platforms. Not all online platforms define toxicity the same way, and each will have different language nuances to accommodate. For example, a gaming platform, an online community for kids, and a social media platform—each would have a different interpretation of the exact same data. This is where model training can help, where a model can be customized to your specific needs.\\nCreates a custom model that adapts to the training data.Updated 8 days ago Table of Contents\\n\\nAn Overview of Model Training\\n\\n\\nWhen to Train a Custom Model\\n\\nIntuition\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\", metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/training-custom-models', 'title': 'Training Custom Models', 'description': \"An Overview of Model Training Cohere's platform gives you the ability to train a Large Language Model (LLM) and customize it with a dataset to excel at a specific task. Custom models can lead to some of the best performing NLP models for a wide number of tasks. In this article, we look at training a...\", 'language': 'en'}),\n",
       " Document(page_content='Comparing Baseline and Custom Models\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to ContentGuides and ConceptsAPI ReferenceRelease NotesLLMUDashboardDocumentationPlaygroundCommunityLog InDashboardDocumentationPlaygroundCommunityLog InGuides and ConceptsAPI ReferenceRelease NotesLLMUSearchGet StartedThe Cohere PlatformIntroduction to Large Language ModelsPlayground OverviewQuickstart TutorialsGoing LiveIntegrationsLearnKey ConceptsEmbeddingsPrompt EngineeringTokensGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-pCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model MetricsMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported LanguagesRerankingReranking Best PracticesGenerating FeedbackIntroductory GuidesSemantic SearchContent ModerationEntity ExtractionText ClassificationText Classification (Classify)Text Classification (Embed)Co.summarize (Beta)Co.rerank (Beta)Responsible UseOverviewUsage GuidelinesModel LimitationsData StatementModelsSecurityEnvironmental ImpactLLM UniversityWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?Module 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language ModelsModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text RepresentationModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere\\'s Command ModelConclusion - Text GenerationAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLPAppendix 2: Building AppsApp ExamplesComparing Baseline and Custom ModelsSuggest EditsToken likelihood is a useful tool for model evaluation. For instance, let\\'s say you\\'ve trained a custom model and would like to know how much it\\'s improved over the default model - you could use token likelihoods to compare the performance of the models on some held-out text. Here is a quick demonstration of how to use the return_likelihoods parameter from the Generate endpoint for model evaluation.\\nExample Setup\\nLet\\'s say we\\'ve custom trained a base-light model on Shakespeare data. We\\'d like to confirm that this custom model has higher likelihood on Shakespeare text compared to the default model. To do this, we could hold out the following snippet from the training data:\\n\"To be, or not to be: that is the question:\"\\n\"Whether ’tis nobler in the mind to suffer\"\\n\"The slings and arrows of outrageous fortune,\"\\n\"Or to take arms against a sea of troubles,\"\\n\"And by opposing end them. To die: to sleep...\"\\n\\nThen we could use the following example code to retrieve the average log-likelihood of the above snippet:\\ncURLPythonNodeGoCLIcurl --location --request POST \\'https://api.cohere.ai/generate\\' \\\\\\n  --header \\'Authorization: BEARER {api_key}\\' \\\\\\n  --header \\'Content-Type: application/json\\' \\\\\\n  --data-raw \\'{\\n      \"model\": \"base-light\",\\n      \"prompt\": \"To be, or not to be: that is the question: Whether ’tis nobler in the mind to suffer The slings and arrows of outrageous fortune, Or to take arms against a sea of troubles, And by opposing end them. To die: to sleep...\",\\n      \"max_tokens\": 1,\\n      \"temperature\": 1,\\n      \"k\": 0,\\n      \"p\": 0.75,\\n      \"return_likelihoods\": \"ALL\"\\n    }\\'\\nimport cohere\\nco = cohere.Client(\\'{api_key}\\')\\nresponse = co.generate(\\n  model=\\'base-light\\',\\n  prompt=\\'To be, or not to be: that is the question: Whether ’tis nobler in the mind to suffer The slings and arrows of outrageous fortune, Or to take arms against a sea of troubles, And by opposing end them. To die: to sleep...\\',\\n  max_tokens=1,\\n  temperature=1,\\n  k=0,\\n  p=0.75,\\n  return_likelihoods=\\'ALL\\')\\nprint(\\'Likelihood: {}\\'.format(response.generations[0].likelihood))\\nconst cohere = require(\\'cohere-ai\\');\\ncohere.init(\\'{api_key}\\');\\n(async () => {\\n  const response = await cohere.generate({\\n    model: \\'base-light\\',\\n    prompt: \\'To be, or not to be: that is the question: Whether ’tis nobler in the mind to suffer The slings and arrows of outrageous fortune, Or to take arms against a sea of troubles, And by opposing end them. To die: to sleep...\\',\\n    max_tokens: 1,\\n    temperature: 1,\\n    k: 0,\\n    p: 0.75,\\n    return_likelihoods: \\'ALL\\']\\n  });\\n  console.log(`Likelihood: ${response.body.generations[0].likelihood}`);\\n})();\\npackage main\\n\\nimport (\\n  \"fmt\"\\n\\n  cohere \"github.com/cohere-ai/cohere-go\"\\n)\\n\\nfunc main() {\\n  co, err := cohere.CreateClient(\"{api_key}\")\\n  if err != nil {\\n    fmt.Println(err)\\n    return\\n  }\\n\\n  response, err := co.Generate(cohere.GenerateOptions{\\n    Model:             \"base-light\",\\n    Prompt:            `To be, or not to be: that is the question: Whether ’tis nobler in the mind to suffer The slings and arrows of outrageous fortune, Or to take arms against a sea of troubles, And by opposing end them. To die: to sleep...`,\\n    MaxTokens:         1,\\n    Temperature:       1,\\n    K:                 0,\\n    P:                 0.75,\\n    ReturnLikelihoods: \"ALL\",\\n  })\\n  if err != nil {\\n    fmt.Println(err)\\n    return\\n  }\\n\\n  fmt.Println(\"Likelihood:\", *response.Generations[0].Likelihood)\\n}\\nco model generate base-light \\'To be, or not to be: that is the question: Whether ’tis nobler in the mind to suffer The slings and arrows of outrageous fortune, Or to take arms against a sea of troubles, And by opposing end them. To die: to sleep...\\' --max-tokens=1 --temperature=1 --k=0 --p=0.75 --return_likelihoods={likelihoods}\\'\\n\\nResults\\nThe following are the average log-likelihoods of the snippet using the baseline and custom base-light models:\\nModelAverage Log-Likelihoodbase-light-2.99custom-base-light-1.12\\nThis demonstrates that customizing this model increased the likelihood of Shakespeare data!Updated 22 days ago Table of Contents\\nExample Setup\\nResults\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n', metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/likelihood-evaluation', 'title': 'Comparing Baseline and Custom Models', 'description': 'Use the API to generate completions, distill text into semantically meaningful vectors, and more. Get state-of-the-art natural language processing without the need for expensive supercomputing infrastructure.', 'language': 'en'}),\n",
       " Document(page_content='Training a Generative Model\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to ContentGuides and ConceptsAPI ReferenceRelease NotesLLMUDashboardDocumentationPlaygroundCommunityLog InDashboardDocumentationPlaygroundCommunityLog InGuides and ConceptsAPI ReferenceRelease NotesLLMUSearchGet StartedThe Cohere PlatformIntroduction to Large Language ModelsPlayground OverviewQuickstart TutorialsGoing LiveIntegrationsLearnKey ConceptsEmbeddingsPrompt EngineeringTokensGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-pCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model MetricsMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported LanguagesRerankingReranking Best PracticesGenerating FeedbackIntroductory GuidesSemantic SearchContent ModerationEntity ExtractionText ClassificationText Classification (Classify)Text Classification (Embed)Co.summarize (Beta)Co.rerank (Beta)Responsible UseOverviewUsage GuidelinesModel LimitationsData StatementModelsSecurityEnvironmental ImpactLLM UniversityWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?Module 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language ModelsModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text RepresentationModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere\\'s Command ModelConclusion - Text GenerationAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLPAppendix 2: Building AppsApp ExamplesTraining a Generative ModelSuggest EditsTraining a generation model consists of a few simple steps. Let’s go through the steps for training a generation model.\\nOn the Cohere dashboard, go to the models page and click on \"Create a custom model\".\\n\\nChoose the Generate Option\\nClick on the tile that says \"Generate\".\\n\\nUpload Your Data\\nUpload your data by clicking on ‘Choose a .txt file’. Your data should be in TXT format.\\nIf your data contains separators to distinguish between training examples, add the separator string in the ‘Data separator’ field (for example: --SEPARATOR--). If your data doesn’t contain separators, leave the field blank.\\n\\nOnce done, click on ‘Review data’.\\n\\nReview Data\\nThe next window will show you a few samples of your data that has been split. If you included data separators, the data will be split according to the separator. If you didn’t, the split will be done automatically.\\nIf you are happy with how the samples look, click on ‘Continue’ at the bottom of the page.\\n\\nStart Training\\nGive your model a nickname! Now, everything is set for custom training to begin. Press Start Training to begin!\\nWe can’t wait to see what you start building! Share your projects or find support on our Discord.Updated 22 days ago What’s NextTroubleshooting A Trained ModelTable of Contents\\nChoose the Generate Option\\nUpload Your Data\\nReview Data\\nStart Training\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n', metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/training-a-generative-model', 'title': 'Training a Generative Model', 'description': 'Use the API to generate completions, distill text into semantically meaningful vectors, and more. Get state-of-the-art natural language processing without the need for expensive supercomputing infrastructure.', 'language': 'en'}),\n",
       " Document(page_content='Training a Representation Model\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to ContentGuides and ConceptsAPI ReferenceRelease NotesLLMUDashboardDocumentationPlaygroundCommunityLog InDashboardDocumentationPlaygroundCommunityLog InGuides and ConceptsAPI ReferenceRelease NotesLLMUSearchGet StartedThe Cohere PlatformIntroduction to Large Language ModelsPlayground OverviewQuickstart TutorialsGoing LiveIntegrationsLearnKey ConceptsEmbeddingsPrompt EngineeringTokensGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-pCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model MetricsMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported LanguagesRerankingReranking Best PracticesGenerating FeedbackIntroductory GuidesSemantic SearchContent ModerationEntity ExtractionText ClassificationText Classification (Classify)Text Classification (Embed)Co.summarize (Beta)Co.rerank (Beta)Responsible UseOverviewUsage GuidelinesModel LimitationsData StatementModelsSecurityEnvironmental ImpactLLM UniversityWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?Module 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language ModelsModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text RepresentationModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere\\'s Command ModelConclusion - Text GenerationAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLPAppendix 2: Building AppsApp ExamplesTraining a Representation ModelSuggest EditsIn this article, we look at training a representation model, which covers both the Embed and Classify endpoints. \\nSee here if you\\'d like to get an overview of training a generation model.\\nA Text Classification Example\\nText classification is one of the most common language understanding tasks. A lot of business use cases can be mapped to text classification. Examples include:\\n\\nEvaluating the tone and sentiment of an incoming customer message (e.g. classes: “positive” and “negative”)\\nRouting incoming customer messages to the appropriate agent (e.g. classes: “billing”, “tech support”, “other”)\\nEvaluating if a user comment needs to be flagged for moderator attention (e.g. classes: “flag for moderation”, “neutral”)\\n\\nIn this article, we\\'ll train a representation model for sentiment classification.\\nA sentiment classifier assigns a piece of text as either \\'positive\\' or \\'negative\\'.\\nWhy Train a Representation Model\\nTraining leads to the best classification results a language model can achieve. That said, untrained baseline embeddings can perform well in a lot of tasks (See the text classification article for an example of how to train a sentiment classifier on top of baseline embedding models). But if we need to get that extra boost in performance, training makes our LLM become a specialist for the task we care about.\\nHow to Train a Representation Model\\nThe training file is a Comma Separated Values (CSV) file with a column for text and another for the number of the class. The contents of that file can look like this:\\nA table with example texts and a numeric label for each text (0 for negative texts, 1 for positive texts).\\nThe CSV file can be prepared in Excel or in text format like this with a .csv extension.\\nMy order was late, 0\\nShipping was fast!, 1\\nOrder arrived on time, 1\\nItems are always sold out, 1\\n\\nThat CSV file is then what you upload in the Representation training dialog box in the Playground.\\n📘New to Cohere?Get started now and get unprecedented access to world-class Generation and Representation models with billions of parameters.\\nWhat Training a Representation Model Does\\nA representation LLM is excellent at generating sentence embeddings (lists of numbers that capture the meaning of the sentences). These embeddings are great at indicating how similar sentences are to each other. We can plot them to explore their similarities and differences (points that are close together have similar embeddings).\\nConsider a case where we have five customer messages. Visualizing their embeddings can look like this:\\nScatter plot of five message example. Three of them are about shipping and are clustered close together.\\nSuch an embedding captures semantic similarity – so for example, messages about shipping are close to each other on the left.\\nIf we want to build the best sentiment classifier, however, then we need our embedding model to care about sentiment more than it cares about semantic similarity.\\nIf we colour the points depending on their sentiment, it could look like this:\\nThe same scatter plot of the five messages, except the colours of the points indicate which messages are positive and which are negative.\\nSuccessfully training a representation model on customer sentiment leads to a model which embeds sentences in this fashion:\\nA different scatterplot. Now positive messages are grouped together on the right, and negative messages are clustered together on the left.\\nTraining an embedding model on customer sentiment leads to an embedding model where the embeddings of positive comments are similar to each other and distinct from those of negative comments. This leads to better sentiment classification results.\\nTips to improve embedding/training quality\\nThere are several things to take into account to achieve the best trained embeddings:\\n\\nText cleaning: Improving the quality of the data is often the best investment in problem solving with machine learning. If the text, for example contains symbols or URLs or HTML code which are not needed for a specific task, make sure to remove them from the trained file (and from the text you later send to the trained model).\\nNumber of examples: The minimum number of labeled examples is 250, though we advise having at least 500 to achieve good training results. The more examples the better. \\nNumber of examples per class: In addition to the overall number of examples, it\\'s important to have many examples of each class in the dataset.\\nMix of examples in dataset: We recommend that you have a balanced (roughly equal) number of examples per class in your dataset.\\nLength of texts: The context size for text is currently 512 tokens. Subsequent tokens are truncated.\\nDeduplication: Ensure that each labelled example in your dataset is unique.\\nHigh quality test set: In the data upload step, upload a separate test set of examples that you want to see the model benchmarked on. These can be examples that were manually written or verified.\\n\\n\\nTraining a Representation Model: Step-by-step\\nTraining a representation model consists of a few simple steps. Let’s go through the steps for training a representation model.\\nOn the Cohere dashboard, go to the models page and click on \"Create a custom model\"\\n\\nChoose the Embed or Classify Option\\nClick on the tile that says \"Classify\" or \"Embed\".\\nBoth classify and embed endpoints will custom train a representation model\\n\\nUpload Your Data\\nUpload your training dataset data by going to ‘Training data’ and clicking on the upload file button. Your data should be in CSV format with exactly two columns—the first and second columns consisting of the examples and labels respectively. \\n\\nOptionally, you can upload a validation dataset. This will not be used during training but instead, will be used for evaluating the model’s performance post-training. To do so, go to ‘Upload validation set (optional)’ and repeat the same steps you just did with the training dataset. If you don’t upload a validation dataset, the platform will automatically set aside a validation dataset from the training dataset.\\nAt this point in time, if there are labels with less than 5 unique examples, we will remove those labels from your training set. \\n\\nAs shown above, the label \\'Area\\' had fewer than 5 examples so it has been removed from the training set.\\nOnce done, click on ‘Next’.\\nPreview Your Data\\nThe preview window will show a few samples of your training dataset, and if you uploaded it, your validation dataset.\\nToggle between the tabs \\'Training\\' and \\'Validation\\' to see a sample of your respective datasets. \\n\\nAt the bottom of this page, the distribution of labels in each respective dataset is shown. \\n\\nIf you are happy with how the samples look, click on \\'Continue\\'.\\nStart Training\\nNow, everything is set for training to begin. Click on \\'Start training\\' to proceed.\\n\\nWe can’t wait to see what you start building! Share your projects or find support on our Discord.Updated 22 days ago Table of Contents\\n\\n\\nA Text Classification Example\\nWhy Train a Representation Model\\nHow to Train a Representation Model\\nWhat Training a Representation Model Does\\nTips to improve embedding/training quality\\n\\n\\n\\nTraining a Representation Model: Step-by-step\\n\\nChoose the Embed or Classify Option\\nUpload Your Data\\nPreview Your Data\\nStart Training\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n', metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/training-a-representation-model', 'title': 'Training a Representation Model', 'description': 'Use the API to generate completions, distill text into semantically meaningful vectors, and more. Get state-of-the-art natural language processing without the need for expensive supercomputing infrastructure.', 'language': 'en'}),\n",
       " Document(page_content='Troubleshooting a Custom Model\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to ContentGuides and ConceptsAPI ReferenceRelease NotesLLMUDashboardDocumentationPlaygroundCommunityLog InDashboardDocumentationPlaygroundCommunityLog InGuides and ConceptsAPI ReferenceRelease NotesLLMUSearchGet StartedThe Cohere PlatformIntroduction to Large Language ModelsPlayground OverviewQuickstart TutorialsGoing LiveIntegrationsLearnKey ConceptsEmbeddingsPrompt EngineeringTokensGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-pCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model MetricsMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported LanguagesRerankingReranking Best PracticesGenerating FeedbackIntroductory GuidesSemantic SearchContent ModerationEntity ExtractionText ClassificationText Classification (Classify)Text Classification (Embed)Co.summarize (Beta)Co.rerank (Beta)Responsible UseOverviewUsage GuidelinesModel LimitationsData StatementModelsSecurityEnvironmental ImpactLLM UniversityWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?Module 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language ModelsModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text RepresentationModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere\\'s Command ModelConclusion - Text GenerationAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLPAppendix 2: Building AppsApp ExamplesTroubleshooting a Custom ModelSuggest EditsIn this post, we answer frequently asked questions about training models.\\nTroubleshooting Representation Models\\nGathering enough data\\nWhile our Classify endpoint enables a user to build a classifier with just 5 examples per label, this classifier runs on our baseline model which has not been trained for specific use cases. Your dataset must contain at least 250 labelled examples to start training.\\nIf you are unable to locate a relevant labelled dataset from online sources, we suggest trying to generate labelled examples using our Generate endpoint. Check out this sample preset of a user generating product feedback to train a product feedback classifier.\\nData formatting best practices\\nEnsure your data is in a two-column csv. One column should be the sample text you\\'d like to classify or search, and the second column should be a label for the text. We recommend using a comma , as your delimiter.\\nHere are a few example lines from a dataset that could be used to train a model that classifies headlines as positive, negative, and neutral with our Classify endpoint:\\nheadline,sentiment\\nThe major construction companies of Finland are operating in Russia,neutral\\n$ESI on lows, down $1.50 to $2.50 BK a real possibility,negative\\n$SPY wouldn\\'t be surprised to see a green close,positive\\n\\nTo pass data validation, ensure that:\\n\\nThere are at least 5 examples for each label in your dataset\\nYour dataset contains at least unique 250 examples in total (not 250 examples per label)\\nYour data is encoded in UTF-8\\nWe will automatically deduplicate your dataset\\n\\nFormatting errors for classification tasks\\nCohere\\'s Classify endpoint will return predictions for classes that sum up to 1. We currently do not support outputting classifications for multiple labels (known as multi-label classification). Each example text should be mapped to one label only.\\nTake this example below:\\nheadline,topic\\n\"How Robots Can Assist Students with Disabilities\",\"technology,health\"\\n\"As Gas Prices Went Up, So Did the Hunt for Electric Vehicles\",\"technology,economy\"\\n\\nCurrently, we will process this data and train with two labels, technology,health and technology,economy instead of the desired three labels, technology, health, and economy.\\nIn this case you will need to select one label for each headline.\\nFormatting for search tasks\\nAt this time, if you are intending to train a representation model to use Cohere\\'s Embed endpoint to perform a search task (not predicting a label), you will still need to assign a label to texts for representation training. \\nFor example, if you are building a search engine for Hacker News posts and you want to either cluster similar posts or associate posts with a certain keyword, you would create a labelled dataset with the post titles mapped to the keyword. See a few sample lines labelled below:\\npost title,keyword\\nAdvice for a new and inexperienced tech lead?,career\\nHow do you deal with getting old and feeling lost?,personal\\nBest way to learn modern C++?,skills\\n\\nIf you are topic modelling and trying to find clusters, we recommend trying the baseline model. Check out our blog post on topic modelling Hacker News posts.\\nTroubleshooting auto evaluation metrics\\nWhen you are viewing auto evaluation metrics during or after your model has finished training, you may find that the F1, Recall, and Precision metrics are missing. This may occur if your dataset is extremely imbalanced (e.g. A binary dataset with 95% positive labels and 5% negative labels) and the trained model fails to predict one of the labels at all. This does not prevent you from using this trained model, it is simply a warning.\\nTo resolve this warning, try adding more examples for labels with less data. \\nHow long does it take to train a model?\\nTrainings are completed sequentially, and when you launch a training session, it is added to the end of a queue. Depending on the length of our training queue, training may take between 1 hour to a day to complete. \\nUsing your trained model\\nTo use your trained model in our API or SDKs, you must call it by its model UUID and not by its name. To get the model UUID, select the model in the playground and click Export Code. Select the library you are using and copy the code to call the model.\\nThis is a screenshot of how to locate the model path to call your custom model.\\nRestarting paused custom models\\nAll trained models are paused after 24 hours of inactivity. To restart your model, select your model in the trained models panel and click on the Wake button, pictured below:\\nThis is a screenshot of how to awaken a paused model.\\nTroubleshooting failed training\\nOur engineers review every individual failed training and will attempt to rectify it without any action on your part. We reach out to individuals with failed custom models we cannot resolve manually.\\nPlease reach out to [email\\xa0protected] or post in our co:mmunity Discord if you have unanswered questions about training models.Updated 22 days ago Table of Contents\\n\\nTroubleshooting Representation Models\\n\\nGathering enough data\\nData formatting best practices\\nFormatting errors for classification tasks\\nFormatting for search tasks\\nTroubleshooting auto evaluation metrics\\n\\n\\n\\nHow long does it take to train a model?\\n\\n\\nUsing your trained model\\n\\n\\nRestarting paused custom models\\n\\n\\nTroubleshooting failed training\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n', metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/training-troubleshooting', 'title': 'Troubleshooting a Custom Model', 'description': 'Use the API to generate completions, distill text into semantically meaningful vectors, and more. Get state-of-the-art natural language processing without the need for expensive supercomputing infrastructure.', 'language': 'en'}),\n",
       " Document(page_content=\"Custom Model Metrics\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to ContentGuides and ConceptsAPI ReferenceRelease NotesLLMUDashboardDocumentationPlaygroundCommunityLog InDashboardDocumentationPlaygroundCommunityLog InGuides and ConceptsAPI ReferenceRelease NotesLLMUSearchGet StartedThe Cohere PlatformIntroduction to Large Language ModelsPlayground OverviewQuickstart TutorialsGoing LiveIntegrationsLearnKey ConceptsEmbeddingsPrompt EngineeringTokensGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-pCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model MetricsMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported LanguagesRerankingReranking Best PracticesGenerating FeedbackIntroductory GuidesSemantic SearchContent ModerationEntity ExtractionText ClassificationText Classification (Classify)Text Classification (Embed)Co.summarize (Beta)Co.rerank (Beta)Responsible UseOverviewUsage GuidelinesModel LimitationsData StatementModelsSecurityEnvironmental ImpactLLM UniversityWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?Module 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language ModelsModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text RepresentationModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere's Command ModelConclusion - Text GenerationAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLPAppendix 2: Building AppsApp ExamplesCustom Model MetricsSuggest EditsWhen you train a custom model, we provide you some measures to see how well your model might perform at the task provided.\\nGenerate Model Metrics\\nPlease note that Generate model outputs are often best evaluated qualitatively, so the performance metrics provided alone will not provide a comprehensive understanding of the model’s performance.\\nWhen you train a Generate custom model, you will see metrics that look like this:\\n\\nAccuracy\\nAccuracy is a measure of how many predictions the model made correctly out of all the predictions in an evaluation. To evaluate Generate models for accuracy, we ask it to predict certain words in the user uploaded data.\\nThe number in the pill (eg. 13%) is the difference between the accuracy of the default model when the user started training, and the accuracy of the model that is deployed. This difference is a proxy for how much accuracy improvement was gained by training the model on the dataset.\\nLoss\\nLoss is a measure that describes how bad or wrong a prediction is. Accuracy may tell you how many predictions the model got wrong, but it will not describe how incorrect the wrong predictions are. If every prediction is perfect, the loss will be 0.\\nTo evaluate Generate models for loss, we ask the model to predict certain words in the user provided data and evaluate how wrong the incorrect predictions are. A loss around 11 indicates totally random performance. \\nFor this reason, the loss should decrease as the model improves. The number in the pill (e.g -0.56) is the difference between the loss when the default model started training and when it was deployed. This difference is a proxy for how much loss improvement was gained by training the model on your dataset.\\nClassify and Embed Model Metrics\\nClassify and Embed custom Models are both trained using data of examples mapping to predicted labels, and for that reason they are evaluated using the same methods and performance metrics. You can also provide a test set of data that we will use to calculate performance metrics. If a test set is not provided, we will split your training data randomly to calculate performance metrics. \\nWhen you train Classify and Embed custom models, you will see metrics that look like this:\\n\\nAccuracy\\nAccuracy is a measure of how many predictions the model made correctly out of all the predictions in an evaluation. To evaluate Embed and Classify models for accuracy, we ask the model to predict labels for the examples in the test set. In this case, the model predicted 95.31% of the labels correctly.\\nThe number in the pill (eg. 75%) is the difference between the accuracy of the default model when the user started training, and the accuracy of the model that is deployed. This difference is a proxy for how much accuracy improvement was gained by training the model on the dataset.\\nLoss\\nLoss is a measure that describes how bad or wrong a prediction is. Accuracy may tell you how many predictions the model got wrong, but it will not describe how incorrect the wrong predictions are. If every prediction is perfect, the loss will be 0.\\nTo evaluate Classify and Embed models for loss, we ask the model to predict labels for the examples in the test set and evaluate how wrong the incorrect predictions are. \\nFor this reason, the loss should decrease as the model improves. The number in the pill (e.g -0.11) is the difference between the loss when the default model started training and when it was deployed. This difference is a proxy for how much loss improvement was gained by training the default model on your dataset.\\nPrecision\\nPrecision is a measure that shows, for a given label, how correct the model was when it predicted the label. It’s calculated by taking the number of true positives and dividing it by the sum of true positives and false positives.\\nFor example, let’s say we have a test set of 100 examples. 50 of them are label A and 50 of them are label B. If the model guessed label A for every prediction (100 times), every incorrectly predicted label B would be a false positive. The precision of label A would be 50%.\\nThis is calculated for every label. The number shown in the metrics are the macro-weighted average of the precision across labels. \\nRecall\\nRecall is a measure that shows how often the model predicted a given label correctly. It’s calculated by taking the number of true positives and dividing it by the sum of true positives and false negatives. \\nFor example, let’s say we have a test set of 100 examples. 50 of them are label A and 50 of them are label B. If the model guessed label A for every prediction (100 times), there would be no false negative predictions of label A. The recall of label A would be 100%.\\nThis is calculated for every label. The number shown in the metrics are the macro-weighted average of the recall across labels.\\nF1\\nOptimizing for either precision or recall often means sacrificing quality in the other. In the example above, 100% recall for label A does not mean that it was a great model, as evidenced by the precision. The F1 score attempts to provide a balanced measure of performance between precision and recall. \\nThe number shown in the metrics are the macro-weighted average of F1 across labels.\\nFor Recall, Precision, and F1, the number in the pill is a proxy for how much improvement was gained by training the default model on your dataset.\\nYou can see the detailed calculations to evaluate Embed and Classify models in this blog post.Updated 22 days ago Table of Contents\\n\\nGenerate Model Metrics\\n\\nAccuracy\\nLoss\\n\\n\\n\\nClassify and Embed Model Metrics\\n\\nAccuracy\\nLoss\\nPrecision\\nRecall\\nF1\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\", metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/custom-model-metrics', 'title': 'Custom Model Metrics', 'description': 'Use the API to generate completions, distill text into semantically meaningful vectors, and more. Get state-of-the-art natural language processing without the need for expensive supercomputing infrastructure.', 'language': 'en'}),\n",
       " Document(page_content='Multilingual Embedding Models\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to ContentGuides and ConceptsAPI ReferenceRelease NotesLLMUDashboardDocumentationPlaygroundCommunityLog InDashboardDocumentationPlaygroundCommunityLog InGuides and ConceptsAPI ReferenceRelease NotesLLMUSearchGet StartedThe Cohere PlatformIntroduction to Large Language ModelsPlayground OverviewQuickstart TutorialsGoing LiveIntegrationsLearnKey ConceptsEmbeddingsPrompt EngineeringTokensGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-pCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model MetricsMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported LanguagesRerankingReranking Best PracticesGenerating FeedbackIntroductory GuidesSemantic SearchContent ModerationEntity ExtractionText ClassificationText Classification (Classify)Text Classification (Embed)Co.summarize (Beta)Co.rerank (Beta)Responsible UseOverviewUsage GuidelinesModel LimitationsData StatementModelsSecurityEnvironmental ImpactLLM UniversityWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?Module 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language ModelsModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text RepresentationModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere\\'s Command ModelConclusion - Text GenerationAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLPAppendix 2: Building AppsApp ExamplesMultilingual Embedding ModelsSuggest EditsAt Cohere, we are committed to breaking down barriers and expanding access to cutting-edge NLP technologies that power projects across the globe. By making our innovative multilingual language models available to all developers, we continue to move toward our goal of empowering developers, researchers, and innovators with state-of-the-art NLP technologies that push the boundaries of Language AI.\\nOur Multilingual Model maps text to a semantic vector space, positioning text with a similar meaning in close proximity. This process unlocks a range of valuable use cases for multilingual settings. For example, one can map a query to this vector space during a search to locate relevant documents nearby. This often yields search results that are several times better than keyword search.\\n\\nDifferences Between English and Multilingual Embedding Models\\nUnlike our English language embedding model, our multilingual model was trained using dot product calculations. Using dot products produces a non-normalized similarity score, reflecting the magnitude of the two compared vectors. When this dimension is incorporated, multilingual embeddings perform better than standard. For more information on how our English language model works (using cosine similarity), see our introductory guide to the Cohere platform. The dimensions of our multilingual embeddings is 768 dimensions.\\nUse Cases\\n\\nMultilingual Semantic Search: Improve your search results regardless of the language.\\nAggregate Customer Feedback: Organize customer feedback across hundreds of languages, simplifying a major challenge for international operations.\\nCross-Lingual Zero-Shot Content Moderation: Identify harmful content in online communities is challenging, especially as users speak hundreds of languages. Train a model with a few English examples, then detect harmful content in 100+ languages.\\n\\nGet Started\\nTo get started using the multilingual embedding models, you can either query our endpoints or install our SDK to use the model within Python:\\nPythonimport cohere  \\nco = cohere.Client(f\"{api_key}\")  \\ntexts = [  \\n   \\'Hello from Cohere!\\', \\'مرحبًا من كوهير!\\', \\'Hallo von Cohere!\\',  \\n   \\'Bonjour de Cohere!\\', \\'¡Hola desde Cohere!\\', \\'Olá do Cohere!\\',  \\n   \\'Ciao da Cohere!\\', \\'您好，来自 Cohere！\\', \\'कोहेरे से नमस्ते!\\'  \\n]  \\nresponse = co.embed(texts=texts, model=\\'embed-multilingual-v2.0\\')  \\nembeddings = response.embeddings # All text embeddings \\nprint(embeddings[0][:5]) # Print embeddings for the first text\\n\\nModel Performance\\nModelClusteringSearch- EnglishSearch- MultilingualCross-lingual Classification Cohere: embed-multilingual-v2.051.055.851.464.6Sentence-transformers:paraphrase-multilingual-mpnet-base-v246.744.415.356.1Google: LaBSE41.020.913.259.2Google: Universal Sentence Encoder40.114.33.459.8\\nList of Supported Languages\\nOur multilingual embedding model supports over 100 languages, including Chinese, Spanish, and French. For a full list of languages we support, please reference this page.Updated 22 days ago Table of Contents\\nDifferences Between English and Multilingual Embedding Models\\nUse Cases\\nGet Started\\nModel Performance\\nList of Supported Languages\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n', metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/multilingual-language-models', 'title': 'Multilingual Embedding Models', 'description': 'At Cohere, we are committed to breaking down barriers and expanding access to cutting-edge NLP technologies that power projects across the globe. By making our innovative multilingual language models available to all developers, we continue to move toward our goal of empowering developers, researche...', 'language': 'en'}),\n",
       " Document(page_content='Language Detection\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to ContentGuides and ConceptsAPI ReferenceRelease NotesLLMUDashboardDocumentationPlaygroundCommunityLog InDashboardDocumentationPlaygroundCommunityLog InGuides and ConceptsAPI ReferenceRelease NotesLLMUSearchGet StartedThe Cohere PlatformIntroduction to Large Language ModelsPlayground OverviewQuickstart TutorialsGoing LiveIntegrationsLearnKey ConceptsEmbeddingsPrompt EngineeringTokensGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-pCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model MetricsMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported LanguagesRerankingReranking Best PracticesGenerating FeedbackIntroductory GuidesSemantic SearchContent ModerationEntity ExtractionText ClassificationText Classification (Classify)Text Classification (Embed)Co.summarize (Beta)Co.rerank (Beta)Responsible UseOverviewUsage GuidelinesModel LimitationsData StatementModelsSecurityEnvironmental ImpactLLM UniversityWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?Module 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language ModelsModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text RepresentationModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere\\'s Command ModelConclusion - Text GenerationAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLPAppendix 2: Building AppsApp ExamplesLanguage DetectionSuggest EditsLanguage detection is a necessary first step for businesses that deal with multilingual user bases. Whether you are working with a single multi-lingual model or a multi model environment, understanding the language of a request (e.g. query, input) is paramount to a good user experience. \\nCo.detect_language is an endpoint gives the following information for a text input: \\n\\nThe full name (language_name) of the language the input is in.\\nA language_code describing the language the input is in. For example, the ISO code for English is en.\\n\\nUse Cases\\nSingle Model Environment\\nUse a single multilingual model to handle both english and non-english queries. Identify the language of an incoming query and filter the results of your results by matching languages for monolingual retrieval with a multilingual model - in addition, you can specify which languages you want to filter for in a cross-lingual retrieval setup. \\nMulti Model Environment\\nUse multiple models for English and non-English embeddings. Identify a query in its respective language and route the request to different models depending on your setup. For example, if a query is in identified as English, route it to our default English embedding model, if not, route it to our multilingual embedding model. \\nExamples\\nInput\\nPythonresponse = co.detect_language(texts=[\"Hello World\",\"2023 will be my year\"])\\n\\nResponse\\nPythonresults: [{language_code:\"en\", language_name:\"English\"},\\n{language_code:\"en\", language_name:\"English\"}]\\n\\nList of Supported Languages\\nLanguage CodeLanguage NameafAfrikaansalsAlbanianamAmharicanAragonesearArabicarzArabic (Egyptian)asAssameseastAsturianavAvaricazAzerbaijaniazbSouth AzerbaijanibaBashkirbarBavarianbclCentral BikolbeBelarusianbgBulgarianbhBiharibnBengaliboTibetanbpyBishnupriya ManipuribrBretonbsBosnianbxrBuryatcaCatalancbkChavacanoceChechencebCebuanockbCentral KurdishcoCorsicancsCzechcvChuvashcyWelshdaDanishdeGermandiqZazakidsbLower SorbiandtyDotelidvDhivehielGreekemlEmilian-RomagnolenEnglisheoEsperantoesSpanishetEstonianeuBasquefaPersianfiFinnishfrFrenchfrrFrisianfyWestern FrisiangaIrishgdGaelic (Scotland)glGaliciangnGuaranigomKonkaniguGujaratigvManxheHebrewhiHindihifFiji HindihrCroatianhsbUpper SorbianhtHaitian CreolehuHungarianhyArmenianiaInterlinguaidIndonesianieInterlingue; OccidentaliloIlokoioIdoisIcelandicitItalianjaJapanesejboLojbanjvJavanesekaGeorgiankkKazakhkmKhmerknKannadakoKoreankrcKarachay-BalkarkuKurdishkvKomikwCornishkyKyrgyzlaLatinlbLuxembourgishlezLezghianliLimburganlmoLombardloLaothianlrcNorthern LuriltLithuanianlvLatvianmaiMaithilimgMalagasymhrMeadow MariminMinangkabaumkMacedonianmlMalayalammnMongolianmrMarathimrjHill MarimsMalaymtMaltesemwlMirandesemyBurmesemyvErzyamznMazandaraninahNahuatlnapNeapolitanndsLow GermanneNepalinewNepal BhasanlDutchnnNorwegian NynorsknoNorwegianocOccitan (post 1500)orOriyaosOssetianpaPunjabipamPampangapflPalatine GermanplPolishpmsPiedmontesepnbPakistani PunjabipsPushtoptPortuguesequQuechuarmRomanshroRomanianruRussianrueRusynsaSanskritsahYakutscSardinianscnSicilianscoScotssdSindhishSerbo-CroatiansiSinhaleseskSlovakslSloveniansoSomalisqAlbaniansrSerbiansuSundanesesvSwedishswSwahilitaTamilteTelugutgTajikthThaitkTurkmentlTagalogtrTurkishttTatartyvTuvinianugUighurukUkrainianurUrduuzUzbekvecVenetianvepVepsviVietnamesevlsVlaamsvoVolapükwaWalloonwarWaraywuuWu ChinesexalKalmykxmfMingrelianyiYiddishyoYorubayueYue ChinesezhChineseUpdated 22 days ago Table of Contents\\n\\nUse Cases\\n\\nSingle Model Environment\\nMulti Model Environment\\n\\n\\n\\nExamples\\n\\nInput\\nResponse\\n\\n\\n\\nList of Supported Languages\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n', metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/language-detection', 'title': 'Language Detection', 'description': 'Language detection is a necessary first step for businesses that deal with multilingual user bases. Whether you are working with a single multi-lingual model or a multi model environment, understanding the language of a request (e.g. query, input) is paramount to a good user experience.Co.detect_lan...', 'language': 'en'}),\n",
       " Document(page_content=\"Multilingual Semantic Search\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to ContentGuides and ConceptsAPI ReferenceRelease NotesLLMUDashboardDocumentationPlaygroundCommunityLog InDashboardDocumentationPlaygroundCommunityLog InGuides and ConceptsAPI ReferenceRelease NotesLLMUSearchGet StartedThe Cohere PlatformIntroduction to Large Language ModelsPlayground OverviewQuickstart TutorialsGoing LiveIntegrationsLearnKey ConceptsEmbeddingsPrompt EngineeringTokensGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-pCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model MetricsMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported LanguagesRerankingReranking Best PracticesGenerating FeedbackIntroductory GuidesSemantic SearchContent ModerationEntity ExtractionText ClassificationText Classification (Classify)Text Classification (Embed)Co.summarize (Beta)Co.rerank (Beta)Responsible UseOverviewUsage GuidelinesModel LimitationsData StatementModelsSecurityEnvironmental ImpactLLM UniversityWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?Module 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language ModelsModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text RepresentationModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere's Command ModelConclusion - Text GenerationAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLPAppendix 2: Building AppsApp ExamplesMultilingual Semantic SearchSuggest EditsSemantic search no longer restricts itself to queries and documents in the same language but also works across languages. For example, if we phrase the search query in Arabic (“ما هي عاصمة الولايات المتحدة؟”), we get the same results, while keyword search can obviously not retrieve any relevant documents.\\n\\nThis enables interesting use cases, for example, in the financial domain, to quickly find relevant information irrespective of the language in which they have been published.Updated 22 days ago \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\", metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/multilingual-semantic-search', 'title': 'Multilingual Semantic Search', 'description': 'Semantic search no longer restricts itself to queries and documents in the same language but also works across languages. For example, if we phrase the search query in Arabic (“ما هي عاصمة الولايات المتحدة؟”), we get the same results, while keyword search can obviously not retrieve any relevant docu...', 'language': 'en'}),\n",
       " Document(page_content=\"Customer Feedback Aggregation\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to ContentGuides and ConceptsAPI ReferenceRelease NotesLLMUDashboardDocumentationPlaygroundCommunityLog InDashboardDocumentationPlaygroundCommunityLog InGuides and ConceptsAPI ReferenceRelease NotesLLMUSearchGet StartedThe Cohere PlatformIntroduction to Large Language ModelsPlayground OverviewQuickstart TutorialsGoing LiveIntegrationsLearnKey ConceptsEmbeddingsPrompt EngineeringTokensGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-pCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model MetricsMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported LanguagesRerankingReranking Best PracticesGenerating FeedbackIntroductory GuidesSemantic SearchContent ModerationEntity ExtractionText ClassificationText Classification (Classify)Text Classification (Embed)Co.summarize (Beta)Co.rerank (Beta)Responsible UseOverviewUsage GuidelinesModel LimitationsData StatementModelsSecurityEnvironmental ImpactLLM UniversityWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?Module 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language ModelsModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text RepresentationModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere's Command ModelConclusion - Text GenerationAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLPAppendix 2: Building AppsApp ExamplesCustomer Feedback AggregationSuggest EditsSuccessful products like the iPhone quickly get tens of thousands of reviews on eCommerce marketplaces and on social media, which are written in many languages. Getting insights from these reviews enables companies to better understand their customer base and to better drive their product roadmap. \\nHowever, methods for content aggregation only worked well for English, and it wasn’t possible to see patterns across languages or to compare markets.\\n\\nCohere’s multilingual model maps text in different languages to the same vector spaces, allowing users to derive insights across languages and find patterns for specific markets (e.g., which markets care about the picture quality of smartphones).Updated 22 days ago \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\", metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/customer-feedback-aggregation', 'title': 'Customer Feedback Aggregation', 'description': 'Successful products like the iPhone quickly get tens of thousands of reviews on eCommerce marketplaces and on social media, which are written in many languages. Getting insights from these reviews enables companies to better understand their customer base and to better drive their product roadmap.Ho...', 'language': 'en'}),\n",
       " Document(page_content=\"Cross-Lingual Content Moderation\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to ContentGuides and ConceptsAPI ReferenceRelease NotesLLMUDashboardDocumentationPlaygroundCommunityLog InDashboardDocumentationPlaygroundCommunityLog InGuides and ConceptsAPI ReferenceRelease NotesLLMUSearchGet StartedThe Cohere PlatformIntroduction to Large Language ModelsPlayground OverviewQuickstart TutorialsGoing LiveIntegrationsLearnKey ConceptsEmbeddingsPrompt EngineeringTokensGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-pCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model MetricsMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported LanguagesRerankingReranking Best PracticesGenerating FeedbackIntroductory GuidesSemantic SearchContent ModerationEntity ExtractionText ClassificationText Classification (Classify)Text Classification (Embed)Co.summarize (Beta)Co.rerank (Beta)Responsible UseOverviewUsage GuidelinesModel LimitationsData StatementModelsSecurityEnvironmental ImpactLLM UniversityWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?Module 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language ModelsModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text RepresentationModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere's Command ModelConclusion - Text GenerationAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLPAppendix 2: Building AppsApp ExamplesCross-Lingual Content ModerationSuggest EditsIn today’s world, content moderation remains a major challenge. As platforms like online games increasingly attract an international audience, the complexity of content moderation has grown as hateful content makes its way across multiple languages and has a greater probability of passing through content moderation tools.\\nTo tackle this challenge, we use multilingual embeddings to build a content moderation tool that works across 100+ languages and only requires training data in English.\\n\\nFor content moderation, we just need a handful of training examples of harmful and acceptable content in one language. For example, in English, we can then train a classifier to find the decision boundary in the vector space that helps us determine which type of content is undesirable on the platform.Updated 22 days ago \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\", metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/cross-lingual-content-moderation', 'title': 'Cross-Lingual Content Moderation', 'description': 'In today’s world, content moderation remains a major challenge. As platforms like online games increasingly attract an international audience, the complexity of content moderation has grown as hateful content makes its way across multiple languages and has a greater probability of passing through co...', 'language': 'en'}),\n",
       " Document(page_content=\"Supported Languages\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to ContentGuides and ConceptsAPI ReferenceRelease NotesLLMUDashboardDocumentationPlaygroundCommunityLog InDashboardDocumentationPlaygroundCommunityLog InGuides and ConceptsAPI ReferenceRelease NotesLLMUSearchGet StartedThe Cohere PlatformIntroduction to Large Language ModelsPlayground OverviewQuickstart TutorialsGoing LiveIntegrationsLearnKey ConceptsEmbeddingsPrompt EngineeringTokensGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-pCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model MetricsMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported LanguagesRerankingReranking Best PracticesGenerating FeedbackIntroductory GuidesSemantic SearchContent ModerationEntity ExtractionText ClassificationText Classification (Classify)Text Classification (Embed)Co.summarize (Beta)Co.rerank (Beta)Responsible UseOverviewUsage GuidelinesModel LimitationsData StatementModelsSecurityEnvironmental ImpactLLM UniversityWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?Module 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language ModelsModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text RepresentationModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere's Command ModelConclusion - Text GenerationAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLPAppendix 2: Building AppsApp ExamplesSupported LanguagesA list of languages that Cohere's multilingual embedding model provides. Please note that performance may vary across languages.Suggest Edits\\nISO CodeLanguage NameafAfrikaansamAmharicarArabicasAssameseazAzerbaijanibeBelarusianbgBulgarianbnBengaliboTibetanbsBosniancaCatalancebCebuanocoCorsicancsCzechcyWelshdaDanishdeGermanelGreekenEnglisheoEsperantoesSpanishetEstonianeuBasquefaPersianfiFinnishfrFrenchfyFrisiangaIrishgdScots_gaelicglGalicianguGujaratihaHausahawHawaiianheHebrewhiHindihmnHmonghrCroatianhtHaitian_creolehuHungarianhyArmenianidIndonesianigIgboisIcelandicitItalianjaJapanesejvJavanesekaGeorgiankkKazakhkmKhmerknKannadakoKoreankuKurdishkyKyrgyzLaLatinLbLuxembourgishLoLaothianLtLithuanianLvLatvianmgMalagasymiMaorimkMacedonianmlMalayalammnMongolianmrMarathimsMalaymtMaltesemyBurmeseneNepalinlDutchnoNorwegiannyNyanjaorOriyapaPunjabiplPolishptPortugueseroRomanianruRussianrwKinyarwandasiSinhaleseskSlovakslSloveniansmSamoansnShonasoSomalisqAlbaniansrSerbianstSesothosuSundanesesvSwedishswSwahilitaTamilteTelugutgTajikthThaitkTurkmentlTagalogtrTurkishttTatarugUighurukUkrainianurUrduuzUzbekviVietnamesewoWolofxhXhosayiYiddishyoYorubazhChinesezuZuluUpdated 22 days ago \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\", metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/supported-languages', 'title': 'Supported Languages', 'description': \"A list of languages that Cohere's multilingual embedding model provides. Please note that performance may vary across languages.\", 'language': 'en'}),\n",
       " Document(page_content='Reranking\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to ContentGuides and ConceptsAPI ReferenceRelease NotesLLMUDashboardDocumentationPlaygroundCommunityLog InDashboardDocumentationPlaygroundCommunityLog InGuides and ConceptsAPI ReferenceRelease NotesLLMUSearchGet StartedThe Cohere PlatformIntroduction to Large Language ModelsPlayground OverviewQuickstart TutorialsGoing LiveIntegrationsLearnKey ConceptsEmbeddingsPrompt EngineeringTokensGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-pCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model MetricsMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported LanguagesRerankingReranking Best PracticesGenerating FeedbackIntroductory GuidesSemantic SearchContent ModerationEntity ExtractionText ClassificationText Classification (Classify)Text Classification (Embed)Co.summarize (Beta)Co.rerank (Beta)Responsible UseOverviewUsage GuidelinesModel LimitationsData StatementModelsSecurityEnvironmental ImpactLLM UniversityWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?Module 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language ModelsModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text RepresentationModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere\\'s Command ModelConclusion - Text GenerationAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLPAppendix 2: Building AppsApp ExamplesRerankingSuggest EditsHow Rerank Works\\nTraditional semantic search consists of a two-part system. An initial retrieval mechanism does an approximate sweep over a collection of documents and creates a document list. Then, a re-ranker mechanism will take this candidate document list and re-rank the elements. With Rerank, you can improve your models by re-organizing your results based on certain parameters. \\nGet Started\\nExample Request\\nPythonquery = \"What is the capital of the United States?\"\\ndocs = [\\n    \"Carson City is the capital city of the American state of Nevada. At the 2010 United States Census, Carson City had a population of 55,274.\",\\n    \"The Commonwealth of the Northern Mariana Islands is a group of islands in the Pacific Ocean that are a political division controlled by the United States. Its capital is Saipan.\",\\n    \"Charlotte Amalie is the capital and largest city of the United States Virgin Islands. It has about 20,000 people. The city is on the island of Saint Thomas.\",\\n    \"Washington, D.C. (also known as simply Washington or D.C., and officially as the District of Columbia) is the capital of the United States. It is a federal district. The President of the USA and many major national government offices are in the territory. This makes it the political center of the United States of America.\",\\n    \"Capital punishment (the death penalty) has existed in the United States since before the United States was a country. As of 2017, capital punishment is legal in 30 of the 50 states. The federal government (including the United States military) also uses capital punishment.\"]\\nresults = co.rerank(model=\"rerank-english-v2.0\", query=query, documents=docs, top_n=3)\\n\\nParameters:\\n\\ndocuments (required) - a list of JSON or string objects.\\na list of document objects to rerank - it is assumed the object has a text key.\\n\\nquery (required) - string\\nThe search query that you would like the documents to be ranked against.\\n\\nmodel (required) - two models:\\nAn english model, rerank-english-v2.0.\\nA multilingual model , rerank-multilingual-v2.0.\\n\\ntop_n (optional) - integer, default is the length of the documents list passed in.\\nthe number of documents returned, ranked in relevance against your query.\\n\\nmax_chunks_per_doc (optional)- integer, default is 10\\nIf your document exceeds 512 tokens, this will determine the maximum number of chunks a document can be split into. For example, if your document is 6000 tokens, with the default of 10, the document will be split into 10 chunks each of 512 tokens and the last 880 tokens will be disregarded.\\n\\nreturn_documents (optional, API only) - boolean, default set as false.\\nif  true, the documents will be returned along with their associated text.\\nif false, the documents will not be returned and the response object will have {index, relevance_score} where index is the document order.🚧In the SDK, documents are always returned, and return_documents is not a valid parameter.\\n\\n\\nExample Response\\nJSX{\\n    \"id\":\"0ded10ab-3326-41e3-aed3-241220ce5fc4\",\\n    \"results\":[\\n    {\\n      \"document\":\\n      {\\n        \"text\":\"Washington, D.C. (also known as simply Washington or D.C., and officially as the District of Columbia) is the capital of the United States. It is a federal district. The President of the USA and many major national government offices are in the territory. This makes it the political center of the United States of America.\"\\n      },\\n      \"index\":3,\\n      \"relevance_score\":0.9871293\\n    },\\n    {\\n      \"document\":\\n      {\\n        \"text\":\"The Commonwealth of the Northern Mariana Islands is a group of islands in the Pacific Ocean that are a political division controlled by the United States. Its capital is Saipan.\"\\n      },\\n      \"index\":1,\\n      \"relevance_score\":0.29961726\\n    },\\n    {\\n      \"document\":\\n      {\\n        \"text\":\"Carson City is the capital city of the American state of Nevada. At the 2010 United States Census, Carson City had a population of 55,274.\"\\n      },\\n      \"index\":0,\\n      \"relevance_score\":0.08977329\\n    },\\n    {\\n      \"document\":\\n      {\\n        \"text\":\"Charlotte Amalie is the capital and largest city of the United States Virgin Islands. It has about 20,000 people. The city is on the island of Saint Thomas.\"\\n      },\\n      \"index\":2,\\n      \"relevance_score\":0.041462272\\n    }\\n  ],\\n    \"meta\":{\"api_version\":{\"version\":\"2022-12-06\"}}}\\n\\nMultilingual Reranking\\n Cohere offers a multilingual model,  rerank-multilingual-v2.0 . The model is trained on the following languages:\\nJSXEnglish, Chinese, French, German, Indonesian, Italian, Portuguese, Russian, Spanish, Arabic, Dutch, Hindi, Japanese, Vietnamese   \\nUpdated 22 days ago Table of Contents\\n\\nHow Rerank Works\\n\\n\\nGet Started\\n\\nExample Request\\nParameters:\\nExample Response\\n\\n\\n\\nMultilingual Reranking\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n', metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/reranking', 'title': 'Reranking', 'description': 'Traditional semantic search consists of a two-part system. An initial retrieval mechanism does an approximate sweep over a collection of documents and creates a document list. Then, a re-ranker mechanism will take this candidate document list and re-rank the elements. With Rerank, you can improve yo...', 'language': 'en'}),\n",
       " Document(page_content=\"Reranking Best Practices\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to ContentGuides and ConceptsAPI ReferenceRelease NotesLLMUDashboardDocumentationPlaygroundCommunityLog InDashboardDocumentationPlaygroundCommunityLog InGuides and ConceptsAPI ReferenceRelease NotesLLMUSearchGet StartedThe Cohere PlatformIntroduction to Large Language ModelsPlayground OverviewQuickstart TutorialsGoing LiveIntegrationsLearnKey ConceptsEmbeddingsPrompt EngineeringTokensGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-pCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model MetricsMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported LanguagesRerankingReranking Best PracticesGenerating FeedbackIntroductory GuidesSemantic SearchContent ModerationEntity ExtractionText ClassificationText Classification (Classify)Text Classification (Embed)Co.summarize (Beta)Co.rerank (Beta)Responsible UseOverviewUsage GuidelinesModel LimitationsData StatementModelsSecurityEnvironmental ImpactLLM UniversityWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?Module 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language ModelsModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text RepresentationModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere's Command ModelConclusion - Text GenerationAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLPAppendix 2: Building AppsApp ExamplesReranking Best PracticesSuggest EditsOptimizing Performance\\nCohere recommends the following tips for optimal endpoint performance:\\nConstraintMinimumMaximumNumber of Documents11000Number of Tokens per Document1N/A (see below for more info)Number of Tokens per Query1256\\nDocument Chunking\\nCohere breaks documents into 510 token chunks. For example, if your query is 50 tokens and your document is 1024 tokens, your document will be broken into the following chunks: \\n\\nrelevance_score_1 = <query[0,50], document[0,460]\\nrelevance_score_2 = <query[0,50], document[460,920]\\nrelevance_score_3 = <query[0,50],document[920,1024]\\nrelevance_score = max(relevance_score_1, relevance_score_2, relevance_score_3)\\n\\nIf you would like more control over how chunking is done, we recommend that you chunk your documents yourself.\\nMax Number of Documents\\nBy default, the endpoint will error if the user tries to pass more than 1000 documents at a time because max_chunks_per_doc has a default of 10. The way we calculate the maximum number of documents that can be passed to the endpoint is the following: len(documents) * max_chunks_per_doc >10,000 then endpoint will return an error. \\nQueries\\nOur models are trained with a context length of 510 tokens - the model takes into account both the input from the query and document. If your query is larger than 256 tokens, it will be truncated to the first 256 tokens. \\nInterpreting Results\\nThe most important output from co.rerank() is the absolute rank that is exposed in the response object. The score is query dependent and could be higher or lower depending on the query and passages sent in.  In the example below, what matters is that Ottawa is more relevant than Toronto, but the user should not assume that Ottawa is two times more relevant than Toronto.\\nPython[ \\n    RerankResult<text: Ottawa, index: 1, relevance_score: 0.9109375>, \\n    RerankResult<text: Toronto, index: 2, relevance_score: 0.7128906>, \\n  RerankResult<text: Ontario, index: 3, relevance_score: 0.04421997>\\n]\\n\\nRelevance scores are normalized to be in [0, 1]. Scores close to 1 indicate a high relevance to the query, and scores closer to zero indicate low relevance. To find a threshold on the scores to determine whether a document is relevant or not, we recommend going through the following process:\\n\\nSelect a set of 30-50 representative queries Q=[q_0, … q_n] from your domain.\\nFor each query provide a document that is considered borderline relevant to the query for your specific use case, and create a list of (query, document) pairs sample_inputs=[(q_0, d_0), …, (q_n, d_n)] .\\nPass all tuples in sample_inputs through the rerank endpoint in a loop, and gather relevance scores sample_scores=[s0, ..., s_n] .\\n\\nThe average of sample_scores can then be used as a reference when deciding a threshold for filtering out irrelevant documents.Updated about 6 hours ago Table of Contents\\n\\nOptimizing Performance\\n\\nDocument Chunking\\nMax Number of Documents\\nQueries\\n\\n\\n\\nInterpreting Results\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\", metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/reranking-best-practices', 'title': 'Reranking Best Practices', 'description': \"Get the best performance from Cohere's endpoints with these tips and tools.\", 'language': 'en'}),\n",
       " Document(page_content='Generating Feedback\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to ContentGuides and ConceptsAPI ReferenceRelease NotesLLMUDashboardDocumentationPlaygroundCommunityLog InDashboardDocumentationPlaygroundCommunityLog InGuides and ConceptsAPI ReferenceRelease NotesLLMUSearchGet StartedThe Cohere PlatformIntroduction to Large Language ModelsPlayground OverviewQuickstart TutorialsGoing LiveIntegrationsLearnKey ConceptsEmbeddingsPrompt EngineeringTokensGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-pCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model MetricsMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported LanguagesRerankingReranking Best PracticesGenerating FeedbackIntroductory GuidesSemantic SearchContent ModerationEntity ExtractionText ClassificationText Classification (Classify)Text Classification (Embed)Co.summarize (Beta)Co.rerank (Beta)Responsible UseOverviewUsage GuidelinesModel LimitationsData StatementModelsSecurityEnvironmental ImpactLLM UniversityWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?Module 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language ModelsModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text RepresentationModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere\\'s Command ModelConclusion - Text GenerationAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLPAppendix 2: Building AppsApp ExamplesGenerating FeedbackSuggest EditsCo.feedback allows users to provide feedback on responses created from Co.Generate. This feedback is used to improve the model. The endpoint can generate preference and performance feedback. This guide provides a starting point for using the endpoint.\\nYou can see a live example of Co.feedback on our playground.\\n\\nOr, you can read below to learn how to call the feedback endpoint with our API.\\n\\nGenerate Feedback\\nYou can produced detailed feedback based on the annotator\\'s acceptance of the generated response using the generate_feedback endpoint. \\nParameters\\nThe endpoint has a number of settings you can use to control the kind of output it generates:\\n\\nrequest_id (String, required): The request_id of the generation request to give feedback on.\\ngood_response (Boolean, required): Whether the response was good or not.\\nmodel (String): The unique ID of the model.\\ndesired_response (String): The desired response. Used when an annotator edits a suggested response.\\nflagged_response (Boolean): Whether the response was flagged or not.\\nflagged_reason (String):  The reason the response was flagged.\\nprompt (String): The original prompt used to generate the response.\\nannotator_id (String): The annotator\\'s ID.\\n\\nExample Requests\\nIf the annotator accepts the suggested response, you could format a request like this:\\nPythongenerations = co.generate(f\"Write me a polite email responding to the one below: {email}. Response:\")\\nif user_accepted_suggestion:\\n    co.generate_feedback(request_id=generations[0].id, good_response=True)\\n\\nIf the annotator edits the suggested response, you could format a request like this:\\nPythongenerations = co.generate(f\"Write me a polite email responding to the one below: {email}. Response:\")\\nif user_edits_suggestion:\\n    co.generate_feedback(request_id=generations[0].id, good_response=False, desired_response=user_edited_suggestion)\\n\\nExample Response\\nGenerate Preference Feedback\\nAlternatively, you can generate feedback based on which response an annotator prefers with the generate_preference_feedback endpoint.\\nParameters\\n\\nratings (List[PreferenceRating], required): A list of PreferenceRating objects.\\nmodel (String):  The unique ID of the model.\\nprompt (String): The original prompt used to generate the response.\\nannotator_id (String):  The annotator\\'s ID.\\n\\nExample Request\\nA user accepts a model\\'s suggestion in an assisted writing setting, and prefers it to a second suggestion, a request might look like this:\\nPythongenerations = co.generate(f\"Write me a polite email responding to the one below: {email}. Response:\", num_generations=2)  \\n         if user_accepted_idx: # prompt user for which generation they prefer  \\n               ratings = \\\\[]  \\n              if user_accepted_idx == 0:  \\n                   ratings.append(PreferenceRating(request_id=0, rating=1))  \\n                   ratings.append(PreferenceRating(request_id=1, rating=0))  \\n              else:  \\n                   ratings.append(PreferenceRating(request_id=0, rating=0))  \\n                   ratings.append(PreferenceRating(request_id=1, rating=1))  \\n                            co.generate_preference_feedback(ratings=ratings)\\nUpdated 8 days ago Table of Contents\\n\\nGenerate Feedback\\n\\nParameters\\nExample Requests\\nExample Response\\n\\n\\n\\nGenerate Preference Feedback\\n\\nParameters\\nExample Request\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n', metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/feedback', 'title': 'Generating Feedback', 'description': 'Co.feedback allows users to provide feedback on responses created from Co.Generate. This feedback is used to improve the model. The endpoint can generate preference and performance feedback. This guide provides a starting point for using the endpoint.You can see a live example of Co.feedback on our ...', 'language': 'en'}),\n",
       " Document(page_content='Semantic Search\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to ContentGuides and ConceptsAPI ReferenceRelease NotesLLMUDashboardDocumentationPlaygroundCommunityLog InDashboardDocumentationPlaygroundCommunityLog InGuides and ConceptsAPI ReferenceRelease NotesLLMUSearchGet StartedThe Cohere PlatformIntroduction to Large Language ModelsPlayground OverviewQuickstart TutorialsGoing LiveIntegrationsLearnKey ConceptsEmbeddingsPrompt EngineeringTokensGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-pCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model MetricsMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported LanguagesRerankingReranking Best PracticesGenerating FeedbackIntroductory GuidesSemantic SearchContent ModerationEntity ExtractionText ClassificationText Classification (Classify)Text Classification (Embed)Co.summarize (Beta)Co.rerank (Beta)Responsible UseOverviewUsage GuidelinesModel LimitationsData StatementModelsSecurityEnvironmental ImpactLLM UniversityWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?Module 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language ModelsModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text RepresentationModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere\\'s Command ModelConclusion - Text GenerationAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLPAppendix 2: Building AppsApp ExamplesSemantic SearchSuggest Edits📘This Guide Uses the Embed Endpoint.You can find more information about the endpoint here.\\nLanguage models give computers the ability to search by meaning and go beyond searching by matching keywords. This capability is called semantic search.\\n\\nIn this article, we\\'ll build a simple semantic search engine. The applications of semantic search go beyond building a web search engine. They can empower a private search engine for internal documents or records. It can be used to power features like StackOverflow\\'s \"similar questions\" feature.\\nYou can find the code in the notebook and colab.\\nContents\\nGet the archive of questions\\nEmbed the archive\\nSearch using an index and nearest neighbour search\\nVisualize the archive based on the embeddings.\\n📘New to Cohere?Get Started now and get unprecedented access to world-class Generation and\\nRepresentation models with billions of parameters.\\n1. Download the Dependencies\\nPYT# Install Cohere for embeddings, Umap to reduce embeddings to 2 dimensions, \\n# Altair for visualization, Annoy for approximate nearest neighbor search\\n!pip install cohere umap-learn altair annoy datasets tqdm\\n\\n1a. Import the Necessary Dependencies to Run this Example\\nPYTHON#title Import libraries (Run this cell to execute required code) {display-mode: \"form\"}\\n\\nimport cohere\\nimport numpy as np\\nimport re\\nimport pandas as pd\\nfrom tqdm import tqdm\\nfrom datasets import load_dataset\\nimport umap\\nimport altair as alt\\nfrom sklearn.metrics.pairwise import cosine_similarity\\nfrom annoy import AnnoyIndex\\nimport warnings\\nwarnings.filterwarnings(\\'ignore\\')\\npd.set_option(\\'display.max_colwidth\\', None)\\n\\n2. Get the Archive of Questions\\nWe\\'ll use the trec dataset which is made up of questions and their categories.\\nPYTHON# Get dataset\\ndataset = load_dataset(\"trec\", split=\"train\")\\n# Import into a pandas dataframe, take only the first 1000 rows\\ndf = pd.DataFrame(dataset)[:1000]\\n# Preview the data to ensure it has loaded correctly\\ndf.head(10)\\n\\nlabel-coarselabel-finetext000How did serfdom develop in and then leave Russia ?111What films featured the character Popeye Doyle ?222How can I find a list of celebrities \\' real names ?333What fowl grabs the spotlight after the Chinese Year of the Monkey ?444What is the full form of .com ?555What contemptible scoundrel stole the cork from my lunch ?666What team did baseball \\'s St. Louis Browns become ?777What is the oldest profession ?888What are liver enzymes ?999Name the scar-faced bounty hunter of The Old West .\\n3. Embed the Archive\\n\\nLet\\'s now embed the text of the questions.\\nTo get a thousand embeddings of this length should take a few seconds.\\nPYTHON# Paste your API key here. Remember to not share publicly\\napi_key = \\'\\'\\n\\n# Create and retrieve a Cohere API key from dashboard.cohere.ai/welcome/register\\nco = cohere.Client(api_key)\\n\\n# Get the embeddings\\nembeds = co.embed(texts=list(df[\\'text\\']),\\n                  model=\\'embed-english-v2.0\\').embeddings\\n\\n4. Build the Index, search Using an Index and Conduct Nearest Neighbour Search\\n\\nLet\\'s build an index using the library called annoy. Annoy is an library created by Spotify to do nearest neighbour search; nearest neighbour search is an optimization problem of finding the point in a given set that is closest (or most similar) to a given point.\\nPYTHON# Create the search index, pass the size of embedding\\nsearch_index = AnnoyIndex(np.array(embeds).shape[1], \\'angular\\')\\n# Add all the vectors to the search index\\nfor i in range(len(embeds)):\\n    search_index.add_item(i, embeds[i])\\nsearch_index.build(10) # 10 trees\\nsearch_index.save(\\'test.ann\\')\\n\\nAfter building the index, we can use it to retrieve the nearest neighbours either of existing questions (section 3.1), or of new questions that we embed (section 3.2).\\n4a. Find the Neighbours of an Example from the Dataset\\nIf we\\'re only interested in measuring the similarities between the questions in the dataset (no outside queries), a simple way is to calculate the similarities between every pair of embeddings we have.\\nPYTHON# Choose an example (we\\'ll retrieve others similar to it)\\nexample_id = 92\\n# Retrieve nearest neighbors\\nsimilar_item_ids = search_index.get_nns_by_item(example_id,10,\\n                                                include_distances=True)\\n# Format and print the text and distances\\nresults = pd.DataFrame(data={\\'texts\\': df.iloc[similar_item_ids[0]][\\'text\\'],\\n                             \\'distance\\': similar_item_ids[1]}).drop(example_id)\\nprint(f\"Question:\\'{df.iloc[example_id][\\'text\\']}\\'\\\\nNearest neighbors:\")\\nresults\\n\\n# Output:\\nQuestion:\\'What are bear and bull markets ?\\'\\nNearest neighbors:\\n\\ntextsdistance614What animals do you find in the stock market ?0.896121137What are equity securities ?0.970260601What is `` the bear of beers \\'\\' ?0.978348307What does NASDAQ stand for ?0.997819683What is the rarest coin ?1.027727112What are the world \\'s four oceans ?1.049661864When did the Dow first reach ?1.050362547Where can stocks be traded on-line ?1.053685871What are the Benelux countries ?1.054899\\n4b. Find the Neighbours of a User Query\\nWe\\'re not limited to searching using existing items. If we get a query, we can embed it and find its nearest neighbours from the dataset.\\nPYTHONquery = \"What is the tallest mountain in the world?\"\\n\\n# Get the query\\'s embedding\\nquery_embed = co.embed(texts=[query],\\n                  model=\"embed-english-v2.0\").embeddings\\n\\n# Retrieve the nearest neighbors\\nsimilar_item_ids = search_index.get_nns_by_vector(query_embed[0],10,\\n                                                include_distances=True)\\n# Format the results\\nresults = pd.DataFrame(data={\\'texts\\': df.iloc[similar_item_ids[0]][\\'text\\'], \\n                             \\'distance\\': similar_item_ids[1]})\\n\\n\\nprint(f\"Query:\\'{query}\\'\\\\nNearest neighbors:\")\\nresults\\n\\ntextsdistance236What is the name of the tallest mountain in the world ?0.431913670What is the highest mountain in the world ?0.436290907What mountain range is traversed by the highest railroad in the world ?0.715265435What is the highest peak in Africa ?0.717943354What ocean is the largest in the world ?0.762917412What was the highest mountain on earth before Mount Everest was discovered ?0.767649109Where is the highest point in Japan ?0.784319114What is the largest snake in the world ?0.789743656What \\'s the tallest building in New York City ?0.793982901What \\'s the longest river in the world ?0.794352\\n5. Visualize the Archive\\nPYTHON#@title Plot the archive {display-mode: \"form\"}\\n\\n# UMAP reduces the dimensions from 1024 to 2 dimensions that we can plot\\nreducer = umap.UMAP(n_neighbors=20) \\numap_embeds = reducer.fit_transform(embeds)\\n# Prepare the data to plot and interactive visualization\\n# using Altair\\ndf_explore = pd.DataFrame(data={\\'text\\': df[\\'text\\']})\\ndf_explore[\\'x\\'] = umap_embeds[:,0]\\ndf_explore[\\'y\\'] = umap_embeds[:,1]\\n\\n# Plot\\nchart = alt.Chart(df_explore).mark_circle(size=60).encode(\\n    x=#\\'x\\',\\n    alt.X(\\'x\\',\\n        scale=alt.Scale(zero=False)\\n    ),\\n    y=\\n    alt.Y(\\'y\\',\\n        scale=alt.Scale(zero=False)\\n    ),\\n    tooltip=[\\'text\\']\\n).properties(\\n    width=700,\\n    height=400\\n)\\nchart.interactive()\\n\\nCreate the graph locally and hover over the points to read the text. Do you see some of the patterns in clustered points? Similar questions, or questions asking about similar topics?\\nThis concludes this introductory guide to semantic search using sentence embeddings. As you continue the path of building a search product additional considerations arise (like dealing with long texts, or training to better improve the embeddings for a specific use case).\\nWe can’t wait to see what you start building! Share your projects or find support on our community discord.Updated about 1 month ago Table of Contents\\n\\nContents\\n\\n\\n1. Download the Dependencies\\n\\n1a. Import the Necessary Dependencies to Run this Example\\n\\n\\n\\n2. Get the Archive of Questions\\n\\n\\n3. Embed the Archive\\n\\n\\n4. Build the Index, search Using an Index and Conduct Nearest Neighbour Search\\n\\n4a. Find the Neighbours of an Example from the Dataset\\n4b. Find the Neighbours of a User Query\\n\\n\\n\\n5. Visualize the Archive\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n', metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/semantic-search', 'title': 'Semantic Search', 'description': \"📘This Guide Uses the Embed Endpoint.You can find more information about the endpoint here.Language models give computers the ability to search by meaning and go beyond searching by matching keywords. This capability is called semantic search. In this article, we'll build a simple semantic search en...\", 'language': 'en'}),\n",
       " Document(page_content='Content Moderation\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to ContentGuides and ConceptsAPI ReferenceRelease NotesLLMUDashboardDocumentationPlaygroundCommunityLog InDashboardDocumentationPlaygroundCommunityLog InGuides and ConceptsAPI ReferenceRelease NotesLLMUSearchGet StartedThe Cohere PlatformIntroduction to Large Language ModelsPlayground OverviewQuickstart TutorialsGoing LiveIntegrationsLearnKey ConceptsEmbeddingsPrompt EngineeringTokensGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-pCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model MetricsMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported LanguagesRerankingReranking Best PracticesGenerating FeedbackIntroductory GuidesSemantic SearchContent ModerationEntity ExtractionText ClassificationText Classification (Classify)Text Classification (Embed)Co.summarize (Beta)Co.rerank (Beta)Responsible UseOverviewUsage GuidelinesModel LimitationsData StatementModelsSecurityEnvironmental ImpactLLM UniversityWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?Module 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language ModelsModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text RepresentationModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere\\'s Command ModelConclusion - Text GenerationAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLPAppendix 2: Building AppsApp ExamplesContent ModerationSuggest Edits📘This Guide Uses the Classify Endpoint.You can find more information about the endpoint here.\\nThe Classify endpoint streamlines the task of running a text classification task. Via a single endpoint, you can deploy different kinds of content moderation use cases according to your needs.\\nAs online communities continue to grow, content moderators need a way to  moderate user-generated content at scale. To appreciate the wide-ranging need for content moderation, we can refer to the paper A Unified Typology of Harmful Content by Banko et al. [Source]. It provides a unified typology of harmful content generated within online communities and a comprehensive list of examples, which can be grouped into four types:\\n\\nHate and Harassment\\nSelf-Inflicted Harm\\nIdeological Harm\\nExploitation\\n\\nThere are publicly available datasets within the content moderation space which you can experiment with, for example:\\n\\nSocial Media Toxicity dataset from Surge AI\\nWikipedia Comments dataset by Jigsaw/Conversation AI\\nCivil Comments dataset by Jigsaw/Conversation AI\\nHate Speech Dataset by Derczynski et al.\\n\\n\\nA Quick Walkthrough\\nHere we take a quick look at performing a toxicity detection using the Classify endpoint of the Cohere API. In this example, our task is to classify a list of example social media comments as either toxic or benign.\\n\\nLLMs work by conditioning it with some examples of what we want its outputs to look like. In our case, we’ll provide a few examples of labeled data, whereby each data point contains the text online comment and the associated toxicity label. Then we feed the model with the inputs we want to classify and the model will return the predicted class it belongs to.\\nWe’ll use the Cohere Playground, which is an interface that helps you quickly prototype and experiment with LLMs.\\nFirst, we choose the model we want to use and enter the labeled examples. The model will work fine with as few as 5 examples per class, but in general, the more data, the better. In this example, we’ll provide 5 examples for each class: toxic and benign.\\n\\nHere’s a better look at all ten examples:\\nNumberTextLabel1yo how are youbenign2PUDGE MID!benign3I WILL REMEMBER THIS FOREVERbenign4I think I saw it firstbenign5bring me a potionbenign6I will honestly kill youtoxic7get rekt morontoxic8go to helltoxic9f  a g o ttoxic10you are hot trashtoxic\\nNext we enter the list of inputs we want to classify and run the classification. Here we have 5 inputs.\\n\\nHere’s a better look at all five inputs and outcomes:\\nNumberTextLabel (Actual)Label (Predicted)1this game sucks, you sucktoxictoxic2put your neck in a noosetoxictoxic3buy the black potionbenignbenign4top miabenignbenign5good work teambenignbenign\\nIn this small example, the model got all classifications correct. We can then generate the equivalent code to access the Classify endpoint by exporting the code from the Playground.\\n\\nThe following is the corresponding code snippet for the API call. From here, we can further build the content moderation solution according to the scale and integration needs.\\nPythonJavaScriptGocURLimport cohere\\nfrom cohere.classify import Example\\nco = cohere.Client(\\'{apiKey}\\')\\nresponse = co.classify(\\n  model=\\'base\\',\\n  inputs=[\"this game sucks, you suck\", \"put your neck in a noose\", \"buy the black potion\", \"top mia\", \"good work team\"],\\n  examples=[Example(\"yo how are you\", \"benign\"), Example(\"PUDGE MID!\", \"benign\"), Example(\"I WILL REMEMBER THIS FOREVER\", \"benign\"), Example(\"I think I saw it first\", \"benign\"), Example(\"bring me a potion\", \"benign\"), Example(\"I will honestly kill you\", \"toxic\"), Example(\"get rekt moron\", \"toxic\"), Example(\"go to hell\", \"toxic\"), Example(\"f*a*g*o*t\", \"toxic\"), Example(\"you are hot trash\", \"toxic\")])\\nprint(\\'The confidence levels of the labels are: {}\\'.format(response.classifications))\\nconst cohere = require(\\'cohere-ai\\');\\ncohere.init(\\'{apiKey}\\');\\n(async () => {\\n  const response = await cohere.classify({\\n    model: \\'small\\',\\n    inputs: [\"this game sucks, you suck\", \"you f*g*t\", \"put your neck in a noose\", \"buy the black potion\", \"top mia\", \"good work team\"],\\n    examples: [{\"text\": \"yo how are you\", \"label\": \"benign\"}, {\"text\": \"PUDGE MID!\", \"label\": \"benign\"}, {\"text\": \"I WILL REMEMBER THIS FOREVER\", \"label\": \"benign\"}, {\"text\": \"I think I saw it first\", \"label\": \"benign\"}, {\"text\": \"bring me a potion\", \"label\": \"benign\"}, {\"text\": \"I will honestly kill you\", \"label\": \"toxic\"}, {\"text\": \"get rekt moron\", \"label\": \"toxic\"}, {\"text\": \"go to hell\", \"label\": \"toxic\"}, {\"text\": \"f*a*g*o*t\", \"label\": \"toxic\"}, {\"text\": \"you are hot trash\", \"label\": \"toxic\"}]\\n  });\\n  console.log(`The confidence levels of the labels are ${JSON.stringify(response.body.classifications)}`);\\n})();\\npackage main\\n\\nimport (\\n  \"fmt\"\\n\\n  cohere \"github.com/cohere-ai/cohere-go\"\\n)\\n\\nfunc main() {\\n  co, err := cohere.CreateClient(\"{apiKey}\")\\n  if err != nil {\\n    fmt.Println(err)\\n    return\\n  }\\n\\n  response, err := co.Classify(cohere.ClassifyOptions{\\n    Model:           \"small\",\\n    Inputs:          []string{`this game sucks, you suck`, `you f*g*t`, `put your neck in a noose`, `buy the black potion`, `top mia`, `good work team`},\\n    Examples:        []cohere.Example{{Text: `yo how are you`, Label: `benign`}, {Text: `PUDGE MID!`, Label: `benign`}, {Text: `I WILL REMEMBER THIS FOREVER`, Label: `benign`}, {Text: `I think I saw it first`, Label: `benign`}, {Text: `bring me a potion`, Label: `benign`}, {Text: `I will honestly kill you`, Label: `toxic`}, {Text: `get rekt moron`, Label: `toxic`}, {Text: `go to hell`, Label: `toxic`}, {Text: `f*a*g*o*t`, Label: `toxic`}, {Text: `you are hot trash`, Label: `toxic`}},\\n  })\\n  if err != nil {\\n    fmt.Println(err)\\n    return\\n  }\\n\\n  fmt.Println(\"The confidence levels of the labels are:\", response.Classifications)\\n}\\ncurl --location --request POST \\'https://api.cohere.ai/classify\\' \\\\\\n  --header \\'Authorization: BEARER {apiKey}\\' \\\\\\n  --header \\'Content-Type: application/json\\' \\\\\\n  --data-raw \\'{\\n    \"model\": \"small\",\\n    \"inputs\": [\"this game sucks, you suck\", \"you f*g*t\", \"put your neck in a noose\", \"buy the black potion\", \"top mia\", \"good work team\"],\\n    \"examples\": [{\"text\": \"yo how are you\", \"label\": \"benign\"}, {\"text\": \"PUDGE MID!\", \"label\": \"benign\"}, {\"text\": \"I WILL REMEMBER THIS FOREVER\", \"label\": \"benign\"}, {\"text\": \"I think I saw it first\", \"label\": \"benign\"}, {\"text\": \"bring me a potion\", \"label\": \"benign\"}, {\"text\": \"I will honestly kill you\", \"label\": \"toxic\"}, {\"text\": \"get rekt moron\", \"label\": \"toxic\"}, {\"text\": \"go to hell\", \"label\": \"toxic\"}, {\"text\": \"f*a*g*o*t\", \"label\": \"toxic\"}, {\"text\": \"you are hot trash\", \"label\": \"toxic\"}]\\n  }\\'\\n\\nNext Steps\\nTo get the best classification performance, you will likely need to perform custom training, which is a method for customizing an LLM model with your own dataset. This is especially true for a content moderation task, where no two communities are the same and where the nature of the content is always evolving. The model will need to capture the nuances of the content within a given community at a given time, and custom model training is a way to do that.\\nThe Cohere platform lets you train a model using a dataset you provide. Refer to this article for a step-by-step guide.\\nIn summary, Cohere’s LLM API empowers developers to build content moderation systems at scale without having to worry about building and deploying machine learning models in-house. In particular, teams can perform text classification tasks via the Classify endpoint. Try it now!Updated 22 days ago Table of Contents\\nA Quick Walkthrough\\nNext Steps\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n', metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/content-moderation-with-classify', 'title': 'Content Moderation', 'description': 'Use the API to generate completions, distill text into semantically meaningful vectors, and more. Get state-of-the-art natural language processing without the need for expensive supercomputing infrastructure.', 'language': 'en'}),\n",
       " Document(page_content='Entity Extraction\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to ContentGuides and ConceptsAPI ReferenceRelease NotesLLMUDashboardDocumentationPlaygroundCommunityLog InDashboardDocumentationPlaygroundCommunityLog InGuides and ConceptsAPI ReferenceRelease NotesLLMUSearchGet StartedThe Cohere PlatformIntroduction to Large Language ModelsPlayground OverviewQuickstart TutorialsGoing LiveIntegrationsLearnKey ConceptsEmbeddingsPrompt EngineeringTokensGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-pCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model MetricsMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported LanguagesRerankingReranking Best PracticesGenerating FeedbackIntroductory GuidesSemantic SearchContent ModerationEntity ExtractionText ClassificationText Classification (Classify)Text Classification (Embed)Co.summarize (Beta)Co.rerank (Beta)Responsible UseOverviewUsage GuidelinesModel LimitationsData StatementModelsSecurityEnvironmental ImpactLLM UniversityWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?Module 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language ModelsModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text RepresentationModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere\\'s Command ModelConclusion - Text GenerationAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLPAppendix 2: Building AppsApp ExamplesEntity ExtractionSuggest Edits📘This Guide Uses the Generate Endpoint.You can find more information about the endpoint here.\\nExtracting a piece of information from text is a common need in language processing systems. LLMs can at times extract entities which are harder to extract using other NLP methods (and where pre-training provides the model with some context on these entities). This is an overview of using generative LLMs to extract entities.\\n\\nExtracting movie names from text\\nThis example uses Cohere\\'s generative models to extract the name of a film from the title of an article. We\\'ll use post titles from the r/Movies subreddit. For each title, we\\'ll extract which movie the post is about. If the model is unable to detect the name of a movie being mentioned, it will return \"none\".\\nThe full code example is in the notebook and colab\\nPreparing examples for the prompt\\nIn our prompt, we\\'ll present the model with examples for the type of output we\\'re after. We basically get a set of subreddit article titles, and label them ourselves. The label here is the name of the movie mentioned in the title (and \"none\" if no movie is mentioned).\\n\\nCreating the extraction prompt\\nWe\\'ll create a prompt that demonstrates the task to the model. The prompt contains the examples above, and then presents the input text and asks the model to extract the movie name.\\n\\nSo let\\'s get a few example titles from the movies subreddit, label them, and make an extraction prompt out of them:\\n\\n\\nDeadpool 2 | Official HD Deadpool\\'s \"Wet on Wet\" Teaser | 2018 \\n\\n    extract the movie title from the post: Deadpool 2 \\n    --- \\n\\n      Jordan Peele Just Became the First Black Writer-Director With a $100M Movie Debut\\n    \\n\\n    extract the movie title from the post: none \\n    --- \\nJoker Officially Rated “R” \\n\\n    extract the movie title from the post: Joker \\n    --- \\n\\n      Ryan Reynolds’ \\'Free Guy\\' Receives July 3, 2020 Release Date - About a bank teller stuck in his routine that\\n      discovers he’s an NPC character in brutal open world game.\\n    \\n\\n    extract the movie title from the post: Free Guy \\n    --- \\nJames Cameron congratulates Kevin Feige and Marvel! \\n\\n    extract the movie title from the post: none \\n    --- \\nThe Cast of Guardians of the Galaxy release statement on James Gunn \\n\\n    extract the movie title from the post: Guardians of the Galaxy \\n    --- \\nINSERT INPUT TEXT HERE\\n\\n    extract the movie title from the post:\\n  \\n\\n\\nLet\\'s point out a few ideas in this prompt:\\n\\nThe prompt is made up of six examples that demonstrate the task to the model before it encounters the input text we want to extract text from\\nEach example demonstrates the task by showing an example input text and an example output text. Between the two is a task description explaining in what needs to be done (e.g. \"extract the movie title from the post:\")\\nThe notebook provides a class that constructs the prompt and makes the string manipulation easier.\\nSee prompt engineering for more details on creating prompts.\\n\\nGetting the data\\nLet\\'s get the top ten posts in r/movies of 2021. We can preview the top three:\\n\\nHayao Miyazaki Got So Bored with Retirement He Started Directing Again ‘in Order to Live’,\\nFirst poster for Pixar\\'s Luca,\\nNew images from Space Jam: A New Legacy\\'\\n\\nWe can then proceed with the extraction. We basically plug each post title into the input text part of the prompt, and retrieve the output of the model.\\nThese are the model\\'s results:\\n\\n\\n\\n\\ntext\\nextracted_text\\n\\n\\n\\n\\n0\\nHayao Miyazaki Got So Bored with Retirement He Started Directing Again ‘in Order to Live’\\nnone\\n\\n\\n1\\nFirst poster for Pixar\\'s Luca\\nPixar\\'s Luca\\n\\n\\n2\\nNew images from Space Jam: A New Legacy\\nSpace Jam: A New Legacy\\n\\n\\n3\\nOfficial Poster for \"Sonic the Hedgehog 2\"\\nSonic the Hedgehog 2\\n\\n\\n4\\n\\n        Ng Man Tat, legendary HK actor and frequent collborator of Stephen Chow (Shaolin Soccer, God of Gambler) died at\\n        70\\n      \\nnone\\n\\n\\n5\\nZack Snyder’s Justice League has officially been Rated R for for violence and some language\\nJustice League\\n\\n\\n6\\nHBOMax and Disney+ NEED to improve their apps if they want to compete with Netflix.\\nnone\\n\\n\\n7\\n\\n        I want a sequel to Rat Race where John Cleese’s character dies and invites everyone from the first film to his\\n        funeral, BUT, he’s secretly set up a Rat Maze to trap them all in. A sort of post-mortem revenge on them for\\n        donating all his wealth to charity.\\n      \\nRat Race\\n\\n\\n8\\n\\'Trainspotting\\' at 25: How an Indie Film About Heroin Became a Feel-Good Classic\\nTrainspotting\\n\\n\\n9\\n\\n        ‘Avatar: The Last Airbender’ Franchise To Expand With Launch Of Nickelodeon’s Avatar Studios, Animated\\n        Theatrical Film To Start Production Later This Year\\n      \\nAvatar: The Last Airbender\\n\\n\\n\\nThe model got 9/10 correctly. It didn\\'t pick up on Shaolin Soccer and God of Gambler in example #4. It also called the second example \"Pixar\\'s Luca\" instead of \"Luca\".\\nSummary\\nFind the full code in the notebook/colab. It proceeds to evaluate performance on a small test set.\\nThis type of extraction is interesting because it doesn\\'t just blindly look at the text. The model has picked up on movie information during its pretraining process and that helps it understand the task from only a few examples.\\nYou can think about extending this to other subreddits, to extract other kinds of entities and information. Join our Discord Community to share ideas and ask questions about NLP and ML and let us know what you are experimenting with and what kind of results you see! \\nHappy building!Updated 22 days ago Table of Contents\\nExtracting movie names from text\\nPreparing examples for the prompt\\nCreating the extraction prompt\\nGetting the data\\nSummary\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n', metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/entity-extraction', 'title': 'Entity Extraction', 'description': 'Use the API to generate completions, distill text into semantically meaningful vectors, and more. Get state-of-the-art natural language processing without the need for expensive supercomputing infrastructure.', 'language': 'en'}),\n",
       " Document(page_content='Text Classification (Classify)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to ContentGuides and ConceptsAPI ReferenceRelease NotesLLMUDashboardDocumentationPlaygroundCommunityLog InDashboardDocumentationPlaygroundCommunityLog InGuides and ConceptsAPI ReferenceRelease NotesLLMUSearchGet StartedThe Cohere PlatformIntroduction to Large Language ModelsPlayground OverviewQuickstart TutorialsGoing LiveIntegrationsLearnKey ConceptsEmbeddingsPrompt EngineeringTokensGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-pCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model MetricsMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported LanguagesRerankingReranking Best PracticesGenerating FeedbackIntroductory GuidesSemantic SearchContent ModerationEntity ExtractionText ClassificationText Classification (Classify)Text Classification (Embed)Co.summarize (Beta)Co.rerank (Beta)Responsible UseOverviewUsage GuidelinesModel LimitationsData StatementModelsSecurityEnvironmental ImpactLLM UniversityWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?Module 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language ModelsModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text RepresentationModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere\\'s Command ModelConclusion - Text GenerationAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLPAppendix 2: Building AppsApp ExamplesText Classification (Classify)Suggest Edits📘This Guide Uses the Classify Endpoint.You can find more information about the endpoint here.\\nIn this section, we show how to use the Classify endpoint to do sentiment classification for customer satisfaction survey responses an e-commerce website may receive.\\n\\nThe Problem We Want to Solve\\nFor this demo, let\\'s assume that we want to classify a set of reviews for a newly released feature into positive and negative classes. We might for instance have a review like this:\\nThe item exceeded my expectations\\nthat we want to classify as a positive review.\\nNaturally, the same techniques that we\\'ll use for this problem can be used for any other task where we want to classify a given text according to a fixed set of classes.\\nUsing Classify For Our Task\\nClassify takes in example inputs with their labels, as well as the input texts we aim to classify. It then trains a classifier using the power of an embeddings model. \\nExamples\\nLabeled examples are used to demonstrate the classification task to the model so it grasps the task. Examples provide two important pieces of information:\\n1- The inputs and expected outputs for the task we\\'re interested in.\\n2- The number of output classes. Every class should appear in at least one example in the labeled examples.\\nIn this case we will be passing in the following examples: \\npy\"The order is 5 days late\" - negative\\n\"The order came 5 days early\" - positive\\n\"I would recommend this to others\" - positive\\n\"The package was damaged\" - negative\\n\"The order was incorrrect\" - negative\\n\"The item exceeded my expecatations\" - positive\\n\"I want to return my item\" - negative\\n\"I ordered more for my friends\" - positive\\n\"The item\\'s material feels low quality\" - negative\\n\\nTexts:\\nThese are the input texts that we would like to classify:\\nGo\"This item was broken when it arrived\"\\n\"This item broke after 3 weeks\"\\n\\nClassifying the Input Texts\\nAdding everything above together, we can call the API with the following arguments:\\n\\nmodel: embed-english-v2.0\\nexamples: [Example(\"The order is 5 days late\",\"negative\"), Example(\"The order came 5 days early\",\"positive\"), Example(\"I would recommend this to others\",\"positive\"), Example(\"The package was damaged\",\"negative\"), Example(\"The order was incorrect\",\"negative\"), Example(\"The item exceeded my expectations\",\"positive\"), Example(\"I want to return my item\",\"negative\"), Example(\"I ordered more for my friends\",\"positive\"), Example(\"The item\\'s material feels low quality\",\"negative\")]\\ninputs: [\"This item was broken when it arrived\",\"This item broke after 3 weeks\"]\\n\\nThe corresponding code snippet for the API call is as follows.\\nPythonimport cohere\\nfrom cohere.classify import Example\\nco = cohere.Client(\\'{apiKey}\\')\\nclassifications = co.classify(\\n  model=\\'embed-english-v2.0\\',\\n  inputs=[\"This item was broken when it arrived\", \"This item broke after 3 weeks\"],\\n  examples=[Example(\"The order came 5 days early\", \"positive\"), Example(\"The item exceeded my expectations\", \"positive\"), Example(\"I ordered more for my friends\", \"positive\"), Example(\"I would buy this again\", \"positive\"), Example(\"I would recommend this to others\", \"positive\"), Example(\"The package was damaged\", \"negative\"), Example(\"The order is 5 days late\", \"negative\"), Example(\"The order was incorrect\", \"negative\"), Example(\"I want to return my item\", \"negative\"), Example(\"The item\\\\\\'s material feels low quality\", \"negative\")])\\nprint(\\'The confidence levels of the labels are: {}\\'.format(\\n       classifications.classifications))\\n\\nIt gives us the following values:\\nGo\"results\": [\\n        {\\n            \"text\": \"This item was broken when it arrived\",\\n            \"prediction\": \"negative\",\\n            \"confidences\": [\\n                {\\n                    \"option\": \"negative\",\\n                    \"confidence\": 0.99564105\\n                },\\n                {\\n                    \"option\": \"positive\",\\n                    \"confidence\": 0.0043589203\\n                }\\n            ]\\n        },\\n        {\\n            \"text\": \"This item broke after 3 weeks\",\\n            \"prediction\": \"negative\",\\n            \"confidences\": [\\n                {\\n                    \"option\": \"negative\",\\n                    \"confidence\": 0.99564105\\n                },\\n                {\\n                    \"option\": \"positive\",\\n                    \"confidence\": 0.0043589203\\n                }\\n            ]\\n        }\\n    ]\\n\\nwhich indicates that, as we would expect, our model thinks that both texts are negative.\\n\\nThe playground has a user interface to help you set up the classification prompts, which can then be exported as code.\\nChoose Model\\nIn the Cohere Playground, click on ‘Classify’.\\nSelect the model size of your choice. Our smaller model is faster, while our larger model has a better grasp of language and are more able to capture and replicate the patterns in the input prompt.\\n\\nAdd Examples\\nAdd your labeled examples in the ‘Examples’ section. The first column is for the examples while the subsequent columns are for the associated labels. Our example here consists of 2 labels but there is no limit as to how many labels you can specify, depending on the task you have.\\nYou can also add your labeled examples using a CSV file by selecting upload your labelled examples.\\n\\nAdd at least 2 examples for each label. The more examples you have, the higher the chance of getting more accurate outcomes.\\nIf you are not sure, there are also some preset examples to help you get started.\\n\\nAdd Inputs\\nAdd the inputs you want to classify in the ‘Inputs’ section. Once done, click on ‘Classify’ to start the classification step.\\n\\nView Results\\nOnce the classification step is completed, you will see the output labels next to the inputs you added.\\nIn the ‘Results’ section, you will also see the confidence levels associated with each output. The confidence level represents the model\\'s degree of certainty that the query falls under a given label. The label with the highest confidence is chosen.\\n\\nExport Code\\nNow the code is ready to be exported. Click on ‘Export code’ and you can choose to export from a few different options. You can use this to start integrating the current API configuration to your application.\\n\\nTraining\\nYou can opt to train a model if you have a dataset of at least 250 labeled examples (500 or more for best results) with at least 5 examples per label. \\nA trained model can potentially lead to a better classification performance than a baseline model. See here  to get an overview of what model training is about.\\nTo train a model for your classification task, navigate to the models page and click on Create a custom model.\\n\\nThe subsequent steps are the same as how you would train a representation model. For this, follow the steps described here.Updated 22 days ago What’s NextContent Moderation with ClassifyTable of Contents\\n\\nThe Problem We Want to Solve\\n\\n\\nUsing Classify For Our Task\\n\\nExamples\\nTexts:\\n\\n\\n\\nClassifying the Input Texts\\n\\nChoose Model\\nAdd Examples\\nAdd Inputs\\nView Results\\nExport Code\\nTraining\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n', metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/text-classification-with-classify', 'title': 'Text Classification (Classify)', 'description': 'Use the API to generate completions, distill text into semantically meaningful vectors, and more. Get state-of-the-art natural language processing without the need for expensive supercomputing infrastructure.', 'language': 'en'}),\n",
       " Document(page_content='Text Classification (Embed)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to ContentGuides and ConceptsAPI ReferenceRelease NotesLLMUDashboardDocumentationPlaygroundCommunityLog InDashboardDocumentationPlaygroundCommunityLog InGuides and ConceptsAPI ReferenceRelease NotesLLMUSearchGet StartedThe Cohere PlatformIntroduction to Large Language ModelsPlayground OverviewQuickstart TutorialsGoing LiveIntegrationsLearnKey ConceptsEmbeddingsPrompt EngineeringTokensGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-pCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model MetricsMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported LanguagesRerankingReranking Best PracticesGenerating FeedbackIntroductory GuidesSemantic SearchContent ModerationEntity ExtractionText ClassificationText Classification (Classify)Text Classification (Embed)Co.summarize (Beta)Co.rerank (Beta)Responsible UseOverviewUsage GuidelinesModel LimitationsData StatementModelsSecurityEnvironmental ImpactLLM UniversityWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?Module 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language ModelsModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text RepresentationModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere\\'s Command ModelConclusion - Text GenerationAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLPAppendix 2: Building AppsApp ExamplesText Classification (Embed)Suggest Edits📘This Guide Uses the Embed Endpoint.You can find more information about the endpoint here.\\nThis notebook shows how to build a classifiers using Cohere\\'s embeddings. You can find the code in the notebook and colab.\\nFirst we embed the text in the dataset, then we use that to train a classifier.\\nThe example classification task here will be sentiment analysis of film reviews. We\\'ll train a simple classifier to detect whether a film review is negative (class 0) or positive (class 1).\\nWe\\'ll go through the following steps:\\n\\nInstall Cohere\\nGet the dataset\\nGet the embeddings of the reviews (for both the training set and the test set).\\nTrain a classifier using the training set\\nEvaluate the performance of the classifier on the testing set\\n\\n1. Install Cohere and Other Dependencies\\nPython!pip install cohere sklearn\\n\\n2. Get the Dataset\\nPythonimport pandas as pd\\nimport cohere\\nfrom sklearn.model_selection import train_test_split\\npd.set_option(\\'display.max_colwidth\\', None)\\n\\n# Get the SST2 training and test sets\\ndf = pd.read_csv(\\'https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/train.tsv\\', delimiter=\\'\\\\t\\', header=None)\\n\\n2a. Print an Example from the Dataset\\nPython# Let\\'s glance at the dataset\\ndf_train.head()\\n\\n\\nWe\\'ll only use a subset of the training and testing datasets in this example. We\\'ll only use 500 examples since this is a toy example. You\\'ll want to increase the number to get better performance and evaluation.\\nThe train_test_split method split arrays or matrices into random train and test subsets.\\nPython# Set the number of examples from the dataset\\nnum_examples = 500\\n# Create a dataframe that\\ndf_sample = df.sample(num_examples)\\n\\n# Split into training and testing sets\\nsentences_train, sentences_test, labels_train, labels_test = train_test_split(\\n            list(df_sample[0]), list(df_sample[1]), test_size=0.25, random_state=0)\\n\\n2a. Set up the Cohere client to embed your reviews\\nPython# ADD YOUR API KEY HERE\\napi_key = \"Insert your api key\"\\n\\n# Create and retrieve a Cohere API key from dashboard.cohere.ai\\nco = cohere.Client(api_key)\\n\\n2b. Use Co.embed() to embed your test and training set\\nWe are calling the co.embed() method to convert our text examples into numerical representations. \\nPython# Embed the training set\\nembeddings_train = co.embed(texts=sentences_train,\\n                             model=\"embed-english-v2.0\").embeddings\\n# Embed the testing set\\nembeddings_test = co.embed(texts=sentences_test,\\n                             model=\"embed-english-v2.0\").embeddings\\n\\n# Here we are using the endpoint co.embed() \\n\\nWe now have two sets of embeddings, embeddings_train contains the embeddings of the training sentences while embeddings_test contains the embeddings of the testing sentences.\\nCurious what an embedding looks like? we can print it:\\nPythonprint(f\"Review text: {sentences_train[0]}\")\\nprint(f\"Embedding vector: {embeddings_train[0][:10]}\")\\n\\nThe results look something like this\\nReview text: the movie \\'s major and most devastating flaw is its reliance on formula , though , and it \\'s quite enough to lessen the overall impact the movie could have had\\nEmbedding vector: [3.1484375, 0.56884766, 1.2861328, 0.83154297, 1.5849609, 0.037872314, 1.2617188, 0.40039062, -0.36889648, 0.8671875]\\n\\n3. Train a Classifier Using the Training Set\\nNow that we have the embedding we can train our classifier. We\\'ll use an SVM from sklearn. We call the make_pipeline which configures a pipeline. The purpose of the pipeline is to assemble several steps that can be cross-validated together while setting different parameters. \\nPython# import SVM classifier code\\nfrom sklearn.svm import SVC\\nfrom sklearn.pipeline import make_pipeline\\nfrom sklearn.preprocessing import StandardScaler\\n\\n\\n# Initialize a support vector machine, with class_weight=\\'balanced\\' because \\n# our training set has roughly an equal amount of positive and negative \\n# sentiment sentences\\nsvm_classifier = make_pipeline(StandardScaler(), SVC(class_weight=\\'balanced\\')) \\n\\n# fit the support vector machine\\nsvm_classifier.fit(embeddings_train, labels_train)\\n\\n\\n4. Evaluate the Performance of the Classifier on The Testing Set\\nPython# get the score from the test set, and print it out to screen!\\nscore = svm_classifier.score(embeddings_test, labels_test)\\nprint(f\"Validation accuracy on Large is {100*score}%!\")\\n\\n Validation accuracy on Large is 88.8%!\\nThis was a small scale example, meant as a proof of concept and designed to illustrate how you can build a custom classifier quickly using a small amount of labelled data and Cohere\\'s embeddings. Increase the number of training examples to achieve better performance on this task.Updated 22 days ago Table of Contents\\n\\n1. Install Cohere and Other Dependencies\\n\\n\\n2. Get the Dataset\\n\\n2a. Print an Example from the Dataset\\n\\n\\n\\n2a. Set up the Cohere client to embed your reviews\\n\\n\\n2b. Use Co.embed() to embed your test and training set\\n\\n\\n3. Train a Classifier Using the Training Set\\n\\n\\n4. Evaluate the Performance of the Classifier on The Testing Set\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n', metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/text-classification-with-embed', 'title': 'Text Classification (Embed)', 'description': 'Use the API to generate completions, distill text into semantically meaningful vectors, and more. Get state-of-the-art natural language processing without the need for expensive supercomputing infrastructure.', 'language': 'en'}),\n",
       " Document(page_content='Co.summarize (Beta)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to ContentGuides and ConceptsAPI ReferenceRelease NotesLLMUDashboardDocumentationPlaygroundCommunityLog InDashboardDocumentationPlaygroundCommunityLog InGuides and ConceptsAPI ReferenceRelease NotesLLMUSearchGet StartedThe Cohere PlatformIntroduction to Large Language ModelsPlayground OverviewQuickstart TutorialsGoing LiveIntegrationsLearnKey ConceptsEmbeddingsPrompt EngineeringTokensGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-pCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model MetricsMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported LanguagesRerankingReranking Best PracticesGenerating FeedbackIntroductory GuidesSemantic SearchContent ModerationEntity ExtractionText ClassificationText Classification (Classify)Text Classification (Embed)Co.summarize (Beta)Co.rerank (Beta)Responsible UseOverviewUsage GuidelinesModel LimitationsData StatementModelsSecurityEnvironmental ImpactLLM UniversityWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?Module 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language ModelsModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text RepresentationModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere\\'s Command ModelConclusion - Text GenerationAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLPAppendix 2: Building AppsApp ExamplesCo.summarize (Beta)Suggest EditsThis endpoint generates a succinct version of the original text that relays the most important information. \\nIdeal use cases include, but are not limited to: news articles, blogs, chat transcripts, scientific articles, meeting notes, and any text that you should like to see a summary of!\\nThe endpoint can:\\n\\nSummarize a single document\\nControl output length \\n\\n🚧Experimental FeaturesThese features are extremely experimental. Using these feature could lead to a substantial decrease in performance over the overall model. It is included as a feature based on user feedback — and our team is actively working on delivering a better solution. Because it is critical for some applications, we have exposed an experimental version. If you do try it out, we welcome your feedback.\\n\\nAbility to format chosen output\\nLong document summaries\\nAbility to provide additional instructions to focus the summary\\n\\nWe recommend to leverage the playground for quick use cases, but for any repeated utilizations we strongly recommend the API. An example is provided below.\\n\\nIn this example, we want to summarize a passage from a news article into its main point.\\n1. Set up\\nInstall the SDK, if you haven\\'t already.\\n$ pip install cohere\\n\\nNext, set up the Cohere client.\\nPythonimport cohere\\nco = cohere.Client(api_key)\\n\\n2. Create prompt\\nStore the document you want to summarize into a variable\\nPythontext =\"\"\"It\\'s an exciting day for the development community. Cohere\\'s state-of-the-art language AI is now available through Amazon SageMaker. This makes it easier for developers to deploy Cohere\\'s pre-trained generation language model to Amazon SageMaker, an end-to-end machine learning (ML) service. Developers, data scientists, and business analysts use Amazon SageMaker to build, train, and deploy ML models quickly and easily using its fully managed infrastructure, tools, and workflows.\\nAt Cohere, the focus is on language. The company\\'s mission is to enable developers and businesses to add language AI to their technology stack and build game-changing applications with it. Cohere helps developers and businesses automate a wide range of tasks, such as copywriting, named entity recognition, paraphrasing, text summarization, and classification. The company builds and continually improves its general-purpose large language models (LLMs), making them accessible via a simple-to-use platform. Companies can use the models out of the box or tailor them to their particular needs using their own custom data.\\nDevelopers using SageMaker will have access to Cohere\\'s Medium generation language model. The Medium generation model excels at tasks that require fast responses, such as question answering, copywriting, or paraphrasing. The Medium model is deployed in containers that enable low-latency inference on a diverse set of hardware accelerators available on AWS, providing different cost and performance advantages for SageMaker customers.\\n\"\"\"\\n\\n3. Define model settings\\nThe endpoint has a number of settings you can use to control the kind of output it generates. The full list is available in the API reference, but let’s look at a few:\\n\\nmodel - summarize-xlarge or summarize-medium. Generally, medium models are faster while larger models will perform better.\\ntemperature - Ranges from 1 to 5. Controls the randomness of the output. Higher values tend to generate more creative outcomes, and gives you the opportunity of generating various summaries for the same input text. It also might include more hallucinations. Use a higher value if for example you plan to perform a selection of various summaries afterwards\\nlength - You can choose between short, medium and long. Short summaries are roughly up to 2 sentences long, medium between 3 and 5 and long might have more 6 or more sentences.\\nformat - You can choose between paragraph and bullets. Paragraph generates a coherent sequence of sentences, while bullets outputs the summary in bullet points\\nextractiveness -low, medium, high\\n\\n4. Generate the summary\\nCall the endpoint via the co.summarize() method, specifying the prompt and the rest of the model settings.\\nPythonresponse = co.summarize( \\n    model=\\'summarize-xlarge\\', \\n    length=\\'medium\\',\\n    extractiveness=\\'medium\\'\\n)\\n\\nsummary = response.summary\\n\\n5. Limitations\\nAs any work building on top of statistical large language models, there is the risk that the output contains facts not present in the original document. Those hallucinations might be innocuous, in the sense that they enrich the summary with additional facts, but can also contain inaccuracies.\\nThe control parameters of length and extractivenesss have an impact on the final output, but are not absolute. For instance, a highly extractive summary can still contain a sentence taken verbatim from the original document, and a long summary can still be less than 6 sentences long.Updated 16 days ago Table of Contents\\n1. Set up\\n2. Create prompt\\n3. Define model settings\\n4. Generate the summary\\n5. Limitations\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n', metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/summarize', 'title': 'Co.summarize (Beta)', 'description': 'This endpoint generates a succinct version of the original text that relays the most important information.Ideal use cases include, but are not limited to: news articles, blogs, chat transcripts, scientific articles, meeting notes, and any text that you should like to see a summary of!The endpoint c...', 'language': 'en'})]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "\n",
    "urls = urls = [\n",
    "    \"https://docs.cohere.com/cohere-ai/docs/the-cohere-platform\",\n",
    "    \"https://docs.cohere.com/cohere-ai/docs/introduction-to-large-language-models\",\n",
    "    \"https://docs.cohere.com/cohere-ai/docs/playground-overview\",\n",
    "    \"https://docs.cohere.com/cohere-ai/docs/quick-start-guides\",\n",
    "    \"https://docs.cohere.com/cohere-ai/docs/going-live\",\n",
    "    \"https://docs.cohere.com/cohere-ai/docs/integrations\",\n",
    "    \"https://docs.cohere.com/cohere-ai/docs/embeddings\",\n",
    "    \"https://docs.cohere.com/cohere-ai/docs/prompt-engineering\",\n",
    "    \"https://docs.cohere.com/cohere-ai/docs/tokens\",\n",
    "    \"https://docs.cohere.com/cohere-ai/docs/command-beta\",\n",
    "    \"https://docs.cohere.com/cohere-ai/docs/likelihood\",\n",
    "    \"https://docs.cohere.com/cohere-ai/docs/number-of-generations\",\n",
    "    \"https://docs.cohere.com/cohere-ai/docs/temperature\",\n",
    "    \"https://docs.cohere.com/cohere-ai/docs/controlling-generation-with-top-k-top-p\",\n",
    "    \"https://docs.cohere.com/cohere-ai/docs/training-custom-models\",\n",
    "    \"https://docs.cohere.com/cohere-ai/docs/likelihood-evaluation\",\n",
    "    \"https://docs.cohere.com/cohere-ai/docs/training-a-generative-model\",\n",
    "    \"https://docs.cohere.com/cohere-ai/docs/training-a-representation-model\",\n",
    "    \"https://docs.cohere.com/cohere-ai/docs/training-troubleshooting\",\n",
    "    \"https://docs.cohere.com/cohere-ai/docs/custom-model-metrics\",\n",
    "    \"https://docs.cohere.com/cohere-ai/docs/multilingual-language-models\",\n",
    "    \"https://docs.cohere.com/cohere-ai/docs/language-detection\",\n",
    "    \"https://docs.cohere.com/cohere-ai/docs/multilingual-semantic-search\",\n",
    "    \"https://docs.cohere.com/cohere-ai/docs/customer-feedback-aggregation\",\n",
    "    \"https://docs.cohere.com/cohere-ai/docs/cross-lingual-content-moderation\",\n",
    "    \"https://docs.cohere.com/cohere-ai/docs/supported-languages\",\n",
    "    \"https://docs.cohere.com/cohere-ai/docs/reranking\",\n",
    "    \"https://docs.cohere.com/cohere-ai/docs/reranking-best-practices\",\n",
    "    \"https://docs.cohere.com/cohere-ai/docs/feedback\",\n",
    "    \"https://docs.cohere.com/cohere-ai/docs/semantic-search\",\n",
    "    \"https://docs.cohere.com/cohere-ai/docs/content-moderation-with-classify\",\n",
    "    \"https://docs.cohere.com/cohere-ai/docs/entity-extraction\",\n",
    "    \"https://docs.cohere.com/cohere-ai/docs/text-classification-with-classify\",\n",
    "    \"https://docs.cohere.com/cohere-ai/docs/text-classification-with-embed\",\n",
    "    \"https://docs.cohere.com/cohere-ai/docs/summarize\"\n",
    "]\n",
    "\n",
    "loader = WebBaseLoader(urls)\n",
    "docs = loader.load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"Jump to Content\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nSearch\\n\\nGet Started\\n\\nThe Cohere Platform\\n\\nIntroduction to Large Language Models\\n\\nPlayground Overview\\n\\nQuickstart Tutorials\\n\\nGoing Live\\n\\nIntegrations\\n\\nLearn\\n\\nKey ConceptsEmbeddingsPrompt EngineeringTokens\\n\\nGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-p\\n\\nCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model Metrics\\n\\nMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported Languages\\n\\nRerankingReranking Best Practices\\n\\nGenerating Feedback\\n\\nIntroductory Guides\\n\\nSemantic Search\\n\\nContent Moderation\\n\\nEntity Extraction\\n\\nText ClassificationText Classification (Classify)Text Classification (Embed)\\n\\nCo.summarize (Beta)\\n\\nCo.rerank (Beta)\\n\\nResponsible Use\\n\\nOverviewUsage GuidelinesModel LimitationsData Statement\\n\\nModels\\n\\nSecurity\\n\\nEnvironmental Impact\\n\\nLLM University\\n\\nWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?\\n\\nModule 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language Models\\n\\nModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text Representation\\n\\nModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere's Command ModelConclusion - Text Generation\\n\\nAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLP\\n\\nAppendix 2: Building AppsApp Examples\\n\\nThe Cohere Platform\\n\\nSuggest Edits\\n\\nCohere offers an API to add cutting-edge language processing to any system. Cohere trains massive language models and puts them behind a simple API. Moreover, through training, users can create massive models customized to their use case and trained on their data. This way, Cohere handles the complexities of collecting massive amounts of text data, the ever evolving neural network architectures, distributed training, and serving models around the clock.\\n\\nCohere offers access to both generation models (through the generate endpoint) and\\nrepresentation models (through the embed endpoint which returns an embedding vector for the input text).\\n\\nTwo major categories of large language models are generative language models (like GPT2 and GPT3) and representation language models (like BERT). Cohere offers variants of both types.\\n\\nUse Cases\\n\\nHere are a few examples of language understanding systems that can be built on top of large language models.\\n\\nSummarize\\n\\nLarge language models present a breakthrough in text generation. For the first time in history, we have software programs that can write text that sounds like itâ€™s written by humans. These capabilities open doors to use cases like summarization or paraphrasing.\\n\\nLanguage models can be instructed to generate useful summaries or paraphrases of input text by guiding them using a task description in the prompt.\\n\\nA summarization prompt in the Cohere playground shows this output (in bold):\\n\\nExample summarization prompt and generation. Stop sequence is specified as the period to limit the output to one sentence.\\n\\nLarge language models can be adapted to new tasks with impressive speed. For tasks which appear in the training data (i.e. documents on the web), language models can successfully summarize text without being shown any examples at all.\\n\\nTwo strategies you can experiment with generative language models are prompt engineering and training (which creates a custom model based on your dataset).\\n\\nSummarization uses the Co.summarize endpoint.\\n\\nðŸ“˜\\n\\nNew to Cohere?\\n\\nGet Started now and get unprecedented access to world-class Generation and Representation models with billions of parameters.\\n\\nClassify\\n\\nClassification is one of the most common use cases in language processing. Building systems on top of language models can automate language-based tasks and save time and energy.\\n\\nDevelopers can build classifiers on top of Cohereâ€™s language models. These classifiers can automate language tasks and workflows.\\n\\nThere's more than one way to build a classifier on top of Cohere's language models. It's worth experimenting to see which method works best for your use case. The simpler methods can get you quick results, while the more advanced methods need more data and will lead to better results.\\n\\nOn the simpler side are methods like using the Classify endpoint for classification. More industrial-grade classifiers can be built by fitting a classifier on top of the embed endpoint (see: Embedding endpoint for classification).\\n\\nSemantic Similarity\\n\\nThink of how many repeated questions have to be answered by a customer service agent every day. Language models are capable of judging text similarity and determining if an incoming question is similar to questions already answered in the FAQ section.\\n\\nA similarity score can be computed through our embeddings by calculating the\\ncosine similarity of two embeddings.\\n\\nThere are multiple things your system can do once it receives the similarity scores â€” one possible next action is to simply show the answer to the most similar question (if above a certain similarity threshold). Another possible next action is to make that suggestion to a customer service agent.\\n\\nUpdated 14 days ago\\n\\nTable of Contents\\n\\nUse Cases\\n\\nSummarize\\nClassify\\nSemantic Similarity\", metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/the-cohere-platform'}),\n",
       " Document(page_content=\"Jump to Content\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nSearch\\n\\nGet Started\\n\\nThe Cohere Platform\\n\\nIntroduction to Large Language Models\\n\\nPlayground Overview\\n\\nQuickstart Tutorials\\n\\nGoing Live\\n\\nIntegrations\\n\\nLearn\\n\\nKey ConceptsEmbeddingsPrompt EngineeringTokens\\n\\nGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-p\\n\\nCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model Metrics\\n\\nMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported Languages\\n\\nRerankingReranking Best Practices\\n\\nGenerating Feedback\\n\\nIntroductory Guides\\n\\nSemantic Search\\n\\nContent Moderation\\n\\nEntity Extraction\\n\\nText ClassificationText Classification (Classify)Text Classification (Embed)\\n\\nCo.summarize (Beta)\\n\\nCo.rerank (Beta)\\n\\nResponsible Use\\n\\nOverviewUsage GuidelinesModel LimitationsData Statement\\n\\nModels\\n\\nSecurity\\n\\nEnvironmental Impact\\n\\nLLM University\\n\\nWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?\\n\\nModule 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language Models\\n\\nModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text Representation\\n\\nModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere's Command ModelConclusion - Text Generation\\n\\nAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLP\\n\\nAppendix 2: Building AppsApp Examples\\n\\nIntroduction to Large Language Models\\n\\nSuggest Edits\\n\\nLanguage is important. It’s how we learn about the world (e.g. news, searching the web or Wikipedia), and also how we shape it (e.g. agreements, laws, or messages). Language is also how we connect and communicate — as people, and as groups and companies.\\n\\nDespite the rapid evolution of software, computers remain limited in their ability to deal with language. Software is great at searching for exact matches in text, but often fails at more advanced uses of language — ones that humans employ on a daily basis.\\n\\nThere’s a clear need for more intelligent tools that better understand language.\\n\\nLarge Language Models\\n\\nA recent breakthrough in artificial intelligence (AI) is the introduction of language processing technologies that enable us to build more intelligent systems with a richer understanding of language than ever before. Large pre-trained Transformer language models, or simply large language models, vastly extend the capabilities of what systems are able to do with text.\\n\\nLarge language models are computer programs that open new possibilities of text understanding and generation in software systems.\\n\\nConsider this: adding language models to empower Google Search was noted as “representing the biggest leap forward in the past five years, and one of the biggest leaps forward in the history of Search“. Microsoft also uses such models for every query in the Bing search engine.\\n\\nDespite the utility of these models, training and deploying them effectively is resource intensive in its requirements of data, compute, and engineering resources.\\n\\nUpdated 23 days ago\\n\\nTable of Contents\\n\\nLarge Language Models\", metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/introduction-to-large-language-models'}),\n",
       " Document(page_content='Jump to Content\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nSearch\\n\\nGet Started\\n\\nThe Cohere Platform\\n\\nIntroduction to Large Language Models\\n\\nPlayground Overview\\n\\nQuickstart Tutorials\\n\\nGoing Live\\n\\nIntegrations\\n\\nLearn\\n\\nKey ConceptsEmbeddingsPrompt EngineeringTokens\\n\\nGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-p\\n\\nCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model Metrics\\n\\nMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported Languages\\n\\nRerankingReranking Best Practices\\n\\nGenerating Feedback\\n\\nIntroductory Guides\\n\\nSemantic Search\\n\\nContent Moderation\\n\\nEntity Extraction\\n\\nText ClassificationText Classification (Classify)Text Classification (Embed)\\n\\nCo.summarize (Beta)\\n\\nCo.rerank (Beta)\\n\\nResponsible Use\\n\\nOverviewUsage GuidelinesModel LimitationsData Statement\\n\\nModels\\n\\nSecurity\\n\\nEnvironmental Impact\\n\\nLLM University\\n\\nWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?\\n\\nModule 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language Models\\n\\nModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text Representation\\n\\nModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere\\'s Command ModelConclusion - Text Generation\\n\\nAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLP\\n\\nAppendix 2: Building AppsApp Examples\\n\\nPlayground Overview\\n\\nSuggest Edits\\n\\nWhat is the Playground?\\n\\nendpoints, we recommend clicking the\\n\\nUsing the Playground\\n\\nGenerate\\n\\nGenerate produces natural language text in response to an input prompt. As seen in the screenshot below, we supplied the model with a prompt, \"Given a product and keywords, this program will generate exciting product descriptions. Here are some examples:\" and gave two examples of a product and keywords. The bolded text was generated by the model.\\n\\nTo write inputs that produce the best results for your use case, read our Prompt Engineering guide.\\n\\nTry tinkering with different temperature and token-picking settings to alter the model\\'s output behaviour.\\n\\nTo further improve your generations or to get the model to focus on generating text about a specific topic, try uploading a sample text to train the model. If you\\'re interested in training a model, please submit a Full Access request from your Cohere Dashboard.\\n\\nTry asking the model to do any of the following:\\n\\nSummarize a paragraph of text\\n\\nGenerate SEO tags for a blog post\\n\\nProduce some questions for your next trivia night\\n\\nProvide ideas of what to do in your city this weekend\\n\\nIn each case, give the model a few examples your desired output.\\n\\nAdditionally, note the Show Likelihood button withinAdvanced Parameters. This feature outputs the likelihood that each token would be generated by the model in the given sequence, as well as the average log-likelihood of each token in the input. Token likelihoods can be retrieved from our Generate endpoint.\\n\\nThe log-likelihood is useful for evaluating model performance, especially when testing user-trained models. If you\\'re interested in training a model, please submit a Full Access request from your Cohere Dashboard.\\n\\nEmbed\\n\\nUsing Embed in the Playground enables users to assign numerical representations to strings and visualize comparative meaning on a 2-dimensional plane. Phrases similar in meaning should ideally be closer together on this visualization. Add a couple of your own phrases and see if the Playground visualization feels accurate to you.\\n\\nCohere’s embeddings can be used to train a semantic classifier out of the box, saving users countless hours gathering data to train a model themselves.\\n\\nClassify\\n\\nCohere’s Classify endpoint enables users to create a classifier from a few labeled examples.\\n\\nSelecting the Right Model Size\\n\\nLarger models are more capable of complex tasks but smaller models have faster response times and are less expensive. Here is a rough guideline for which model size to use for various tasks:\\n\\nGeneration models\\n\\ncommand\\nCommand is the most capable generative model and can perform any task other models can with better results. This model is well suited for challenging tasks including complex extraction, rewriting, question-answering, summarization, conversation, and brainstorming.\\n\\ncommand-light\\nCommand Light provides a great tradeoff between power and speed. Use this model to power tasks like generating marketing ad-copy, extracting key entities from text, or powering conversational agents.\\n\\nRepresentation models\\n\\nembed-english-v2.0\\nEmbed is our most capable representation model and can perform any tasks other models can with better results. The large model performs better at few shot classification tasks in both single label and multi-label scenarios. Large embeddings have 4096 dimensions.\\n\\nembed-english-light-v2.0\\nEmbed Light is our fastest model, and has the lightest storage requirements. Small embeddings have 1024 dimensions.\\n\\nembed-multilingual-v2.0\\n\\nWe currently have a single multilingual representation model available on out platform. The embeddings have 768 dimensions.\\n\\nUpdated 23 days ago\\n\\nTable of Contents\\n\\nWhat is the Playground?\\n\\n\\nUsing the Playground\\n\\nGenerate\\nEmbed\\nClassify\\n\\n\\n\\nSelecting the Right Model Size\\n\\nGeneration models\\nRepresentation models', metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/playground-overview'}),\n",
       " Document(page_content=\"Jump to Content\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nSearch\\n\\nGet Started\\n\\nThe Cohere Platform\\n\\nIntroduction to Large Language Models\\n\\nPlayground Overview\\n\\nQuickstart Tutorials\\n\\nGoing Live\\n\\nIntegrations\\n\\nLearn\\n\\nKey ConceptsEmbeddingsPrompt EngineeringTokens\\n\\nGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-p\\n\\nCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model Metrics\\n\\nMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported Languages\\n\\nRerankingReranking Best Practices\\n\\nGenerating Feedback\\n\\nIntroductory Guides\\n\\nSemantic Search\\n\\nContent Moderation\\n\\nEntity Extraction\\n\\nText ClassificationText Classification (Classify)Text Classification (Embed)\\n\\nCo.summarize (Beta)\\n\\nCo.rerank (Beta)\\n\\nResponsible Use\\n\\nOverviewUsage GuidelinesModel LimitationsData Statement\\n\\nModels\\n\\nSecurity\\n\\nEnvironmental Impact\\n\\nLLM University\\n\\nWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?\\n\\nModule 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language Models\\n\\nModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text Representation\\n\\nModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere's Command ModelConclusion - Text Generation\\n\\nAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLP\\n\\nAppendix 2: Building AppsApp Examples\\n\\nQuickstart Tutorials\\n\\nSuggest Edits\\n\\nCohere's API is created to help you build natural language understanding and generation into your production with a few lines of code. Our Quickstart Tutorials will show you how to implement our API from zero-to-one in under 5 minutes.\\n\\n1. Customer SupportCustomer support tickets can come from all directions, and manually analyzing and routing information is an overwhelming job. A text classification system can help support teams accelerate this process.  Here is an example of classifying customer emails to an insurance company into four categories: Finding policy details, Change account settings, Filing a claim and viewing status, and Cancelling coverage.\\n\\n2. Intent Recognition\\nChatbots are designed to understand and respond to human language. They need to be able to understand the text they hear and understand the context of the conversation. They also need to be able to respond to people’s questions and comments in a meaningful way. To accomplish this, chatbots must be able to recognize specific intents that people express in conversation.Here is an example of classifying the intent of customer inquiries on an eCommerce website into three categories: Shipping and handling policy, Start return or exchange, or Track order.\\n\\n3. Sentiment AnalysisSentiment analysis is a type of classification task that analyzes the tone of a piece of text. It is used in a variety of different ways, or example, on social media comments and customer reviews. It is commonly used to see how people feel about their products or company, but it can also be used to help businesses understand how different trends in the economy may impact their business.Here is an example of classifying the sentiments of customer feedback about a product into three categories: Positive, Negative, or Neutral.\\n\\n4. Text SummarizationThe goal of text summarization is to condense the original text into a shorter version that retains the most important information. In this example, we want to summarize a passage from a news article into its main point.\\n\\n5. Toxicity DetectionThe internet is dominated by user-generated content. While it provides an avenue for online platforms to grow, it is a bane for content moderators managing them. It is impossible for humans to manually moderate all the user content that is created. This is why an automated solution is needed, such as in flagging for toxic content.Here is an example of classifying online user comments for toxicity into two categories: Toxic or Not Toxic.\\n\\nUpdated 23 days ago\", metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/quick-start-guides'}),\n",
       " Document(page_content='Jump to Content\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nSearch\\n\\nGet Started\\n\\nThe Cohere Platform\\n\\nIntroduction to Large Language Models\\n\\nPlayground Overview\\n\\nQuickstart Tutorials\\n\\nGoing Live\\n\\nIntegrations\\n\\nLearn\\n\\nKey ConceptsEmbeddingsPrompt EngineeringTokens\\n\\nGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-p\\n\\nCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model Metrics\\n\\nMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported Languages\\n\\nRerankingReranking Best Practices\\n\\nGenerating Feedback\\n\\nIntroductory Guides\\n\\nSemantic Search\\n\\nContent Moderation\\n\\nEntity Extraction\\n\\nText ClassificationText Classification (Classify)Text Classification (Embed)\\n\\nCo.summarize (Beta)\\n\\nCo.rerank (Beta)\\n\\nResponsible Use\\n\\nOverviewUsage GuidelinesModel LimitationsData Statement\\n\\nModels\\n\\nSecurity\\n\\nEnvironmental Impact\\n\\nLLM University\\n\\nWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?\\n\\nModule 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language Models\\n\\nModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text Representation\\n\\nModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere\\'s Command ModelConclusion - Text Generation\\n\\nAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLP\\n\\nAppendix 2: Building AppsApp Examples\\n\\nGoing Live\\n\\nSuggest Edits\\n\\nGoing Live\\n\\nUpon registration, every Cohere user receives a free, rate-limited Trial key to use with our endpoints. If you find that you are running against the Trial key rate limit or want to serve Cohere in production, this page details the process of upgrading to a Production key and going live.\\n\\nTrial Key Limitations\\n\\nTrial keys are rate-limited depending on the endpoint you want to use:\\n\\nCo.Generate, Co.Summarize\\n\\nAll other endpoints\\n\\n100\\n\\nIf you’d like to use Cohere’s endpoints in a production application or require higher throughput from our endpoints for your usage, you can upgrade to a Production key.\\n\\nWith a Trial Key:\\n\\nOrganizations can still have unlimited trial keys in the free tier.\\nThere is a defined usage limit on all the development API keys per minute (all keys add up to that rate limit).\\nWhen a developer/org reaches a rate limit, they will receive an error that they have exceeded the limit/minute.\\nPlayground usage counts toward your Trial key rate limit.\\nIf calls exceed the throttling we throw an error that says “Trial keys are throttled.\" Please upgrade your API key or contact us directly on Discord.\\nTrial keys are free to use even after you upgrade to a Production key.\\n\\nProduction Key Specifications\\n\\nProduction keys for all endpoints are rate-limited at 10,000 calls per minute and are intended for serving Cohere in a public-facing application and testing purposes. Usage of Production keys is metered at price points which can be found on our pricing page.\\n\\nTo get a Production key, you will need to complete a few steps in our Go to Production workflow. You can start the process by navigating to the Billing and Usage page in your Cohere dashboard as the Admin of your organization (or asking your organization Admin to complete these steps). From there, click on the Get your Production key button to start the process.\\n\\nThe process takes less than 3 minutes to finish, and enables you to generate a Production key that you can use to serve Cohere APIs in production. If you deploy without completing the Go to Production workflow, your API key may be temporarily or permanently revoked.\\n\\nGo to Production\\n\\nYou must acknowledge Cohere’s SaaS Agreement and Terms of Service. Your organization must also read and recognize our Model Limitations, Model Cards, and Data Statement.\\n\\nYou will be asked if your usage of Cohere API involves any of the sensitive use cases outlined in our Usage Guidelines. Following your acknowledgement of our terms, you will be able to generate and use a Production key immediately. However, if you indicate your usage involves a sensitive use case, your Production key may be rate limited the same as a Trial key until our Safety team reaches out and manually approves your use case. Reviews on sensitive use cases will take no longer than 48 hours.\\n\\nTrack Incidents\\n\\nNavigate to our status page which features information including a summary status indicator, component statuses, unresolved incidents, status history, and any upcoming or in-progress scheduled maintenance. We recommend subscribing for updates with an email or phone number to receive notifications whenever Cohere creates, updates or resolves an incident.\\n\\nUpdated 23 days ago\\n\\nTable of Contents\\n\\nGoing Live\\nTrial Key Limitations\\nProduction Key Specifications\\nGo to Production\\nTrack Incidents', metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/going-live'}),\n",
       " Document(page_content=\"Jump to Content\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nSearch\\n\\nGet Started\\n\\nThe Cohere Platform\\n\\nIntroduction to Large Language Models\\n\\nPlayground Overview\\n\\nQuickstart Tutorials\\n\\nGoing Live\\n\\nIntegrations\\n\\nLearn\\n\\nKey ConceptsEmbeddingsPrompt EngineeringTokens\\n\\nGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-p\\n\\nCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model Metrics\\n\\nMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported Languages\\n\\nRerankingReranking Best Practices\\n\\nGenerating Feedback\\n\\nIntroductory Guides\\n\\nSemantic Search\\n\\nContent Moderation\\n\\nEntity Extraction\\n\\nText ClassificationText Classification (Classify)Text Classification (Embed)\\n\\nCo.summarize (Beta)\\n\\nCo.rerank (Beta)\\n\\nResponsible Use\\n\\nOverviewUsage GuidelinesModel LimitationsData Statement\\n\\nModels\\n\\nSecurity\\n\\nEnvironmental Impact\\n\\nLLM University\\n\\nWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?\\n\\nModule 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language Models\\n\\nModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text Representation\\n\\nModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere's Command ModelConclusion - Text Generation\\n\\nAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLP\\n\\nAppendix 2: Building AppsApp Examples\\n\\nIntegrations\\n\\nUse Cohere's models with the tools you love.\\n\\nSuggest Edits\\n\\nQdrant is an open-source vector similarity search engine and vector database. It provides a production-ready service with a convenient API to store, search, and manage points - vectors with an additional payload. Qdrant is tailored to extended filtering support. It makes it useful for all sorts of neural-network or semantic-based matching, faceted search, and other applications.\\n\\nQdrant is written in Rust, which makes it fast and reliable even under high load.\\n\\nLearn More\\n\\nWeaviate is an open source vector search engine that stores both objects and vectors, allowing for combining vector search with structured filtering.\\n\\nThe text2vec-cohere module allows you to use Cohere embeddings directly in the Weaviate vector search engine as a vectorization module.\\n\\nLearn More\\n\\nThe Pinecone vector database makes it easy to build high-performance vector search applications. Use Cohere to generate language embeddings, then store them in Pinecone and use them for Semantic Search.\\n\\nLearn More\\n\\nCohere offers optimized containers that enable low latency inference on a diverse set of hardware accelerators available on AWS, providing different cost and performance points for Sagemaker customers.\\n\\nLearn More\\n\\nIntegrate the Surge AI labeling platform into your Cohere workflow.\\n\\nLearn More\\n\\nUse Scale's labelled datasets with Cohere's Large Language Models.\\n\\nLearn More\\n\\nMilvus is a highly flexible, reliable, and blazing-fast cloud-native, open-source vector database. It powers embedding similarity search and AI applications and strives to make vector databases accessible to every organization. Milvus is a graduated-stage project of the LF AI & Data Foundation.\\n\\nLearn More\\n\\nZilliz Cloud is a cloud-native vector database that stores, indexes, and searches for billions of embedding vectors to power enterprise-grade similarity search, recommender systems, anomaly detection, and more. Zilliz Cloud provides a fully-managed Milvus service, made by the creators of Milvus that allows for easy integration with vectorizers from Cohere and other popular models. Purpose-built to solve the challenge of managing billions of embeddings, Zilliz Cloud makes it easy to build applications for scale.\\n\\nLearn More\\n\\nUpdated 22 days ago\", metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/integrations'}),\n",
       " Document(page_content=\"Jump to Content\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nSearch\\n\\nGet Started\\n\\nThe Cohere Platform\\n\\nIntroduction to Large Language Models\\n\\nPlayground Overview\\n\\nQuickstart Tutorials\\n\\nGoing Live\\n\\nIntegrations\\n\\nLearn\\n\\nKey ConceptsEmbeddingsPrompt EngineeringTokens\\n\\nGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-p\\n\\nCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model Metrics\\n\\nMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported Languages\\n\\nRerankingReranking Best Practices\\n\\nGenerating Feedback\\n\\nIntroductory Guides\\n\\nSemantic Search\\n\\nContent Moderation\\n\\nEntity Extraction\\n\\nText ClassificationText Classification (Classify)Text Classification (Embed)\\n\\nCo.summarize (Beta)\\n\\nCo.rerank (Beta)\\n\\nResponsible Use\\n\\nOverviewUsage GuidelinesModel LimitationsData Statement\\n\\nModels\\n\\nSecurity\\n\\nEnvironmental Impact\\n\\nLLM University\\n\\nWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?\\n\\nModule 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language Models\\n\\nModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text Representation\\n\\nModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere's Command ModelConclusion - Text Generation\\n\\nAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLP\\n\\nAppendix 2: Building AppsApp Examples\\n\\nEmbeddings\\n\\nSuggest Edits\\n\\nEmbeddings are a way to represent the meaning of text as a list of numbers. This is useful because once text is in this form, it can be compared to other text for similarity. Using a simple comparison function, we can calculate a similarity score for two embeddings to figure out whether two texts are talking about similar things.\\n\\nIn the example below, the embeddings for two similar phrases have a high similarity score, and the embeddings for two unrelated phrases have a low similarity score:\\n\\nTurning text into embeddings.\\n\\nApplications\\n\\nBuild a Frequently Asked Questions bot that compares the customer question for similarity to an existing collection of frequently asked questions.\\n\\nEfficiently cluster large amounts of text, using k-means clustering, for example. The embeddings can also be visualized using projection techniques such as PCA, UMAP, or t-SNE. This can be helpful when trying to visualize large amounts of unstructured text.\\n\\nPerform semantic search over text in a database\\n\\nPair with a downstream classifier like a random forest or an SVM to perform binary or multi-class classification or tasks such as sentiment classification or toxicity detection.\\n\\nHow Embeddings are Obtained\\n\\nFor short texts (shorter than 512 tokens), we return embeddings obtained by averaging the contextualized embeddings of each token in the text, following Reimers and Gurevych. The final embedding thus captures semantic information about the entirety of the text. For texts longer than 512 tokens, we will truncate your inputs to the maximum context length.\\n\\nUpdated 22 days ago\\n\\nTable of Contents\\n\\nApplications\\nHow Embeddings are Obtained\", metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/embeddings'}),\n",
       " Document(page_content='Jump to Content\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nSearch\\n\\nGet Started\\n\\nThe Cohere Platform\\n\\nIntroduction to Large Language Models\\n\\nPlayground Overview\\n\\nQuickstart Tutorials\\n\\nGoing Live\\n\\nIntegrations\\n\\nLearn\\n\\nKey ConceptsEmbeddingsPrompt EngineeringTokens\\n\\nGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-p\\n\\nCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model Metrics\\n\\nMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported Languages\\n\\nRerankingReranking Best Practices\\n\\nGenerating Feedback\\n\\nIntroductory Guides\\n\\nSemantic Search\\n\\nContent Moderation\\n\\nEntity Extraction\\n\\nText ClassificationText Classification (Classify)Text Classification (Embed)\\n\\nCo.summarize (Beta)\\n\\nCo.rerank (Beta)\\n\\nResponsible Use\\n\\nOverviewUsage GuidelinesModel LimitationsData Statement\\n\\nModels\\n\\nSecurity\\n\\nEnvironmental Impact\\n\\nLLM University\\n\\nWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?\\n\\nModule 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language Models\\n\\nModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text Representation\\n\\nModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere\\'s Command ModelConclusion - Text Generation\\n\\nAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLP\\n\\nAppendix 2: Building AppsApp Examples\\n\\nPrompt Engineering\\n\\nSuggest Edits\\n\\nHere, we discuss a few principles and techniques for writing prompts (inputs for our models) that will help you get the best generations for your task. Choosing the right temperature can also have a big influence on generation quality. We discuss temperature separately here.\\n\\nMain Principles\\n\\nWe find that there are two main ideas to keep in mind while designing prompts for our models.\\n\\n1. A prompt guides the model to generate useful output\\n\\nIf you need a summary of an article, for example, a large language model trained on enough data can generate a summary if you guide it as such:\\n\\nThis prompt has two components: the text you want summarized, and the task description.\\n\\n2. Try multiple formulations of your prompt to get the best generations\\n\\nWhen using generate, it is useful to try a range of different prompts for the problem you are trying to solve. Different formulations of the same prompt which might sound similar to humans can lead to generations that are quite different from each other. This might happen, for instance, because our models have learned that the different formulations are actually used in very different contexts and for different purposes. Below we give a number of examples that we\\'ve found to work particularly well for different tasks.\\n\\nIn the summarization example, if “In summary,” doesn’t lead to a good generation, we may want to try “To summarize in plain language,“ or “The main point to take from this article is that”.\\n\\nAdditionally, you can also use the likelihood feature in the playground to see if there are particular words, phrases, or structures that the model has trouble understanding. However, keep in mind that the average likelihood of tokens will always be high at the beginning of the sequence. The model might assign low likelihood to the first time you introduce a novel concept or name, but once it has seen it once it can readily use it in the generation. You can also use the likelihood capability to see if there is any spelling or punctuation that is creating issues for tokenization.\\n\\n3. Describe the task and the general setting\\n\\nIt\\'s often useful to include additional components of the task description, naturally these tend to come after the input text we\\'re trying to process.\\n\\nProvide the model with enough context. For example, we can describe the summarization task in more detail before the article.\\n\\nExample: shaping the task we need the model to do in natural language can use text both before and after the input text we aim to process.\\n\\nLet\\'s consider a few more aspects of this by looking at a different example. Suppose that you would like to use our models to assist your customer satisfaction department by automatically generating plausible responses to customer requests (note: the generations are not to be sent to the customers, this is only a simulation).\\n\\nA customer contacts your company with the following question:\\n\\nHow do we design a prompt around this to get useful generations for the agent interacting with the customer? Let\\'s begin with telling our model what the general setting is and what the remainder of the prompt is going to contain:\\n\\nGreat, we\\'ve told our model about what to expect and have made it clear that our query is a question of the customer. Next, let\\'s show the model the beginning of the response we would like to give the customer.\\n\\nNote how we\\'ve stated clearly that the next sentence is a response to the question, that it comes from a customer service agent, and that we want to give a positive answer. Putting this all together, we obtain the following prompt:\\n\\nCertain components of prompts (like input and output indicators) are useful in describing a desired task to the model, especially when including multiple examples in the prompt (as the next figures will show).\\n\\nFeeding this into our Medium model multiple times we get the following completions:\\n\\nYes, we are able to accept returns if the product is unused and unopened.\\n\\nYes, we are happy to refund your purchase. However, we do require you to return the item to our store for a full refund.\\n\\nYes, we can do that. Please send us a message with your name, phone number, and the reason for the refund. We will get back to you as soon as possible.\\n\\nNote that even though this is a simplified example we get plausible completions from the baseline model using only a small number of customer service interactions! This could be further improved by finetuning it on examples of how you would like the model to handle specific questions and requests.\\n\\n4. Show the model what you would like to see\\n\\nAdding examples to a prompt is one of the key ways to achieving good generations. Examples demonstrate to the model the type of output we target.\\n\\nGive a few examples of the types of generations you want. This is called few-shot learning. Let\\'s look at an example. Say, you\\'d like to use our models to classify whether a movie review is positive, negative or neutral. Imagine that you feed the following prompt into our model:\\n\\nAn actual generation based on this prompt by our Medium model reads:\\n\\nClearly, there are generations that our model sees as likely that are not the type of generation we\\'d like to get.\\n\\nExamples in the prompt should include both an example input and the output we want the model emulate.\\n\\nPutting this all together and feeding this new prompt into the Medium Generation model, we reliably get the generation positive.\\n\\nA simpler version of this prompt can be visualized like this:\\n\\nAn example bringing together the various components of a prompt. We can also repeat the task description with each example to emphasize the instruction to the model.\\n\\nFew-shot generations will generally work better with our larger models. You can use the likelihood endpoint to see how uncertain the model is about the correct answers given in the examples.\\n\\nIf the command format does not work, try structuring as prose. An intuitive way to interact with the generate models is to give commands to the model about the type of generation that you want e.g. Give a list of artistic professions:. However, since much of the text that our models have seen is internet articles, sometimes this way of writing will be misunderstood. Try rephrasing the command into prose in a way such that the model will give the desired output:\\n\\nIn general, you may want to experiment with different styles of writing until you get something that works. Examples include writing in the style of a news article, a blog post, or a dialogue.\\n\\nExamples\\n\\nHere we showcase how we can use to apply the principles above by looking at two specific tasks: generating keywords based on a given passage and generating additional examples given a few existing examples.\\n\\nKeyword generation: Let\\'s imagine that we have text passages that we\\'d like to automatically tag with the most relevant concepts appearing in the text.\\n\\nBy combining a number of the techniques discussed above, we can generate just that! First, we state what the setting for this prompt is at the beginning of the prompt. Then we show the model two examples of what we want it to do: label a passage from John von Neumann\\'s Wikipedia page with the label \"John von Neumann\", and label a paragraph from the Wikipedia page on Feminism with the label \"Feminism\". Lastly, we give the model a passage from the Wikipedia page on Python.\\n\\nThis prompt reliably generates \"Python\" as an answer – while sometimes also returning \"Guido van Rossum\", another plausible option.\\n\\nExample generation. A common task is to try to get the model to generate examples according to some description. Formulating the prompt as a list in the following style tends to work well.\\n\\nwhich then gives us generations like:\\n\\nUpdated 22 days ago\\n\\nTable of Contents\\n\\nMain Principles\\n\\n1. A prompt guides the model to generate useful output\\n2. Try multiple formulations of your prompt to get the best generations\\n3. Describe the task and the general setting\\n4. Show the model what you would like to see\\n\\n\\n\\nExamples', metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/prompt-engineering'}),\n",
       " Document(page_content='Jump to Content\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nSearch\\n\\nGet Started\\n\\nThe Cohere Platform\\n\\nIntroduction to Large Language Models\\n\\nPlayground Overview\\n\\nQuickstart Tutorials\\n\\nGoing Live\\n\\nIntegrations\\n\\nLearn\\n\\nKey ConceptsEmbeddingsPrompt EngineeringTokens\\n\\nGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-p\\n\\nCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model Metrics\\n\\nMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported Languages\\n\\nRerankingReranking Best Practices\\n\\nGenerating Feedback\\n\\nIntroductory Guides\\n\\nSemantic Search\\n\\nContent Moderation\\n\\nEntity Extraction\\n\\nText ClassificationText Classification (Classify)Text Classification (Embed)\\n\\nCo.summarize (Beta)\\n\\nCo.rerank (Beta)\\n\\nResponsible Use\\n\\nOverviewUsage GuidelinesModel LimitationsData Statement\\n\\nModels\\n\\nSecurity\\n\\nEnvironmental Impact\\n\\nLLM University\\n\\nWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?\\n\\nModule 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language Models\\n\\nModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text Representation\\n\\nModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere\\'s Command ModelConclusion - Text Generation\\n\\nAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLP\\n\\nAppendix 2: Building AppsApp Examples\\n\\nTokens\\n\\nSuggest Edits\\n\\nOur language models understand \"tokens\" rather than characters or bytes. One token can be a part of a word, an entire word, or punctuation. Very common words like \"water\" will have their own unique tokens. A longer, less frequent word might be encoded into 2-3 tokens, e.g. \"waterfall\" gets encoded into two tokens, one for \"water\" and one for \"fall\". Note that tokenization is sensitive to whitespace and capitalization.\\n\\nHere are some references to calibrate how many tokens are in a text:\\n\\none word tends to be about 2-3 tokens\\n\\na verse of a song is about 128 tokens\\n\\nthis short article has about 300 tokens\\n\\nThe number of tokens per word depends on the complexity of the text. Simple text may approach 1 token per word on average, while complex texts may use less common words that require 3-4 tokens per word on average. Our representation models are currently limited to processing sequences with a maximum length of 4096 tokens. Generation models support up to 2048 tokens.\\n\\nOur vocabulary of tokens is created using Byte Pair Encoding.\\n\\nTurning text into tokens.\\n\\nHow to pick max_tokens when sampling\\n\\nThe easiest way to determine a good number of tokens is to guess and check using our playground. It is common to request more tokens than required and then run additional processing to retrieve the desired output.\\n\\nUpdated 22 days ago\\n\\nTable of Contents\\n\\nHow to pick max_tokens when sampling', metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/tokens'}),\n",
       " Document(page_content=\"Jump to Content\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nSearch\\n\\nGet Started\\n\\nThe Cohere Platform\\n\\nIntroduction to Large Language Models\\n\\nPlayground Overview\\n\\nQuickstart Tutorials\\n\\nGoing Live\\n\\nIntegrations\\n\\nLearn\\n\\nKey ConceptsEmbeddingsPrompt EngineeringTokens\\n\\nGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-p\\n\\nCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model Metrics\\n\\nMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported Languages\\n\\nRerankingReranking Best Practices\\n\\nGenerating Feedback\\n\\nIntroductory Guides\\n\\nSemantic Search\\n\\nContent Moderation\\n\\nEntity Extraction\\n\\nText ClassificationText Classification (Classify)Text Classification (Embed)\\n\\nCo.summarize (Beta)\\n\\nCo.rerank (Beta)\\n\\nResponsible Use\\n\\nOverviewUsage GuidelinesModel LimitationsData Statement\\n\\nModels\\n\\nSecurity\\n\\nEnvironmental Impact\\n\\nLLM University\\n\\nWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?\\n\\nModule 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language Models\\n\\nModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text Representation\\n\\nModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere's Command ModelConclusion - Text Generation\\n\\nAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLP\\n\\nAppendix 2: Building AppsApp Examples\\n\\nCommand Nightly\\n\\nSuggest Edits\\n\\nðŸš§\\n\\nThis model is in active development. Our team is pushing hard to ensure command is safe, and helpful for our users. As you experiment with the model and run into issues, please help us by flagging it to our team by emailing us at [email\\xa0protected]\\n\\nTo reduce the turnaround time for releases, we have nightly versions of command available. This means that every week, you can expect the performance of command-nightly-* to improve.\\n\\nðŸ“˜\\n\\nExample Prompts\\n\\nGet Started\\n\\nSet up\\n\\nInstall the SDK, if you haven't already.\\n\\npip install cohere\\n\\nThen, set up the Cohere client.\\n\\nCreate prompt\\n\\nGenerate text\\n\\nFAQ\\n\\nCan users train Command?\\nUsers cannot train Command in OS at this time. However, our team can handle this on a case by case basis. Please email [email\\xa0protected] if youâ€™re interested in training this model.\\n\\nWhere can I leave feedback about Cohere's generative models?\\nPlease leave feedback in #product-updates on Discord.\\n\\nUpdated 22 days ago\\n\\nTable of Contents\\n\\nExample Prompts\\n\\n\\nGet Started\\n\\nSet up\\nCreate prompt\\nGenerate text\\n\\n\\n\\nFAQ\", metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/command-beta'}),\n",
       " Document(page_content=\"Jump to Content\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nSearch\\n\\nGet Started\\n\\nThe Cohere Platform\\n\\nIntroduction to Large Language Models\\n\\nPlayground Overview\\n\\nQuickstart Tutorials\\n\\nGoing Live\\n\\nIntegrations\\n\\nLearn\\n\\nKey ConceptsEmbeddingsPrompt EngineeringTokens\\n\\nGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-p\\n\\nCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model Metrics\\n\\nMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported Languages\\n\\nRerankingReranking Best Practices\\n\\nGenerating Feedback\\n\\nIntroductory Guides\\n\\nSemantic Search\\n\\nContent Moderation\\n\\nEntity Extraction\\n\\nText ClassificationText Classification (Classify)Text Classification (Embed)\\n\\nCo.summarize (Beta)\\n\\nCo.rerank (Beta)\\n\\nResponsible Use\\n\\nOverviewUsage GuidelinesModel LimitationsData Statement\\n\\nModels\\n\\nSecurity\\n\\nEnvironmental Impact\\n\\nLLM University\\n\\nWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?\\n\\nModule 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language Models\\n\\nModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text Representation\\n\\nModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere's Command ModelConclusion - Text Generation\\n\\nAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLP\\n\\nAppendix 2: Building AppsApp Examples\\n\\nLikelihood\\n\\nSuggest Edits\\n\\nOur models learn to model language by reading text scraped from the internet. Given a sentence, such as I like to bake cookies, the model is asked to repeatedly predict what the next token [?] is:\\n\\nIntuition\\n\\nLikelihood of a token\\n\\nUpdated 22 days ago\\n\\nLikelihood Evaluation\\n\\nTable of Contents\\n\\nIntuition\", metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/likelihood'}),\n",
       " Document(page_content=\"Jump to Content\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nSearch\\n\\nGet Started\\n\\nThe Cohere Platform\\n\\nIntroduction to Large Language Models\\n\\nPlayground Overview\\n\\nQuickstart Tutorials\\n\\nGoing Live\\n\\nIntegrations\\n\\nLearn\\n\\nKey ConceptsEmbeddingsPrompt EngineeringTokens\\n\\nGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-p\\n\\nCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model Metrics\\n\\nMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported Languages\\n\\nRerankingReranking Best Practices\\n\\nGenerating Feedback\\n\\nIntroductory Guides\\n\\nSemantic Search\\n\\nContent Moderation\\n\\nEntity Extraction\\n\\nText ClassificationText Classification (Classify)Text Classification (Embed)\\n\\nCo.summarize (Beta)\\n\\nCo.rerank (Beta)\\n\\nResponsible Use\\n\\nOverviewUsage GuidelinesModel LimitationsData Statement\\n\\nModels\\n\\nSecurity\\n\\nEnvironmental Impact\\n\\nLLM University\\n\\nWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?\\n\\nModule 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language Models\\n\\nModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text Representation\\n\\nModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere's Command ModelConclusion - Text Generation\\n\\nAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLP\\n\\nAppendix 2: Building AppsApp Examples\\n\\nNumber of Generations\\n\\nSuggest Edits\\n\\nWhen you call the Generate endpoint, you have the option to generate multiple generations in a single call. This is done by setting the num_generations parameter.\\n\\nGenerating multiple outputs in a single API call.\\n\\nEach generation comes with its set of likelihood values, which consists of:\\n\\nThe likelihood of each generated token\\n\\nThe average likelihood of all generated tokens.\\n\\nExample\\n\\nThis example uses the input: “This curved gaming monitor delivers ...”\\n\\nThe output generated with a maximum token set of 4 and sorted by average token likelihood are:\\n\\n0.96\\n\\na truly immersive experience\\n\\n1.11\\n\\na virtually seamless view\\n\\n1.70\\n\\nthe ultimate viewing experience\\n\\n2.15\\n\\na 144Hz rapid\\n\\n2.44\\n\\na comfortable and stylish\\n\\nYou can use these outputs in a number of ways, for example, by selecting the one with the highest likelihood as the final output or by presenting these as options in your application.\\n\\nUpdated 22 days ago\\n\\nTable of Contents\\n\\nExample\", metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/number-of-generations'}),\n",
       " Document(page_content='Jump to Content\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nSearch\\n\\nGet Started\\n\\nThe Cohere Platform\\n\\nIntroduction to Large Language Models\\n\\nPlayground Overview\\n\\nQuickstart Tutorials\\n\\nGoing Live\\n\\nIntegrations\\n\\nLearn\\n\\nKey ConceptsEmbeddingsPrompt EngineeringTokens\\n\\nGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-p\\n\\nCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model Metrics\\n\\nMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported Languages\\n\\nRerankingReranking Best Practices\\n\\nGenerating Feedback\\n\\nIntroductory Guides\\n\\nSemantic Search\\n\\nContent Moderation\\n\\nEntity Extraction\\n\\nText ClassificationText Classification (Classify)Text Classification (Embed)\\n\\nCo.summarize (Beta)\\n\\nCo.rerank (Beta)\\n\\nResponsible Use\\n\\nOverviewUsage GuidelinesModel LimitationsData Statement\\n\\nModels\\n\\nSecurity\\n\\nEnvironmental Impact\\n\\nLLM University\\n\\nWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?\\n\\nModule 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language Models\\n\\nModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text Representation\\n\\nModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere\\'s Command ModelConclusion - Text Generation\\n\\nAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLP\\n\\nAppendix 2: Building AppsApp Examples\\n\\nTemperature\\n\\nSuggest Edits\\n\\nSampling from generation models incorporates randomness, so that the same prompt may yield different outputs each time you hit \"generate\". Temperature is a number used to tune the degree of randomness.\\n\\nHow to pick temperature when sampling\\n\\nA lower temperature means less randomness; a temperature of 0 will always yield the same output. Lower temperatures (less than 1) are more appropriate when performing tasks that have a \"correct\" answer, like question answering or summarization. If the model starts repeating itself this is a sign that the temperature is too low.\\n\\nHigh temperature means more randomness, which can help the model give more creative outputs. If the model starts going off topic or giving non-sensical outputs, this is a sign that the temperature is too high.\\n\\nAdjusting the temperature setting\\n\\nTemperature can be tuned for different problems, but most people will find that a temperature of 1 is a good starting point.\\n\\nAs sequences get longer, the model naturally becomes more confident in its predictions, so you can raise the temperature much higher for long prompts without going off topic. In contrast, using high temperatures on short prompts can lead to outputs being very unstable.\\n\\nUpdated 22 days ago\\n\\nTable of Contents\\n\\nHow to pick temperature when sampling', metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/temperature'}),\n",
       " Document(page_content='Jump to Content\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nSearch\\n\\nGet Started\\n\\nThe Cohere Platform\\n\\nIntroduction to Large Language Models\\n\\nPlayground Overview\\n\\nQuickstart Tutorials\\n\\nGoing Live\\n\\nIntegrations\\n\\nLearn\\n\\nKey ConceptsEmbeddingsPrompt EngineeringTokens\\n\\nGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-p\\n\\nCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model Metrics\\n\\nMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported Languages\\n\\nRerankingReranking Best Practices\\n\\nGenerating Feedback\\n\\nIntroductory Guides\\n\\nSemantic Search\\n\\nContent Moderation\\n\\nEntity Extraction\\n\\nText ClassificationText Classification (Classify)Text Classification (Embed)\\n\\nCo.summarize (Beta)\\n\\nCo.rerank (Beta)\\n\\nResponsible Use\\n\\nOverviewUsage GuidelinesModel LimitationsData Statement\\n\\nModels\\n\\nSecurity\\n\\nEnvironmental Impact\\n\\nLLM University\\n\\nWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?\\n\\nModule 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language Models\\n\\nModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text Representation\\n\\nModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere\\'s Command ModelConclusion - Text Generation\\n\\nAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLP\\n\\nAppendix 2: Building AppsApp Examples\\n\\nTop-k & Top-p\\n\\nSuggest Edits\\n\\nThe method of picking output tokens is a key concept in text generation with language models. There are several methods (also called decoding strategies) for picking the output token and two of the leading ones are top-k sampling and top-p sampling.\\n\\nLet’s look at the example where the input to the model is the prompt The name of that country is the:\\n\\nExample output of a generation language model.\\n\\nThe output token in this case, United, was picked in the last step of processing -- after the language model has processed the input and calculated a likelihood score for every token in its vocabulary. This score indicates the likelihood that it will be the next token in the sentence (based on all the text the model was trained on).\\n\\nThe model calculates a likelihood for each token in its vocabulary. The decoding strategy then picks one as the output.\\n\\n1. Pick the top token: greedy decoding\\n\\nYou can see in this example that we picked the token with the highest likelihood, ‘United’.\\n\\nAlways picking the highest scoring token is called \"Greedy Decoding\". It\\'s useful but has some drawbacks.\\n\\nGreedy decoding is a reasonable strategy but has some drawbacks such as outputs with repetitive loops of text. Think of the suggestions in your smartphone\\'s auto-suggest. When you continually pick the highest suggested word, it may devolve into repeated sentences.\\n\\n2. Pick from amongst the top tokens: top-k\\n\\nAnother commonly used strategy is to sample from a shortlist of the top 3 tokens. This approach allows the other high-scoring tokens a chance of being picked. The randomness introduced by this sampling helps the quality of generation in a lot of scenarios.\\n\\nAdding some randomness helps make output text more natural. In top-3 decoding, we first shortlist three tokens then sample one of them considering their likelihood scores.\\n\\nMore broadly, choosing the top three tokens means setting the top-k parameter to 3. Changing the top-k parameter sets the size of the shortlist the model samples from as it outputs each token. Setting top-k to 1 gives us greedy decoding.\\n\\nAdjusting to the top-k setting.\\n\\n3. Pick from amongst the top tokens whose probabilities add up to 15%: top-p\\n\\nThe difficulty of selecting the best top-k value opens the door for a popular decoding strategy that dynamically sets the size of the shortlist of tokens. This method, called Nucleus Sampling, shortlists the top tokens whose sum of likelihoods does not exceed a certain value. A toy example with a top-p value of 0.15 could look like this:\\n\\nIn top-p, the size of the shortlist is dynamically selected based on the sum of likelihood scores reaching some threshold.\\n\\nUpdated 22 days ago\\n\\nTable of Contents\\n\\n1. Pick the top token: greedy decoding\\n2. Pick from amongst the top tokens: top-k\\n3. Pick from amongst the top tokens whose probabilities add up to 15%: top-p', metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/controlling-generation-with-top-k-top-p'}),\n",
       " Document(page_content=\"Jump to Content\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nSearch\\n\\nGet Started\\n\\nThe Cohere Platform\\n\\nIntroduction to Large Language Models\\n\\nPlayground Overview\\n\\nQuickstart Tutorials\\n\\nGoing Live\\n\\nIntegrations\\n\\nLearn\\n\\nKey ConceptsEmbeddingsPrompt EngineeringTokens\\n\\nGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-p\\n\\nCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model Metrics\\n\\nMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported Languages\\n\\nRerankingReranking Best Practices\\n\\nGenerating Feedback\\n\\nIntroductory Guides\\n\\nSemantic Search\\n\\nContent Moderation\\n\\nEntity Extraction\\n\\nText ClassificationText Classification (Classify)Text Classification (Embed)\\n\\nCo.summarize (Beta)\\n\\nCo.rerank (Beta)\\n\\nResponsible Use\\n\\nOverviewUsage GuidelinesModel LimitationsData Statement\\n\\nModels\\n\\nSecurity\\n\\nEnvironmental Impact\\n\\nLLM University\\n\\nWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?\\n\\nModule 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language Models\\n\\nModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text Representation\\n\\nModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere's Command ModelConclusion - Text Generation\\n\\nAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLP\\n\\nAppendix 2: Building AppsApp Examples\\n\\nTraining Custom Models\\n\\nSuggest Edits\\n\\nAn Overview of Model Training\\n\\nCohere's platform gives you the ability to train a Large Language Model (LLM) and customize it with a dataset to excel at a specific task. Custom models can lead to some of the best performing NLP models for a wide number of tasks.\\n\\nIn this article, we look at training a generation model. See here for training a representation model.\\n\\nCustom models use training data to turn a baseline model into a fine-tuned model.\\n\\nWhen to Train a Custom Model\\n\\nTraining large language models is recommended when you want to teach the model a new task like  or specific domain knowledge like the different gaits of a horse or your company's unique knowledge base. Common knowledge, like the colour of the sky, does not require training. Training is also helpful for generating or understanding data in a specific writing style or format.\\n\\nIntuition\\n\\nLet's take a representation model as an example, where we finetune a model for a classification task with training data consisting of three classes.\\n\\nTo get an idea of how a representation model performs, we can project the embeddings it generates on a 2-dimensional plot, as per the image below. This image was taken from actual model outputs in the Playground.\\n\\nThe distance between two data points represents how semantically similar they are—the closer they are, the more similar they are, and vice versa. A good model will have a clear separation between classes. To test the model, here we have fifteen data points, five for each class, in which the classes are unknown to the model.\\n\\nWith a baseline model (left plot), we get a good separation between classes, which shows that it can perform well in this task.\\n\\nBut with a custom model (right plot), the separation becomes even more apparent. Similar data points are now pushed even closer together and further apart from the rest. This indicates that the model has adapted to the additional data it received during training, hence is more likely to perform even better in this task.\\n\\nIn real applications, this makes a huge difference. One example is a toxicity classifier to help content moderators automatically flag toxic content on their platforms. Not all online platforms define toxicity the same way, and each will have different language nuances to accommodate. For example, a gaming platform, an online community for kids, and a social media platform—each would have a different interpretation of the exact same data. This is where model training can help, where a model can be customized to your specific needs.\\n\\nCreates a custom model that adapts to the training data.\\n\\nUpdated 8 days ago\\n\\nTable of Contents\\n\\nAn Overview of Model Training\\n\\n\\nWhen to Train a Custom Model\\n\\nIntuition\", metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/training-custom-models'}),\n",
       " Document(page_content=\"Jump to Content\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nSearch\\n\\nGet Started\\n\\nThe Cohere Platform\\n\\nIntroduction to Large Language Models\\n\\nPlayground Overview\\n\\nQuickstart Tutorials\\n\\nGoing Live\\n\\nIntegrations\\n\\nLearn\\n\\nKey ConceptsEmbeddingsPrompt EngineeringTokens\\n\\nGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-p\\n\\nCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model Metrics\\n\\nMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported Languages\\n\\nRerankingReranking Best Practices\\n\\nGenerating Feedback\\n\\nIntroductory Guides\\n\\nSemantic Search\\n\\nContent Moderation\\n\\nEntity Extraction\\n\\nText ClassificationText Classification (Classify)Text Classification (Embed)\\n\\nCo.summarize (Beta)\\n\\nCo.rerank (Beta)\\n\\nResponsible Use\\n\\nOverviewUsage GuidelinesModel LimitationsData Statement\\n\\nModels\\n\\nSecurity\\n\\nEnvironmental Impact\\n\\nLLM University\\n\\nWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?\\n\\nModule 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language Models\\n\\nModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text Representation\\n\\nModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere's Command ModelConclusion - Text Generation\\n\\nAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLP\\n\\nAppendix 2: Building AppsApp Examples\\n\\nComparing Baseline and Custom Models\\n\\nSuggest Edits\\n\\nToken likelihood is a useful tool for model evaluation. For instance, let's say you've trained a custom model and would like to know how much it's improved over the default model - you could use token likelihoods to compare the performance of the models on some held-out text. Here is a quick demonstration of how to use the return_likelihoods parameter from the Generate endpoint for model evaluation.\\n\\nExample Setup\\n\\nLet's say we've custom trained a base-light model on Shakespeare data. We'd like to confirm that this custom model has higher likelihood on Shakespeare text compared to the default model. To do this, we could hold out the following snippet from the training data:\\n\\nThen we could use the following example code to retrieve the average log-likelihood of the above snippet:\\n\\nResults\\n\\nThe following are the average log-likelihoods of the snippet using the baseline and custom base-light models:\\n\\nbase-light\\n\\n2.99\\n\\ncustom-base-light\\n\\n1.12\\n\\nThis demonstrates that customizing this model increased the likelihood of Shakespeare data!\\n\\nUpdated 22 days ago\\n\\nTable of Contents\\n\\nExample Setup\\nResults\", metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/likelihood-evaluation'}),\n",
       " Document(page_content='Jump to Content\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nSearch\\n\\nGet Started\\n\\nThe Cohere Platform\\n\\nIntroduction to Large Language Models\\n\\nPlayground Overview\\n\\nQuickstart Tutorials\\n\\nGoing Live\\n\\nIntegrations\\n\\nLearn\\n\\nKey ConceptsEmbeddingsPrompt EngineeringTokens\\n\\nGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-p\\n\\nCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model Metrics\\n\\nMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported Languages\\n\\nRerankingReranking Best Practices\\n\\nGenerating Feedback\\n\\nIntroductory Guides\\n\\nSemantic Search\\n\\nContent Moderation\\n\\nEntity Extraction\\n\\nText ClassificationText Classification (Classify)Text Classification (Embed)\\n\\nCo.summarize (Beta)\\n\\nCo.rerank (Beta)\\n\\nResponsible Use\\n\\nOverviewUsage GuidelinesModel LimitationsData Statement\\n\\nModels\\n\\nSecurity\\n\\nEnvironmental Impact\\n\\nLLM University\\n\\nWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?\\n\\nModule 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language Models\\n\\nModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text Representation\\n\\nModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere\\'s Command ModelConclusion - Text Generation\\n\\nAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLP\\n\\nAppendix 2: Building AppsApp Examples\\n\\nTraining a Generative Model\\n\\nSuggest Edits\\n\\nTraining a generation model consists of a few simple steps. Let’s go through the steps for training a generation model.\\n\\nOn the Cohere dashboard, go to the models page and click on \"Create a custom model\".\\n\\nChoose the Generate Option\\n\\nClick on the tile that says \"Generate\".\\n\\nUpload Your Data\\n\\nUpload your data by clicking on ‘Choose a .txt file’. Your data should be in TXT format.\\nIf your data contains separators to distinguish between training examples, add the separator string in the ‘Data separator’ field (for example: --SEPARATOR--). If your data doesn’t contain separators, leave the field blank.\\n\\nOnce done, click on ‘Review data’.\\n\\nReview Data\\n\\nThe next window will show you a few samples of your data that has been split. If you included data separators, the data will be split according to the separator. If you didn’t, the split will be done automatically.\\n\\nIf you are happy with how the samples look, click on ‘Continue’ at the bottom of the page.\\n\\nStart Training\\n\\nGive your model a nickname! Now, everything is set for custom training to begin. Press Start Training to begin!\\n\\nWe can’t wait to see what you start building! Share your projects or find support on our Discord.\\n\\nUpdated 22 days ago\\n\\nTroubleshooting A Trained Model\\n\\nTable of Contents\\n\\nChoose the Generate Option\\nUpload Your Data\\nReview Data\\nStart Training', metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/training-a-generative-model'}),\n",
       " Document(page_content='Jump to Content\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nSearch\\n\\nGet Started\\n\\nThe Cohere Platform\\n\\nIntroduction to Large Language Models\\n\\nPlayground Overview\\n\\nQuickstart Tutorials\\n\\nGoing Live\\n\\nIntegrations\\n\\nLearn\\n\\nKey ConceptsEmbeddingsPrompt EngineeringTokens\\n\\nGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-p\\n\\nCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model Metrics\\n\\nMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported Languages\\n\\nRerankingReranking Best Practices\\n\\nGenerating Feedback\\n\\nIntroductory Guides\\n\\nSemantic Search\\n\\nContent Moderation\\n\\nEntity Extraction\\n\\nText ClassificationText Classification (Classify)Text Classification (Embed)\\n\\nCo.summarize (Beta)\\n\\nCo.rerank (Beta)\\n\\nResponsible Use\\n\\nOverviewUsage GuidelinesModel LimitationsData Statement\\n\\nModels\\n\\nSecurity\\n\\nEnvironmental Impact\\n\\nLLM University\\n\\nWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?\\n\\nModule 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language Models\\n\\nModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text Representation\\n\\nModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere\\'s Command ModelConclusion - Text Generation\\n\\nAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLP\\n\\nAppendix 2: Building AppsApp Examples\\n\\nTraining a Representation Model\\n\\nSuggest Edits\\n\\nIn this article, we look at training a representation model, which covers both the Embed and Classify endpoints.\\n\\nSee here if you\\'d like to get an overview of training a generation model.\\n\\nA Text Classification Example\\n\\nText classification is one of the most common language understanding tasks. A lot of business use cases can be mapped to text classification. Examples include:\\n\\nEvaluating the tone and sentiment of an incoming customer message (e.g. classes: ‚Äúpositive‚Äù and ‚Äúnegative‚Äù)\\n\\nRouting incoming customer messages to the appropriate agent (e.g. classes: ‚Äúbilling‚Äù, ‚Äútech support‚Äù, ‚Äúother‚Äù)\\n\\nEvaluating if a user comment needs to be flagged for moderator attention (e.g. classes: ‚Äúflag for moderation‚Äù, ‚Äúneutral‚Äù)\\n\\nIn this article, we\\'ll train a representation model for sentiment classification.\\n\\nA sentiment classifier assigns a piece of text as either \\'positive\\' or \\'negative\\'.\\n\\nWhy Train a Representation Model\\n\\nTraining leads to the best classification results a language model can achieve. That said, untrained baseline embeddings can perform well in a lot of tasks (See the text classification article for an example of how to train a sentiment classifier on top of baseline embedding models). But if we need to get that extra boost in performance, training makes our LLM become a specialist for the task we care about.\\n\\nHow to Train a Representation Model\\n\\nThe training file is a Comma Separated Values (CSV) file with a column for text and another for the number of the class. The contents of that file can look like this:\\n\\nA table with example texts and a numeric label for each text (0 for negative texts, 1 for positive texts).\\n\\nThe CSV file can be prepared in Excel or in text format like this with a .csv extension.\\n\\nThat CSV file is then what you upload in the Representation training dialog box in the Playground.\\n\\n\\uf8ffüìò\\n\\nNew to Cohere?\\n\\nGet started now and get unprecedented access to world-class Generation and Representation models with billions of parameters.\\n\\nWhat Training a Representation Model Does\\n\\nA representation LLM is excellent at generating sentence embeddings (lists of numbers that capture the meaning of the sentences). These embeddings are great at indicating how similar sentences are to each other. We can plot them to explore their similarities and differences (points that are close together have similar embeddings).\\n\\nConsider a case where we have five customer messages. Visualizing their embeddings can look like this:\\n\\nScatter plot of five message example. Three of them are about shipping and are clustered close together.\\n\\nSuch an embedding captures semantic similarity ‚Äì so for example, messages about shipping are close to each other on the left.\\n\\nIf we want to build the best sentiment classifier, however, then we need our embedding model to care about sentiment more than it cares about semantic similarity.\\n\\nIf we colour the points depending on their sentiment, it could look like this:\\n\\nThe same scatter plot of the five messages, except the colours of the points indicate which messages are positive and which are negative.\\n\\nSuccessfully training a representation model on customer sentiment leads to a model which embeds sentences in this fashion:\\n\\nA different scatterplot. Now positive messages are grouped together on the right, and negative messages are clustered together on the left.\\n\\nTraining an embedding model on customer sentiment leads to an embedding model where the embeddings of positive comments are similar to each other and distinct from those of negative comments. This leads to better sentiment classification results.\\n\\nTips to improve embedding/training quality\\n\\nThere are several things to take into account to achieve the best trained embeddings:\\n\\nText cleaning: Improving the quality of the data is often the best investment in problem solving with machine learning. If the text, for example contains symbols or URLs or HTML code which are not needed for a specific task, make sure to remove them from the trained file (and from the text you later send to the trained model).\\n\\nNumber of examples: The minimum number of labeled examples is 250, though we advise having at least 500 to achieve good training results. The more examples the better.\\n\\nNumber of examples per class: In addition to the overall number of examples, it\\'s important to have many examples of each class in the dataset.\\n\\nMix of examples in dataset: We recommend that you have a balanced (roughly equal) number of examples per class in your dataset.\\n\\nLength of texts: The context size for text is currently 512 tokens. Subsequent tokens are truncated.\\n\\nDeduplication: Ensure that each labelled example in your dataset is unique.\\n\\nHigh quality test set: In the data upload step, upload a separate test set of examples that you want to see the model benchmarked on. These can be examples that were manually written or verified.\\n\\nTraining a Representation Model: Step-by-step\\n\\nTraining a representation model consists of a few simple steps. Let‚Äôs go through the steps for training a representation model.\\n\\nOn the Cohere dashboard, go to the models page and click on \"Create a custom model\"\\n\\nChoose the Embed or Classify Option\\n\\nClick on the tile that says \"Classify\" or \"Embed\".\\n\\nBoth classify and embed endpoints will custom train a representation model\\n\\nUpload Your Data\\n\\nUpload your training dataset data by going to ‚ÄòTraining data‚Äô and clicking on the upload file button. Your data should be in CSV format with exactly two columns‚Äîthe first and second columns consisting of the examples and labels respectively.\\n\\nOptionally, you can upload a validation dataset. This will not be used during training but instead, will be used for evaluating the model‚Äôs performance post-training. To do so, go to ‚ÄòUpload validation set (optional)‚Äô and repeat the same steps you just did with the training dataset. If you don‚Äôt upload a validation dataset, the platform will automatically set aside a validation dataset from the training dataset.\\n\\nAt this point in time, if there are labels with less than 5 unique examples, we will remove those labels from your training set.\\n\\nAs shown above, the label \\'Area\\' had fewer than 5 examples so it has been removed from the training set.\\n\\nOnce done, click on ‚ÄòNext‚Äô.\\n\\nPreview Your Data\\n\\nThe preview window will show a few samples of your training dataset, and if you uploaded it, your validation dataset.\\nToggle between the tabs \\'Training\\' and \\'Validation\\' to see a sample of your respective datasets.\\n\\nAt the bottom of this page, the distribution of labels in each respective dataset is shown.\\n\\nIf you are happy with how the samples look, click on \\'Continue\\'.\\n\\nStart Training\\n\\nNow, everything is set for training to begin. Click on \\'Start training\\' to proceed.\\n\\nWe can‚Äôt wait to see what you start building! Share your projects or find support on our Discord.\\n\\nUpdated 22 days ago\\n\\nTable of Contents\\n\\nA Text Classification Example\\nWhy Train a Representation Model\\nHow to Train a Representation Model\\nWhat Training a Representation Model Does\\nTips to improve embedding/training quality\\n\\n\\n\\nTraining a Representation Model: Step-by-step\\n\\nChoose the Embed or Classify Option\\nUpload Your Data\\nPreview Your Data\\nStart Training', metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/training-a-representation-model'}),\n",
       " Document(page_content=\"Jump to Content\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nSearch\\n\\nGet Started\\n\\nThe Cohere Platform\\n\\nIntroduction to Large Language Models\\n\\nPlayground Overview\\n\\nQuickstart Tutorials\\n\\nGoing Live\\n\\nIntegrations\\n\\nLearn\\n\\nKey ConceptsEmbeddingsPrompt EngineeringTokens\\n\\nGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-p\\n\\nCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model Metrics\\n\\nMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported Languages\\n\\nRerankingReranking Best Practices\\n\\nGenerating Feedback\\n\\nIntroductory Guides\\n\\nSemantic Search\\n\\nContent Moderation\\n\\nEntity Extraction\\n\\nText ClassificationText Classification (Classify)Text Classification (Embed)\\n\\nCo.summarize (Beta)\\n\\nCo.rerank (Beta)\\n\\nResponsible Use\\n\\nOverviewUsage GuidelinesModel LimitationsData Statement\\n\\nModels\\n\\nSecurity\\n\\nEnvironmental Impact\\n\\nLLM University\\n\\nWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?\\n\\nModule 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language Models\\n\\nModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text Representation\\n\\nModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere's Command ModelConclusion - Text Generation\\n\\nAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLP\\n\\nAppendix 2: Building AppsApp Examples\\n\\nTroubleshooting a Custom Model\\n\\nSuggest Edits\\n\\nIn this post, we answer frequently asked questions about training models.\\n\\nTroubleshooting Representation Models\\n\\nGathering enough data\\n\\nWhile our Classify endpoint enables a user to build a classifier with just 5 examples per label, this classifier runs on our baseline model which has not been trained for specific use cases. Your dataset must contain at least 250 labelled examples to start training.\\n\\nIf you are unable to locate a relevant labelled dataset from online sources, we suggest trying to generate labelled examples using our Generate endpoint. Check out this sample preset of a user generating product feedback to train a product feedback classifier.\\n\\nData formatting best practices\\n\\nEnsure your data is in a two-column csv. One column should be the sample text you'd like to classify or search, and the second column should be a label for the text. We recommend using a comma , as your delimiter.\\n\\nTo pass data validation, ensure that:\\n\\nThere are at least 5 examples for each label in your dataset\\n\\nYour dataset contains at least unique 250 examples in total (not 250 examples per label)\\n\\nYour data is encoded in UTF-8\\n\\nWe will automatically deduplicate your dataset\\n\\nFormatting errors for classification tasks\\n\\nCohere's Classify endpoint will return predictions for classes that sum up to 1. We currently do not support outputting classifications for multiple labels (known as multi-label classification). Each example text should be mapped to one label only.\\n\\nTake this example below:\\n\\nIn this case you will need to select one label for each headline.\\n\\nFormatting for search tasks\\n\\nAt this time, if you are intending to train a representation model to use Cohere's Embed endpoint to perform a search task (not predicting a label), you will still need to assign a label to texts for representation training.\\n\\nFor example, if you are building a search engine for Hacker News posts and you want to either cluster similar posts or associate posts with a certain keyword, you would create a labelled dataset with the post titles mapped to the keyword. See a few sample lines labelled below:\\n\\nIf you are topic modelling and trying to find clusters, we recommend trying the baseline model. Check out our blog post on topic modelling Hacker News posts.\\n\\nTroubleshooting auto evaluation metrics\\n\\nWhen you are viewing auto evaluation metrics during or after your model has finished training, you may find that the F1, Recall, and Precision metrics are missing. This may occur if your dataset is extremely imbalanced (e.g. A binary dataset with 95% positive labels and 5% negative labels) and the trained model fails to predict one of the labels at all. This does not prevent you from using this trained model, it is simply a warning.\\n\\nTo resolve this warning, try adding more examples for labels with less data.\\n\\nHow long does it take to train a model?\\n\\nTrainings are completed sequentially, and when you launch a training session, it is added to the end of a queue. Depending on the length of our training queue, training may take between 1 hour to a day to complete.\\n\\nUsing your trained model\\n\\nTo use your trained model in our API or SDKs, you must call it by its model UUID and not by its name. To get the model UUID, select the model in the playground and click Export Code. Select the library you are using and copy the code to call the model.\\n\\nThis is a screenshot of how to locate the model path to call your custom model.\\n\\nRestarting paused custom models\\n\\nAll trained models are paused after 24 hours of inactivity. To restart your model, select your model in the trained models panel and click on the Wake button, pictured below:\\n\\nThis is a screenshot of how to awaken a paused model.\\n\\nTroubleshooting failed training\\n\\nOur engineers review every individual failed training and will attempt to rectify it without any action on your part. We reach out to individuals with failed custom models we cannot resolve manually.\\n\\nPlease reach out to [email\\xa0protected] or post in our co:mmunity Discord if you have unanswered questions about training models.\\n\\nUpdated 22 days ago\\n\\nTable of Contents\\n\\nTroubleshooting Representation Models\\n\\nGathering enough data\\nData formatting best practices\\nFormatting errors for classification tasks\\nFormatting for search tasks\\nTroubleshooting auto evaluation metrics\\n\\n\\n\\nHow long does it take to train a model?\\n\\n\\nUsing your trained model\\n\\n\\nRestarting paused custom models\\n\\n\\nTroubleshooting failed training\", metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/training-troubleshooting'}),\n",
       " Document(page_content=\"Jump to Content\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nSearch\\n\\nGet Started\\n\\nThe Cohere Platform\\n\\nIntroduction to Large Language Models\\n\\nPlayground Overview\\n\\nQuickstart Tutorials\\n\\nGoing Live\\n\\nIntegrations\\n\\nLearn\\n\\nKey ConceptsEmbeddingsPrompt EngineeringTokens\\n\\nGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-p\\n\\nCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model Metrics\\n\\nMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported Languages\\n\\nRerankingReranking Best Practices\\n\\nGenerating Feedback\\n\\nIntroductory Guides\\n\\nSemantic Search\\n\\nContent Moderation\\n\\nEntity Extraction\\n\\nText ClassificationText Classification (Classify)Text Classification (Embed)\\n\\nCo.summarize (Beta)\\n\\nCo.rerank (Beta)\\n\\nResponsible Use\\n\\nOverviewUsage GuidelinesModel LimitationsData Statement\\n\\nModels\\n\\nSecurity\\n\\nEnvironmental Impact\\n\\nLLM University\\n\\nWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?\\n\\nModule 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language Models\\n\\nModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text Representation\\n\\nModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere's Command ModelConclusion - Text Generation\\n\\nAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLP\\n\\nAppendix 2: Building AppsApp Examples\\n\\nCustom Model Metrics\\n\\nSuggest Edits\\n\\nWhen you train a custom model, we provide you some measures to see how well your model might perform at the task provided.\\n\\nGenerate Model Metrics\\n\\nPlease note that Generate model outputs are often best evaluated qualitatively, so the performance metrics provided alone will not provide a comprehensive understanding of the model’s performance.\\n\\nWhen you train a Generate custom model, you will see metrics that look like this:\\n\\nAccuracy\\n\\nAccuracy is a measure of how many predictions the model made correctly out of all the predictions in an evaluation. To evaluate Generate models for accuracy, we ask it to predict certain words in the user uploaded data.\\n\\nThe number in the pill (eg. 13%) is the difference between the accuracy of the default model when the user started training, and the accuracy of the model that is deployed. This difference is a proxy for how much accuracy improvement was gained by training the model on the dataset.\\n\\nLoss\\n\\nLoss is a measure that describes how bad or wrong a prediction is. Accuracy may tell you how many predictions the model got wrong, but it will not describe how incorrect the wrong predictions are. If every prediction is perfect, the loss will be 0.\\n\\nTo evaluate Generate models for loss, we ask the model to predict certain words in the user provided data and evaluate how wrong the incorrect predictions are. A loss around 11 indicates totally random performance.\\n\\nFor this reason, the loss should decrease as the model improves. The number in the pill (e.g -0.56) is the difference between the loss when the default model started training and when it was deployed. This difference is a proxy for how much loss improvement was gained by training the model on your dataset.\\n\\nClassify and Embed Model Metrics\\n\\nClassify and Embed custom Models are both trained using data of examples mapping to predicted labels, and for that reason they are evaluated using the same methods and performance metrics. You can also provide a test set of data that we will use to calculate performance metrics. If a test set is not provided, we will split your training data randomly to calculate performance metrics.\\n\\nWhen you train Classify and Embed custom models, you will see metrics that look like this:\\n\\nAccuracy\\n\\nAccuracy is a measure of how many predictions the model made correctly out of all the predictions in an evaluation. To evaluate Embed and Classify models for accuracy, we ask the model to predict labels for the examples in the test set. In this case, the model predicted 95.31% of the labels correctly.\\n\\nThe number in the pill (eg. 75%) is the difference between the accuracy of the default model when the user started training, and the accuracy of the model that is deployed. This difference is a proxy for how much accuracy improvement was gained by training the model on the dataset.\\n\\nLoss\\n\\nLoss is a measure that describes how bad or wrong a prediction is. Accuracy may tell you how many predictions the model got wrong, but it will not describe how incorrect the wrong predictions are. If every prediction is perfect, the loss will be 0.\\n\\nTo evaluate Classify and Embed models for loss, we ask the model to predict labels for the examples in the test set and evaluate how wrong the incorrect predictions are.\\n\\nFor this reason, the loss should decrease as the model improves. The number in the pill (e.g -0.11) is the difference between the loss when the default model started training and when it was deployed. This difference is a proxy for how much loss improvement was gained by training the default model on your dataset.\\n\\nPrecision\\n\\nPrecision is a measure that shows, for a given label, how correct the model was when it predicted the label. It’s calculated by taking the number of true positives and dividing it by the sum of true positives and false positives.\\n\\nThis is calculated for every label. The number shown in the metrics are the macro-weighted average of the precision across labels.\\n\\nRecall\\n\\nRecall is a measure that shows how often the model predicted a given label correctly. It’s calculated by taking the number of true positives and dividing it by the sum of true positives and false negatives.\\n\\nThis is calculated for every label. The number shown in the metrics are the macro-weighted average of the recall across labels.\\n\\nF1\\n\\nOptimizing for either precision or recall often means sacrificing quality in the other. In the example above, 100% recall for label A does not mean that it was a great model, as evidenced by the precision. The F1 score attempts to provide a balanced measure of performance between precision and recall.\\n\\nThe number shown in the metrics are the macro-weighted average of F1 across labels.\\n\\nFor Recall, Precision, and F1, the number in the pill is a proxy for how much improvement was gained by training the default model on your dataset.\\n\\nYou can see the detailed calculations to evaluate Embed and Classify models in this blog post.\\n\\nUpdated 22 days ago\\n\\nTable of Contents\\n\\nGenerate Model Metrics\\n\\nAccuracy\\nLoss\\n\\n\\n\\nClassify and Embed Model Metrics\\n\\nAccuracy\\nLoss\\nPrecision\\nRecall\\nF1\", metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/custom-model-metrics'}),\n",
       " Document(page_content=\"Jump to Content\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nSearch\\n\\nGet Started\\n\\nThe Cohere Platform\\n\\nIntroduction to Large Language Models\\n\\nPlayground Overview\\n\\nQuickstart Tutorials\\n\\nGoing Live\\n\\nIntegrations\\n\\nLearn\\n\\nKey ConceptsEmbeddingsPrompt EngineeringTokens\\n\\nGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-p\\n\\nCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model Metrics\\n\\nMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported Languages\\n\\nRerankingReranking Best Practices\\n\\nGenerating Feedback\\n\\nIntroductory Guides\\n\\nSemantic Search\\n\\nContent Moderation\\n\\nEntity Extraction\\n\\nText ClassificationText Classification (Classify)Text Classification (Embed)\\n\\nCo.summarize (Beta)\\n\\nCo.rerank (Beta)\\n\\nResponsible Use\\n\\nOverviewUsage GuidelinesModel LimitationsData Statement\\n\\nModels\\n\\nSecurity\\n\\nEnvironmental Impact\\n\\nLLM University\\n\\nWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?\\n\\nModule 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language Models\\n\\nModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text Representation\\n\\nModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere's Command ModelConclusion - Text Generation\\n\\nAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLP\\n\\nAppendix 2: Building AppsApp Examples\\n\\nMultilingual Embedding Models\\n\\nSuggest Edits\\n\\nAt Cohere, we are committed to breaking down barriers and expanding access to cutting-edge NLP technologies that power projects across the globe. By making our innovative multilingual language models available to all developers, we continue to move toward our goal of empowering developers, researchers, and innovators with state-of-the-art NLP technologies that push the boundaries of Language AI.\\n\\nOur Multilingual Model maps text to a semantic vector space, positioning text with a similar meaning in close proximity. This process unlocks a range of valuable use cases for multilingual settings. For example, one can map a query to this vector space during a search to locate relevant documents nearby. This often yields search results that are several times better than keyword search.\\n\\nDifferences Between English and Multilingual Embedding Models\\n\\nUnlike our English language embedding model, our multilingual model was trained using dot product calculations. Using dot products produces a non-normalized similarity score, reflecting the magnitude of the two compared vectors. When this dimension is incorporated, multilingual embeddings perform better than standard. For more information on how our English language model works (using cosine similarity), see our introductory guide to the Cohere platform. The dimensions of our multilingual embeddings is 768 dimensions.\\n\\nUse Cases\\n\\nMultilingual Semantic Search: Improve your search results regardless of the language.\\n\\nAggregate Customer Feedback: Organize customer feedback across hundreds of languages, simplifying a major challenge for international operations.\\n\\nCross-Lingual Zero-Shot Content Moderation: Identify harmful content in online communities is challenging, especially as users speak hundreds of languages. Train a model with a few English examples, then detect harmful content in 100+ languages.\\n\\nGet Started\\n\\nTo get started using the multilingual embedding models, you can either query our endpoints or install our SDK to use the model within Python:\\n\\nModel Performance\\n\\nCohere: embed-multilingual-v2.0\\n\\n51.0\\n\\n55.8\\n\\n51.4\\n\\n64.6\\n\\nSentence-transformers:paraphrase-multilingual-mpnet-base-v2\\n\\n46.7\\n\\n44.4\\n\\n15.3\\n\\n56.1\\n\\nGoogle: LaBSE\\n\\n41.0\\n\\n20.9\\n\\n13.2\\n\\n59.2\\n\\nGoogle: Universal Sentence Encoder\\n\\n40.1\\n\\n14.3\\n\\n3.4\\n\\n59.8\\n\\nList of Supported Languages\\n\\nOur multilingual embedding model supports over 100 languages, including Chinese, Spanish, and French. For a full list of languages we support, please reference this page.\\n\\nUpdated 22 days ago\\n\\nTable of Contents\\n\\nDifferences Between English and Multilingual Embedding Models\\nUse Cases\\nGet Started\\nModel Performance\\nList of Supported Languages\", metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/multilingual-language-models'}),\n",
       " Document(page_content=\"Jump to Content\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nSearch\\n\\nGet Started\\n\\nThe Cohere Platform\\n\\nIntroduction to Large Language Models\\n\\nPlayground Overview\\n\\nQuickstart Tutorials\\n\\nGoing Live\\n\\nIntegrations\\n\\nLearn\\n\\nKey ConceptsEmbeddingsPrompt EngineeringTokens\\n\\nGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-p\\n\\nCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model Metrics\\n\\nMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported Languages\\n\\nRerankingReranking Best Practices\\n\\nGenerating Feedback\\n\\nIntroductory Guides\\n\\nSemantic Search\\n\\nContent Moderation\\n\\nEntity Extraction\\n\\nText ClassificationText Classification (Classify)Text Classification (Embed)\\n\\nCo.summarize (Beta)\\n\\nCo.rerank (Beta)\\n\\nResponsible Use\\n\\nOverviewUsage GuidelinesModel LimitationsData Statement\\n\\nModels\\n\\nSecurity\\n\\nEnvironmental Impact\\n\\nLLM University\\n\\nWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?\\n\\nModule 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language Models\\n\\nModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text Representation\\n\\nModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere's Command ModelConclusion - Text Generation\\n\\nAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLP\\n\\nAppendix 2: Building AppsApp Examples\\n\\nLanguage Detection\\n\\nSuggest Edits\\n\\nLanguage detection is a necessary first step for businesses that deal with multilingual user bases. Whether you are working with a single multi-lingual model or a multi model environment, understanding the language of a request (e.g. query, input) is paramount to a good user experience.\\n\\nCo.detect_language is an endpoint gives the following information for a text input:\\n\\nThe full name (language_name) of the language the input is in.\\n\\nA language_code describing the language the input is in. For example, the ISO code for English is en.\\n\\nUse Cases\\n\\nSingle Model Environment\\n\\nUse a single multilingual model to handle both english and non-english queries. Identify the language of an incoming query and filter the results of your results by matching languages for monolingual retrieval with a multilingual model - in addition, you can specify which languages you want to filter for in a cross-lingual retrieval setup.\\n\\nMulti Model Environment\\n\\nUse multiple models for English and non-English embeddings. Identify a query in its respective language and route the request to different models depending on your setup. For example, if a query is in identified as English, route it to our default English embedding model, if not, route it to our multilingual embedding model.\\n\\nExamples\\n\\nInput\\n\\nResponse\\n\\nList of Supported Languages\\n\\naf\\n\\nAfrikaans\\n\\nals\\n\\nAlbanian\\n\\nam\\n\\nAmharic\\n\\nan\\n\\nAragonese\\n\\nar\\n\\nArabic\\n\\narz\\n\\nArabic (Egyptian)\\n\\nas\\n\\nAssamese\\n\\nast\\n\\nAsturian\\n\\nav\\n\\nAvaric\\n\\naz\\n\\nAzerbaijani\\n\\nazb\\n\\nSouth Azerbaijani\\n\\nba\\n\\nBashkir\\n\\nbar\\n\\nBavarian\\n\\nbcl\\n\\nCentral Bikol\\n\\nbe\\n\\nBelarusian\\n\\nbg\\n\\nBulgarian\\n\\nbh\\n\\nBihari\\n\\nbn\\n\\nBengali\\n\\nbo\\n\\nTibetan\\n\\nbpy\\n\\nBishnupriya Manipuri\\n\\nbr\\n\\nBreton\\n\\nbs\\n\\nBosnian\\n\\nbxr\\n\\nBuryat\\n\\nca\\n\\nCatalan\\n\\ncbk\\n\\nChavacano\\n\\nce\\n\\nChechen\\n\\nceb\\n\\nCebuano\\n\\nckb\\n\\nCentral Kurdish\\n\\nco\\n\\nCorsican\\n\\ncs\\n\\nCzech\\n\\ncv\\n\\nChuvash\\n\\ncy\\n\\nWelsh\\n\\nda\\n\\nDanish\\n\\nde\\n\\nGerman\\n\\ndiq\\n\\nZazaki\\n\\ndsb\\n\\nLower Sorbian\\n\\ndty\\n\\nDoteli\\n\\ndv\\n\\nDhivehi\\n\\nel\\n\\nGreek\\n\\neml\\n\\nEmilian-Romagnol\\n\\nen\\n\\nEnglish\\n\\neo\\n\\nEsperanto\\n\\nes\\n\\nSpanish\\n\\net\\n\\nEstonian\\n\\neu\\n\\nBasque\\n\\nfa\\n\\nPersian\\n\\nfi\\n\\nFinnish\\n\\nfr\\n\\nFrench\\n\\nfrr\\n\\nFrisian\\n\\nfy\\n\\nWestern Frisian\\n\\nga\\n\\nIrish\\n\\ngd\\n\\nGaelic (Scotland)\\n\\ngl\\n\\nGalician\\n\\ngn\\n\\nGuarani\\n\\ngom\\n\\nKonkani\\n\\ngu\\n\\nGujarati\\n\\ngv\\n\\nManx\\n\\nhe\\n\\nHebrew\\n\\nhi\\n\\nHindi\\n\\nhif\\n\\nFiji Hindi\\n\\nhr\\n\\nCroatian\\n\\nhsb\\n\\nUpper Sorbian\\n\\nht\\n\\nHaitian Creole\\n\\nhu\\n\\nHungarian\\n\\nhy\\n\\nArmenian\\n\\nia\\n\\nInterlingua\\n\\nid\\n\\nIndonesian\\n\\nie\\n\\nInterlingue; Occidental\\n\\nilo\\n\\nIloko\\n\\nio\\n\\nIdo\\n\\nis\\n\\nIcelandic\\n\\nit\\n\\nItalian\\n\\nja\\n\\nJapanese\\n\\njbo\\n\\nLojban\\n\\njv\\n\\nJavanese\\n\\nka\\n\\nGeorgian\\n\\nkk\\n\\nKazakh\\n\\nkm\\n\\nKhmer\\n\\nkn\\n\\nKannada\\n\\nko\\n\\nKorean\\n\\nkrc\\n\\nKarachay-Balkar\\n\\nku\\n\\nKurdish\\n\\nkv\\n\\nKomi\\n\\nkw\\n\\nCornish\\n\\nky\\n\\nKyrgyz\\n\\nla\\n\\nLatin\\n\\nlb\\n\\nLuxembourgish\\n\\nlez\\n\\nLezghian\\n\\nli\\n\\nLimburgan\\n\\nlmo\\n\\nLombard\\n\\nlo\\n\\nLaothian\\n\\nlrc\\n\\nNorthern Luri\\n\\nlt\\n\\nLithuanian\\n\\nlv\\n\\nLatvian\\n\\nmai\\n\\nMaithili\\n\\nmg\\n\\nMalagasy\\n\\nmhr\\n\\nMeadow Mari\\n\\nmin\\n\\nMinangkabau\\n\\nmk\\n\\nMacedonian\\n\\nml\\n\\nMalayalam\\n\\nmn\\n\\nMongolian\\n\\nmr\\n\\nMarathi\\n\\nmrj\\n\\nHill Mari\\n\\nms\\n\\nMalay\\n\\nmt\\n\\nMaltese\\n\\nmwl\\n\\nMirandese\\n\\nmy\\n\\nBurmese\\n\\nmyv\\n\\nErzya\\n\\nmzn\\n\\nMazandarani\\n\\nnah\\n\\nNahuatl\\n\\nnap\\n\\nNeapolitan\\n\\nnds\\n\\nLow German\\n\\nne\\n\\nNepali\\n\\nnew\\n\\nNepal Bhasa\\n\\nnl\\n\\nDutch\\n\\nnn\\n\\nNorwegian Nynorsk\\n\\nno\\n\\nNorwegian\\n\\noc\\n\\nOccitan (post 1500)\\n\\nor\\n\\nOriya\\n\\nos\\n\\nOssetian\\n\\npa\\n\\nPunjabi\\n\\npam\\n\\nPampanga\\n\\npfl\\n\\nPalatine German\\n\\npl\\n\\nPolish\\n\\npms\\n\\nPiedmontese\\n\\npnb\\n\\nPakistani Punjabi\\n\\nps\\n\\nPushto\\n\\npt\\n\\nPortuguese\\n\\nqu\\n\\nQuechua\\n\\nrm\\n\\nRomansh\\n\\nro\\n\\nRomanian\\n\\nru\\n\\nRussian\\n\\nrue\\n\\nRusyn\\n\\nsa\\n\\nSanskrit\\n\\nsah\\n\\nYakut\\n\\nsc\\n\\nSardinian\\n\\nscn\\n\\nSicilian\\n\\nsco\\n\\nScots\\n\\nsd\\n\\nSindhi\\n\\nsh\\n\\nSerbo-Croatian\\n\\nsi\\n\\nSinhalese\\n\\nsk\\n\\nSlovak\\n\\nsl\\n\\nSlovenian\\n\\nso\\n\\nSomali\\n\\nsq\\n\\nAlbanian\\n\\nsr\\n\\nSerbian\\n\\nsu\\n\\nSundanese\\n\\nsv\\n\\nSwedish\\n\\nsw\\n\\nSwahili\\n\\nta\\n\\nTamil\\n\\nte\\n\\nTelugu\\n\\ntg\\n\\nTajik\\n\\nth\\n\\nThai\\n\\ntk\\n\\nTurkmen\\n\\ntl\\n\\nTagalog\\n\\ntr\\n\\nTurkish\\n\\ntt\\n\\nTatar\\n\\ntyv\\n\\nTuvinian\\n\\nug\\n\\nUighur\\n\\nuk\\n\\nUkrainian\\n\\nur\\n\\nUrdu\\n\\nuz\\n\\nUzbek\\n\\nvec\\n\\nVenetian\\n\\nvep\\n\\nVeps\\n\\nvi\\n\\nVietnamese\\n\\nvls\\n\\nVlaams\\n\\nvo\\n\\nVolapük\\n\\nwa\\n\\nWalloon\\n\\nwar\\n\\nWaray\\n\\nwuu\\n\\nWu Chinese\\n\\nxal\\n\\nKalmyk\\n\\nxmf\\n\\nMingrelian\\n\\nyi\\n\\nYiddish\\n\\nyo\\n\\nYoruba\\n\\nyue\\n\\nYue Chinese\\n\\nzh\\n\\nChinese\\n\\nUpdated 22 days ago\\n\\nTable of Contents\\n\\nUse Cases\\n\\nSingle Model Environment\\nMulti Model Environment\\n\\n\\n\\nExamples\\n\\nInput\\nResponse\\n\\n\\n\\nList of Supported Languages\", metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/language-detection'}),\n",
       " Document(page_content=\"Jump to Content\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nSearch\\n\\nGet Started\\n\\nThe Cohere Platform\\n\\nIntroduction to Large Language Models\\n\\nPlayground Overview\\n\\nQuickstart Tutorials\\n\\nGoing Live\\n\\nIntegrations\\n\\nLearn\\n\\nKey ConceptsEmbeddingsPrompt EngineeringTokens\\n\\nGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-p\\n\\nCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model Metrics\\n\\nMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported Languages\\n\\nRerankingReranking Best Practices\\n\\nGenerating Feedback\\n\\nIntroductory Guides\\n\\nSemantic Search\\n\\nContent Moderation\\n\\nEntity Extraction\\n\\nText ClassificationText Classification (Classify)Text Classification (Embed)\\n\\nCo.summarize (Beta)\\n\\nCo.rerank (Beta)\\n\\nResponsible Use\\n\\nOverviewUsage GuidelinesModel LimitationsData Statement\\n\\nModels\\n\\nSecurity\\n\\nEnvironmental Impact\\n\\nLLM University\\n\\nWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?\\n\\nModule 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language Models\\n\\nModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text Representation\\n\\nModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere's Command ModelConclusion - Text Generation\\n\\nAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLP\\n\\nAppendix 2: Building AppsApp Examples\\n\\nMultilingual Semantic Search\\n\\nSuggest Edits\\n\\nSemantic search no longer restricts itself to queries and documents in the same language but also works across languages. For example, if we phrase the search query in Arabic (“ما هي عاصمة الولايات المتحدة؟”), we get the same results, while keyword search can obviously not retrieve any relevant documents.\\n\\nThis enables interesting use cases, for example, in the financial domain, to quickly find relevant information irrespective of the language in which they have been published.\\n\\nUpdated 22 days ago\", metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/multilingual-semantic-search'}),\n",
       " Document(page_content=\"Jump to Content\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nSearch\\n\\nGet Started\\n\\nThe Cohere Platform\\n\\nIntroduction to Large Language Models\\n\\nPlayground Overview\\n\\nQuickstart Tutorials\\n\\nGoing Live\\n\\nIntegrations\\n\\nLearn\\n\\nKey ConceptsEmbeddingsPrompt EngineeringTokens\\n\\nGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-p\\n\\nCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model Metrics\\n\\nMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported Languages\\n\\nRerankingReranking Best Practices\\n\\nGenerating Feedback\\n\\nIntroductory Guides\\n\\nSemantic Search\\n\\nContent Moderation\\n\\nEntity Extraction\\n\\nText ClassificationText Classification (Classify)Text Classification (Embed)\\n\\nCo.summarize (Beta)\\n\\nCo.rerank (Beta)\\n\\nResponsible Use\\n\\nOverviewUsage GuidelinesModel LimitationsData Statement\\n\\nModels\\n\\nSecurity\\n\\nEnvironmental Impact\\n\\nLLM University\\n\\nWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?\\n\\nModule 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language Models\\n\\nModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text Representation\\n\\nModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere's Command ModelConclusion - Text Generation\\n\\nAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLP\\n\\nAppendix 2: Building AppsApp Examples\\n\\nCustomer Feedback Aggregation\\n\\nSuggest Edits\\n\\nSuccessful products like the iPhone quickly get tens of thousands of reviews on eCommerce marketplaces and on social media, which are written in many languages. Getting insights from these reviews enables companies to better understand their customer base and to better drive their product roadmap.\\n\\nHowever, methods for content aggregation only worked well for English, and it wasn’t possible to see patterns across languages or to compare markets.\\n\\nCohere’s multilingual model maps text in different languages to the same vector spaces, allowing users to derive insights across languages and find patterns for specific markets (e.g., which markets care about the picture quality of smartphones).\\n\\nUpdated 22 days ago\", metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/customer-feedback-aggregation'}),\n",
       " Document(page_content=\"Jump to Content\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nSearch\\n\\nGet Started\\n\\nThe Cohere Platform\\n\\nIntroduction to Large Language Models\\n\\nPlayground Overview\\n\\nQuickstart Tutorials\\n\\nGoing Live\\n\\nIntegrations\\n\\nLearn\\n\\nKey ConceptsEmbeddingsPrompt EngineeringTokens\\n\\nGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-p\\n\\nCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model Metrics\\n\\nMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported Languages\\n\\nRerankingReranking Best Practices\\n\\nGenerating Feedback\\n\\nIntroductory Guides\\n\\nSemantic Search\\n\\nContent Moderation\\n\\nEntity Extraction\\n\\nText ClassificationText Classification (Classify)Text Classification (Embed)\\n\\nCo.summarize (Beta)\\n\\nCo.rerank (Beta)\\n\\nResponsible Use\\n\\nOverviewUsage GuidelinesModel LimitationsData Statement\\n\\nModels\\n\\nSecurity\\n\\nEnvironmental Impact\\n\\nLLM University\\n\\nWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?\\n\\nModule 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language Models\\n\\nModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text Representation\\n\\nModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere's Command ModelConclusion - Text Generation\\n\\nAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLP\\n\\nAppendix 2: Building AppsApp Examples\\n\\nCross-Lingual Content Moderation\\n\\nSuggest Edits\\n\\nIn today’s world, content moderation remains a major challenge. As platforms like online games increasingly attract an international audience, the complexity of content moderation has grown as hateful content makes its way across multiple languages and has a greater probability of passing through content moderation tools.\\n\\nTo tackle this challenge, we use multilingual embeddings to build a content moderation tool that works across 100+ languages and only requires training data in English.\\n\\nFor content moderation, we just need a handful of training examples of harmful and acceptable content in one language. For example, in English, we can then train a classifier to find the decision boundary in the vector space that helps us determine which type of content is undesirable on the platform.\\n\\nUpdated 22 days ago\", metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/cross-lingual-content-moderation'}),\n",
       " Document(page_content=\"Jump to Content\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nSearch\\n\\nGet Started\\n\\nThe Cohere Platform\\n\\nIntroduction to Large Language Models\\n\\nPlayground Overview\\n\\nQuickstart Tutorials\\n\\nGoing Live\\n\\nIntegrations\\n\\nLearn\\n\\nKey ConceptsEmbeddingsPrompt EngineeringTokens\\n\\nGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-p\\n\\nCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model Metrics\\n\\nMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported Languages\\n\\nRerankingReranking Best Practices\\n\\nGenerating Feedback\\n\\nIntroductory Guides\\n\\nSemantic Search\\n\\nContent Moderation\\n\\nEntity Extraction\\n\\nText ClassificationText Classification (Classify)Text Classification (Embed)\\n\\nCo.summarize (Beta)\\n\\nCo.rerank (Beta)\\n\\nResponsible Use\\n\\nOverviewUsage GuidelinesModel LimitationsData Statement\\n\\nModels\\n\\nSecurity\\n\\nEnvironmental Impact\\n\\nLLM University\\n\\nWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?\\n\\nModule 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language Models\\n\\nModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text Representation\\n\\nModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere's Command ModelConclusion - Text Generation\\n\\nAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLP\\n\\nAppendix 2: Building AppsApp Examples\\n\\nSupported Languages\\n\\nA list of languages that Cohere's multilingual embedding model provides. Please note that performance may vary across languages.\\n\\nSuggest Edits\\n\\naf\\n\\nAfrikaans\\n\\nam\\n\\nAmharic\\n\\nar\\n\\nArabic\\n\\nas\\n\\nAssamese\\n\\naz\\n\\nAzerbaijani\\n\\nbe\\n\\nBelarusian\\n\\nbg\\n\\nBulgarian\\n\\nbn\\n\\nBengali\\n\\nbo\\n\\nTibetan\\n\\nbs\\n\\nBosnian\\n\\nca\\n\\nCatalan\\n\\nceb\\n\\nCebuano\\n\\nco\\n\\nCorsican\\n\\ncs\\n\\nCzech\\n\\ncy\\n\\nWelsh\\n\\nda\\n\\nDanish\\n\\nde\\n\\nGerman\\n\\nel\\n\\nGreek\\n\\nen\\n\\nEnglish\\n\\neo\\n\\nEsperanto\\n\\nes\\n\\nSpanish\\n\\net\\n\\nEstonian\\n\\neu\\n\\nBasque\\n\\nfa\\n\\nPersian\\n\\nfi\\n\\nFinnish\\n\\nfr\\n\\nFrench\\n\\nfy\\n\\nFrisian\\n\\nga\\n\\nIrish\\n\\ngd\\n\\nScots_gaelic\\n\\ngl\\n\\nGalician\\n\\ngu\\n\\nGujarati\\n\\nha\\n\\nHausa\\n\\nhaw\\n\\nHawaiian\\n\\nhe\\n\\nHebrew\\n\\nhi\\n\\nHindi\\n\\nhmn\\n\\nHmong\\n\\nhr\\n\\nCroatian\\n\\nht\\n\\nHaitian_creole\\n\\nhu\\n\\nHungarian\\n\\nhy\\n\\nArmenian\\n\\nid\\n\\nIndonesian\\n\\nig\\n\\nIgbo\\n\\nis\\n\\nIcelandic\\n\\nit\\n\\nItalian\\n\\nja\\n\\nJapanese\\n\\njv\\n\\nJavanese\\n\\nka\\n\\nGeorgian\\n\\nkk\\n\\nKazakh\\n\\nkm\\n\\nKhmer\\n\\nkn\\n\\nKannada\\n\\nko\\n\\nKorean\\n\\nku\\n\\nKurdish\\n\\nky\\n\\nKyrgyz\\n\\nLa\\n\\nLatin\\n\\nLb\\n\\nLuxembourgish\\n\\nLo\\n\\nLaothian\\n\\nLt\\n\\nLithuanian\\n\\nLv\\n\\nLatvian\\n\\nmg\\n\\nMalagasy\\n\\nmi\\n\\nMaori\\n\\nmk\\n\\nMacedonian\\n\\nml\\n\\nMalayalam\\n\\nmn\\n\\nMongolian\\n\\nmr\\n\\nMarathi\\n\\nms\\n\\nMalay\\n\\nmt\\n\\nMaltese\\n\\nmy\\n\\nBurmese\\n\\nne\\n\\nNepali\\n\\nnl\\n\\nDutch\\n\\nno\\n\\nNorwegian\\n\\nny\\n\\nNyanja\\n\\nor\\n\\nOriya\\n\\npa\\n\\nPunjabi\\n\\npl\\n\\nPolish\\n\\npt\\n\\nPortuguese\\n\\nro\\n\\nRomanian\\n\\nru\\n\\nRussian\\n\\nrw\\n\\nKinyarwanda\\n\\nsi\\n\\nSinhalese\\n\\nsk\\n\\nSlovak\\n\\nsl\\n\\nSlovenian\\n\\nsm\\n\\nSamoan\\n\\nsn\\n\\nShona\\n\\nso\\n\\nSomali\\n\\nsq\\n\\nAlbanian\\n\\nsr\\n\\nSerbian\\n\\nst\\n\\nSesotho\\n\\nsu\\n\\nSundanese\\n\\nsv\\n\\nSwedish\\n\\nsw\\n\\nSwahili\\n\\nta\\n\\nTamil\\n\\nte\\n\\nTelugu\\n\\ntg\\n\\nTajik\\n\\nth\\n\\nThai\\n\\ntk\\n\\nTurkmen\\n\\ntl\\n\\nTagalog\\n\\ntr\\n\\nTurkish\\n\\ntt\\n\\nTatar\\n\\nug\\n\\nUighur\\n\\nuk\\n\\nUkrainian\\n\\nur\\n\\nUrdu\\n\\nuz\\n\\nUzbek\\n\\nvi\\n\\nVietnamese\\n\\nwo\\n\\nWolof\\n\\nxh\\n\\nXhosa\\n\\nyi\\n\\nYiddish\\n\\nyo\\n\\nYoruba\\n\\nzh\\n\\nChinese\\n\\nzu\\n\\nZulu\\n\\nUpdated 22 days ago\", metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/supported-languages'}),\n",
       " Document(page_content=\"Jump to Content\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nSearch\\n\\nGet Started\\n\\nThe Cohere Platform\\n\\nIntroduction to Large Language Models\\n\\nPlayground Overview\\n\\nQuickstart Tutorials\\n\\nGoing Live\\n\\nIntegrations\\n\\nLearn\\n\\nKey ConceptsEmbeddingsPrompt EngineeringTokens\\n\\nGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-p\\n\\nCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model Metrics\\n\\nMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported Languages\\n\\nRerankingReranking Best Practices\\n\\nGenerating Feedback\\n\\nIntroductory Guides\\n\\nSemantic Search\\n\\nContent Moderation\\n\\nEntity Extraction\\n\\nText ClassificationText Classification (Classify)Text Classification (Embed)\\n\\nCo.summarize (Beta)\\n\\nCo.rerank (Beta)\\n\\nResponsible Use\\n\\nOverviewUsage GuidelinesModel LimitationsData Statement\\n\\nModels\\n\\nSecurity\\n\\nEnvironmental Impact\\n\\nLLM University\\n\\nWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?\\n\\nModule 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language Models\\n\\nModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text Representation\\n\\nModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere's Command ModelConclusion - Text Generation\\n\\nAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLP\\n\\nAppendix 2: Building AppsApp Examples\\n\\nReranking\\n\\nSuggest Edits\\n\\nHow Rerank Works\\n\\nTraditional semantic search consists of a two-part system. An initial retrieval mechanism does an approximate sweep over a collection of documents and creates a document list. Then, a re-ranker mechanism will take this candidate document list and re-rank the elements. With Rerank, you can improve your models by re-organizing your results based on certain parameters.\\n\\nGet Started\\n\\nExample Request\\n\\nParameters:\\n\\ndocuments (required) - a list of JSON or string objects.\\na list of document objects to rerank - it is assumed the object has a text key.\\n\\nquery (required) - string\\nThe search query that you would like the documents to be ranked against.\\n\\nmodel (required) - two models:\\nAn english model, rerank-english-v2.0.\\nA multilingual model , rerank-multilingual-v2.0.\\n\\ntop_n (optional) - integer, default is the length of the documents list passed in.\\nthe number of documents returned, ranked in relevance against your query.\\n\\nmax_chunks_per_doc (optional)- integer, default is 10\\nIf your document exceeds 512 tokens, this will determine the maximum number of chunks a document can be split into. For example, if your document is 6000 tokens, with the default of 10, the document will be split into 10 chunks each of 512 tokens and the last 880 tokens will be disregarded.\\n\\nreturn_documents (optional, API only) - boolean, default set as false.\\nif  true, the documents will be returned along with their associated text.\\nif false, the documents will not be returned and the response object will have {index, relevance_score} where index is the document order.ðŸš§In the SDK, documents are always returned, and return_documents is not a valid parameter.\\n\\nExample Response\\n\\nMultilingual Reranking\\n\\nCohere offers a multilingual model,  rerank-multilingual-v2.0 . The model is trained on the following languages:\\n\\nUpdated 22 days ago\\n\\nTable of Contents\\n\\nHow Rerank Works\\n\\n\\nGet Started\\n\\nExample Request\\nParameters:\\nExample Response\\n\\n\\n\\nMultilingual Reranking\", metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/reranking'}),\n",
       " Document(page_content=\"Jump to Content\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nSearch\\n\\nGet Started\\n\\nThe Cohere Platform\\n\\nIntroduction to Large Language Models\\n\\nPlayground Overview\\n\\nQuickstart Tutorials\\n\\nGoing Live\\n\\nIntegrations\\n\\nLearn\\n\\nKey ConceptsEmbeddingsPrompt EngineeringTokens\\n\\nGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-p\\n\\nCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model Metrics\\n\\nMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported Languages\\n\\nRerankingReranking Best Practices\\n\\nGenerating Feedback\\n\\nIntroductory Guides\\n\\nSemantic Search\\n\\nContent Moderation\\n\\nEntity Extraction\\n\\nText ClassificationText Classification (Classify)Text Classification (Embed)\\n\\nCo.summarize (Beta)\\n\\nCo.rerank (Beta)\\n\\nResponsible Use\\n\\nOverviewUsage GuidelinesModel LimitationsData Statement\\n\\nModels\\n\\nSecurity\\n\\nEnvironmental Impact\\n\\nLLM University\\n\\nWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?\\n\\nModule 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language Models\\n\\nModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text Representation\\n\\nModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere's Command ModelConclusion - Text Generation\\n\\nAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLP\\n\\nAppendix 2: Building AppsApp Examples\\n\\nReranking Best Practices\\n\\nSuggest Edits\\n\\nOptimizing Performance\\n\\nCohere recommends the following tips for optimal endpoint performance:\\n\\nNumber of Documents\\n\\n1000\\n\\nNumber of Tokens per Document\\n\\nN/A (see below for more info)\\n\\nNumber of Tokens per Query\\n\\n256\\n\\nDocument Chunking\\n\\nCohere breaks documents into 510 token chunks. For example, if your query is 50 tokens and your document is 1024 tokens, your document will be broken into the following chunks:\\n\\nrelevance_score_1 = <query[0,50], document[0,460]\\n\\nrelevance_score_2 = <query[0,50], document[460,920]\\n\\nrelevance_score_3 = <query[0,50],document[920,1024]\\n\\nrelevance_score = max(relevance_score_1, relevance_score_2, relevance_score_3)\\n\\nIf you would like more control over how chunking is done, we recommend that you chunk your documents yourself.\\n\\nMax Number of Documents\\n\\nBy default, the endpoint will error if the user tries to pass more than 1000 documents at a time because max_chunks_per_doc has a default of 10. The way we calculate the maximum number of documents that can be passed to the endpoint is the following: len(documents) * max_chunks_per_doc >10,000 then endpoint will return an error.\\n\\nQueries\\n\\nOur models are trained with a context length of 510 tokens - the model takes into account both the input from the query and document. If your query is larger than 256 tokens, it will be truncated to the first 256 tokens.\\n\\nInterpreting Results\\n\\nThe most important output from co.rerank() is the absolute rank that is exposed in the response object. The score is query dependent and could be higher or lower depending on the query and passages sent in.  In the example below, what matters is that Ottawa is more relevant than Toronto, but the user should not assume that Ottawa is two times more relevant than Toronto.\\n\\nRelevance scores are normalized to be in [0, 1]. Scores close to 1 indicate a high relevance to the query, and scores closer to zero indicate low relevance. To find a threshold on the scores to determine whether a document is relevant or not, we recommend going through the following process:\\n\\nSelect a set of 30-50 representative queries Q=[q_0, … q_n] from your domain.\\n\\nFor each query provide a document that is considered borderline relevant to the query for your specific use case, and create a list of (query, document) pairs sample_inputs=[(q_0, d_0), …, (q_n, d_n)] .\\n\\nPass all tuples in sample_inputs through the rerank endpoint in a loop, and gather relevance scores sample_scores=[s0, ..., s_n] .\\n\\nThe average of sample_scores can then be used as a reference when deciding a threshold for filtering out irrelevant documents.\\n\\nUpdated about 6 hours ago\\n\\nTable of Contents\\n\\nOptimizing Performance\\n\\nDocument Chunking\\nMax Number of Documents\\nQueries\\n\\n\\n\\nInterpreting Results\", metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/reranking-best-practices'}),\n",
       " Document(page_content=\"Jump to Content\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nSearch\\n\\nGet Started\\n\\nThe Cohere Platform\\n\\nIntroduction to Large Language Models\\n\\nPlayground Overview\\n\\nQuickstart Tutorials\\n\\nGoing Live\\n\\nIntegrations\\n\\nLearn\\n\\nKey ConceptsEmbeddingsPrompt EngineeringTokens\\n\\nGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-p\\n\\nCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model Metrics\\n\\nMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported Languages\\n\\nRerankingReranking Best Practices\\n\\nGenerating Feedback\\n\\nIntroductory Guides\\n\\nSemantic Search\\n\\nContent Moderation\\n\\nEntity Extraction\\n\\nText ClassificationText Classification (Classify)Text Classification (Embed)\\n\\nCo.summarize (Beta)\\n\\nCo.rerank (Beta)\\n\\nResponsible Use\\n\\nOverviewUsage GuidelinesModel LimitationsData Statement\\n\\nModels\\n\\nSecurity\\n\\nEnvironmental Impact\\n\\nLLM University\\n\\nWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?\\n\\nModule 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language Models\\n\\nModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text Representation\\n\\nModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere's Command ModelConclusion - Text Generation\\n\\nAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLP\\n\\nAppendix 2: Building AppsApp Examples\\n\\nGenerating Feedback\\n\\nSuggest Edits\\n\\nCo.feedback allows users to provide feedback on responses created from Co.Generate. This feedback is used to improve the model. The endpoint can generate preference and performance feedback. This guide provides a starting point for using the endpoint.\\n\\nYou can see a live example of Co.feedback on our playground.\\n\\nOr, you can read below to learn how to call the feedback endpoint with our API.\\n\\nGenerate Feedback\\n\\nYou can produced detailed feedback based on the annotator's acceptance of the generated response using the generate_feedback endpoint.\\n\\nParameters\\n\\nThe endpoint has a number of settings you can use to control the kind of output it generates:\\n\\nrequest_id (String, required): The request_id of the generation request to give feedback on.\\n\\ngood_response (Boolean, required): Whether the response was good or not.\\n\\nmodel (String): The unique ID of the model.\\n\\ndesired_response (String): The desired response. Used when an annotator edits a suggested response.\\n\\nflagged_response (Boolean): Whether the response was flagged or not.\\n\\nflagged_reason (String):  The reason the response was flagged.\\n\\nprompt (String): The original prompt used to generate the response.\\n\\nannotator_id (String): The annotator's ID.\\n\\nExample Requests\\n\\nIf the annotator accepts the suggested response, you could format a request like this:\\n\\nIf the annotator edits the suggested response, you could format a request like this:\\n\\nExample Response\\n\\nGenerate Preference Feedback\\n\\nAlternatively, you can generate feedback based on which response an annotator prefers with the generate_preference_feedback endpoint.\\n\\nParameters\\n\\nratings (List[PreferenceRating], required): A list of PreferenceRating objects.\\n\\nmodel (String):  The unique ID of the model.\\n\\nprompt (String): The original prompt used to generate the response.\\n\\nannotator_id (String):  The annotator's ID.\\n\\nExample Request\\n\\nA user accepts a model's suggestion in an assisted writing setting, and prefers it to a second suggestion, a request might look like this:\\n\\nUpdated 8 days ago\\n\\nTable of Contents\\n\\nGenerate Feedback\\n\\nParameters\\nExample Requests\\nExample Response\\n\\n\\n\\nGenerate Preference Feedback\\n\\nParameters\\nExample Request\", metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/feedback'}),\n",
       " Document(page_content='Jump to Content\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nSearch\\n\\nGet Started\\n\\nThe Cohere Platform\\n\\nIntroduction to Large Language Models\\n\\nPlayground Overview\\n\\nQuickstart Tutorials\\n\\nGoing Live\\n\\nIntegrations\\n\\nLearn\\n\\nKey ConceptsEmbeddingsPrompt EngineeringTokens\\n\\nGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-p\\n\\nCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model Metrics\\n\\nMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported Languages\\n\\nRerankingReranking Best Practices\\n\\nGenerating Feedback\\n\\nIntroductory Guides\\n\\nSemantic Search\\n\\nContent Moderation\\n\\nEntity Extraction\\n\\nText ClassificationText Classification (Classify)Text Classification (Embed)\\n\\nCo.summarize (Beta)\\n\\nCo.rerank (Beta)\\n\\nResponsible Use\\n\\nOverviewUsage GuidelinesModel LimitationsData Statement\\n\\nModels\\n\\nSecurity\\n\\nEnvironmental Impact\\n\\nLLM University\\n\\nWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?\\n\\nModule 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language Models\\n\\nModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text Representation\\n\\nModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere\\'s Command ModelConclusion - Text Generation\\n\\nAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLP\\n\\nAppendix 2: Building AppsApp Examples\\n\\nSemantic Search\\n\\nSuggest Edits\\n\\nðŸ“˜\\n\\nThis Guide Uses the Embed Endpoint.\\n\\nYou can find more information about the endpoint here.\\n\\nLanguage models give computers the ability to search by meaning and go beyond searching by matching keywords. This capability is called semantic search.\\n\\nIn this article, we\\'ll build a simple semantic search engine. The applications of semantic search go beyond building a web search engine. They can empower a private search engine for internal documents or records. It can be used to power features like StackOverflow\\'s \"similar questions\" feature.\\n\\nYou can find the code in the notebook and colab.\\n\\nContents\\n\\nGet the archive of questions\\nEmbed the archive\\nSearch using an index and nearest neighbour search\\nVisualize the archive based on the embeddings.\\n\\nðŸ“˜\\n\\nNew to Cohere?\\n\\nGet Started now and get unprecedented access to world-class Generation and\\nRepresentation models with billions of parameters.\\n\\n1. Download the Dependencies\\n\\n1a. Import the Necessary Dependencies to Run this Example\\n\\n2. Get the Archive of Questions\\n\\nWe\\'ll use the trec dataset which is made up of questions and their categories.\\n\\nHow did serfdom develop in and then leave Russia ?\\n\\nWhat films featured the character Popeye Doyle ?\\n\\nHow can I find a list of celebrities \\' real names ?\\n\\nWhat fowl grabs the spotlight after the Chinese Year of the Monkey ?\\n\\nWhat is the full form of .com ?\\n\\nWhat contemptible scoundrel stole the cork from my lunch ?\\n\\nWhat team did baseball \\'s St. Louis Browns become ?\\n\\nWhat is the oldest profession ?\\n\\nWhat are liver enzymes ?\\n\\nName the scar-faced bounty hunter of The Old West .\\n\\n3. Embed the Archive\\n\\nLet\\'s now embed the text of the questions.\\n\\nTo get a thousand embeddings of this length should take a few seconds.\\n\\n4. Build the Index, search Using an Index and Conduct Nearest Neighbour Search\\n\\nLet\\'s build an index using the library called annoy. Annoy is an library created by Spotify to do nearest neighbour search; nearest neighbour search is an optimization problem of finding the point in a given set that is closest (or most similar) to a given point.\\n\\nAfter building the index, we can use it to retrieve the nearest neighbours either of existing questions (section 3.1), or of new questions that we embed (section 3.2).\\n\\n4a. Find the Neighbours of an Example from the Dataset\\n\\nIf we\\'re only interested in measuring the similarities between the questions in the dataset (no outside queries), a simple way is to calculate the similarities between every pair of embeddings we have.\\n\\n614\\n\\nWhat animals do you find in the stock market ?\\n\\n0.896121\\n\\n137\\n\\nWhat are equity securities ?\\n\\n0.970260\\n\\n601\\n\\nWhat is `` the bear of beers \\'\\' ?\\n\\n0.978348\\n\\n307\\n\\nWhat does NASDAQ stand for ?\\n\\n0.997819\\n\\n683\\n\\nWhat is the rarest coin ?\\n\\n1.027727\\n\\n112\\n\\nWhat are the world \\'s four oceans ?\\n\\n1.049661\\n\\n864\\n\\nWhen did the Dow first reach ?\\n\\n1.050362\\n\\n547\\n\\nWhere can stocks be traded on-line ?\\n\\n1.053685\\n\\n871\\n\\nWhat are the Benelux countries ?\\n\\n1.054899\\n\\n4b. Find the Neighbours of a User Query\\n\\nWe\\'re not limited to searching using existing items. If we get a query, we can embed it and find its nearest neighbours from the dataset.\\n\\n236\\n\\nWhat is the name of the tallest mountain in the world ?\\n\\n0.431913\\n\\n670\\n\\nWhat is the highest mountain in the world ?\\n\\n0.436290\\n\\n907\\n\\nWhat mountain range is traversed by the highest railroad in the world ?\\n\\n0.715265\\n\\n435\\n\\nWhat is the highest peak in Africa ?\\n\\n0.717943\\n\\n354\\n\\nWhat ocean is the largest in the world ?\\n\\n0.762917\\n\\n412\\n\\nWhat was the highest mountain on earth before Mount Everest was discovered ?\\n\\n0.767649\\n\\n109\\n\\nWhere is the highest point in Japan ?\\n\\n0.784319\\n\\n114\\n\\nWhat is the largest snake in the world ?\\n\\n0.789743\\n\\n656\\n\\nWhat \\'s the tallest building in New York City ?\\n\\n0.793982\\n\\n901\\n\\nWhat \\'s the longest river in the world ?\\n\\n0.794352\\n\\n5. Visualize the Archive\\n\\nCreate the graph locally and hover over the points to read the text. Do you see some of the patterns in clustered points? Similar questions, or questions asking about similar topics?\\n\\nThis concludes this introductory guide to semantic search using sentence embeddings. As you continue the path of building a search product additional considerations arise (like dealing with long texts, or training to better improve the embeddings for a specific use case).\\n\\nWe canâ€™t wait to see what you start building! Share your projects or find support on our community discord.\\n\\nUpdated about 1 month ago\\n\\nTable of Contents\\n\\nContents\\n\\n\\n1. Download the Dependencies\\n\\n1a. Import the Necessary Dependencies to Run this Example\\n\\n\\n\\n2. Get the Archive of Questions\\n\\n\\n3. Embed the Archive\\n\\n\\n4. Build the Index, search Using an Index and Conduct Nearest Neighbour Search\\n\\n4a. Find the Neighbours of an Example from the Dataset\\n4b. Find the Neighbours of a User Query\\n\\n\\n\\n5. Visualize the Archive', metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/semantic-search'}),\n",
       " Document(page_content=\"Jump to Content\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nSearch\\n\\nGet Started\\n\\nThe Cohere Platform\\n\\nIntroduction to Large Language Models\\n\\nPlayground Overview\\n\\nQuickstart Tutorials\\n\\nGoing Live\\n\\nIntegrations\\n\\nLearn\\n\\nKey ConceptsEmbeddingsPrompt EngineeringTokens\\n\\nGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-p\\n\\nCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model Metrics\\n\\nMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported Languages\\n\\nRerankingReranking Best Practices\\n\\nGenerating Feedback\\n\\nIntroductory Guides\\n\\nSemantic Search\\n\\nContent Moderation\\n\\nEntity Extraction\\n\\nText ClassificationText Classification (Classify)Text Classification (Embed)\\n\\nCo.summarize (Beta)\\n\\nCo.rerank (Beta)\\n\\nResponsible Use\\n\\nOverviewUsage GuidelinesModel LimitationsData Statement\\n\\nModels\\n\\nSecurity\\n\\nEnvironmental Impact\\n\\nLLM University\\n\\nWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?\\n\\nModule 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language Models\\n\\nModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text Representation\\n\\nModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere's Command ModelConclusion - Text Generation\\n\\nAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLP\\n\\nAppendix 2: Building AppsApp Examples\\n\\nContent Moderation\\n\\nSuggest Edits\\n\\nðŸ“˜\\n\\nThis Guide Uses the Classify Endpoint.\\n\\nYou can find more information about the endpoint here.\\n\\nThe Classify endpoint streamlines the task of running a text classification task. Via a single endpoint, you can deploy different kinds of content moderation use cases according to your needs.\\n\\nAs online communities continue to grow, content moderators need a way to  moderate user-generated content at scale. To appreciate the wide-ranging need for content moderation, we can refer to the paper A Unified Typology of Harmful Content by Banko et al. [Source]. It provides a unified typology of harmful content generated within online communities and a comprehensive list of examples, which can be grouped into four types:\\n\\nHate and Harassment\\n\\nSelf-Inflicted Harm\\n\\nIdeological Harm\\n\\nExploitation\\n\\nThere are publicly available datasets within the content moderation space which you can experiment with, for example:\\n\\nSocial Media Toxicity dataset from Surge AI\\n\\nWikipedia Comments dataset by Jigsaw/Conversation AI\\n\\nCivil Comments dataset by Jigsaw/Conversation AI\\n\\nHate Speech Dataset by Derczynski et al.\\n\\nA Quick Walkthrough\\n\\nHere we take a quick look at performing a toxicity detection using the Classify endpoint of the Cohere API. In this example, our task is to classify a list of example social media comments as either toxic or benign.\\n\\nLLMs work by conditioning it with some examples of what we want its outputs to look like. In our case, weâ€™ll provide a few examples of labeled data, whereby each data point contains the text online comment and the associated toxicity label. Then we feed the model with the inputs we want to classify and the model will return the predicted class it belongs to.\\n\\nWeâ€™ll use the Cohere Playground, which is an interface that helps you quickly prototype and experiment with LLMs.\\n\\nFirst, we choose the model we want to use and enter the labeled examples. The model will work fine with as few as 5 examples per class, but in general, the more data, the better. In this example, weâ€™ll provide 5 examples for each class: toxic and benign.\\n\\nHereâ€™s a better look at all ten examples:\\n\\nyo how are you\\n\\nbenign\\n\\nPUDGE MID!\\n\\nbenign\\n\\nI WILL REMEMBER THIS FOREVER\\n\\nbenign\\n\\nI think I saw it first\\n\\nbenign\\n\\nbring me a potion\\n\\nbenign\\n\\nI will honestly kill you\\n\\ntoxic\\n\\nget rekt moron\\n\\ntoxic\\n\\ngo to hell\\n\\ntoxic\\n\\nf  a g o t\\n\\ntoxic\\n\\n10\\n\\nyou are hot trash\\n\\ntoxic\\n\\nNext we enter the list of inputs we want to classify and run the classification. Here we have 5 inputs.\\n\\nHereâ€™s a better look at all five inputs and outcomes:\\n\\nthis game sucks, you suck\\n\\ntoxic\\n\\ntoxic\\n\\nput your neck in a noose\\n\\ntoxic\\n\\ntoxic\\n\\nbuy the black potion\\n\\nbenign\\n\\nbenign\\n\\ntop mia\\n\\nbenign\\n\\nbenign\\n\\ngood work team\\n\\nbenign\\n\\nbenign\\n\\nIn this small example, the model got all classifications correct. We can then generate the equivalent code to access the Classify endpoint by exporting the code from the Playground.\\n\\nThe following is the corresponding code snippet for the API call. From here, we can further build the content moderation solution according to the scale and integration needs.\\n\\nNext Steps\\n\\nTo get the best classification performance, you will likely need to perform custom training, which is a method for customizing an LLM model with your own dataset. This is especially true for a content moderation task, where no two communities are the same and where the nature of the content is always evolving. The model will need to capture the nuances of the content within a given community at a given time, and custom model training is a way to do that.\\n\\nThe Cohere platform lets you train a model using a dataset you provide. Refer to this article for a step-by-step guide.\\n\\nIn summary, Cohereâ€™s LLM API empowers developers to build content moderation systems at scale without having to worry about building and deploying machine learning models in-house. In particular, teams can perform text classification tasks via the Classify endpoint. Try it now!\\n\\nUpdated 22 days ago\\n\\nTable of Contents\\n\\nA Quick Walkthrough\\nNext Steps\", metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/content-moderation-with-classify'}),\n",
       " Document(page_content='Jump to Content\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nSearch\\n\\nGet Started\\n\\nThe Cohere Platform\\n\\nIntroduction to Large Language Models\\n\\nPlayground Overview\\n\\nQuickstart Tutorials\\n\\nGoing Live\\n\\nIntegrations\\n\\nLearn\\n\\nKey ConceptsEmbeddingsPrompt EngineeringTokens\\n\\nGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-p\\n\\nCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model Metrics\\n\\nMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported Languages\\n\\nRerankingReranking Best Practices\\n\\nGenerating Feedback\\n\\nIntroductory Guides\\n\\nSemantic Search\\n\\nContent Moderation\\n\\nEntity Extraction\\n\\nText ClassificationText Classification (Classify)Text Classification (Embed)\\n\\nCo.summarize (Beta)\\n\\nCo.rerank (Beta)\\n\\nResponsible Use\\n\\nOverviewUsage GuidelinesModel LimitationsData Statement\\n\\nModels\\n\\nSecurity\\n\\nEnvironmental Impact\\n\\nLLM University\\n\\nWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?\\n\\nModule 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language Models\\n\\nModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text Representation\\n\\nModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere\\'s Command ModelConclusion - Text Generation\\n\\nAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLP\\n\\nAppendix 2: Building AppsApp Examples\\n\\nEntity Extraction\\n\\nSuggest Edits\\n\\n\\uf8ffüìò\\n\\nThis Guide Uses the Generate Endpoint.\\n\\nYou can find more information about the endpoint here.\\n\\nExtracting a piece of information from text is a common need in language processing systems. LLMs can at times extract entities which are harder to extract using other NLP methods (and where pre-training provides the model with some context on these entities). This is an overview of using generative LLMs to extract entities.\\n\\nExtracting movie names from text\\n\\nThis example uses Cohere\\'s generative models to extract the name of a film from the title of an article. We\\'ll use post titles from the r/Movies subreddit. For each title, we\\'ll extract which movie the post is about. If the model is unable to detect the name of a movie being mentioned, it will return \"none\".\\n\\nThe full code example is in the notebook and colab\\n\\nPreparing examples for the prompt\\n\\nIn our prompt, we\\'ll present the model with examples for the type of output we\\'re after. We basically get a set of subreddit article titles, and label them ourselves. The label here is the name of the movie mentioned in the title (and \"none\" if no movie is mentioned).\\n\\nCreating the extraction prompt\\n\\nWe\\'ll create a prompt that demonstrates the task to the model. The prompt contains the examples above, and then presents the input text and asks the model to extract the movie name.\\n\\nSo let\\'s get a few example titles from the movies subreddit, label them, and make an extraction prompt out of them:\\n\\nDeadpool 2 | Official HD Deadpool\\'s \"Wet on Wet\" Teaser | 2018\\n\\nDeadpool 2\\n\\nJordan Peele Just Became the First Black Writer-Director With a $100M Movie Debut\\n\\nnone\\n\\nJoker Officially Rated ‚ÄúR‚Äù\\n\\nJoker\\n\\nRyan Reynolds‚Äô \\'Free Guy\\' Receives July 3, 2020 Release Date - About a bank teller stuck in his routine that\\n      discovers he‚Äôs an NPC character in brutal open world game.\\n\\nFree Guy\\n\\nJames Cameron congratulates Kevin Feige and Marvel!\\n\\nnone\\n\\nThe Cast of Guardians of the Galaxy release statement on James Gunn\\n\\nGuardians of the Galaxy\\n\\nINSERT INPUT TEXT HERE\\n\\nLet\\'s point out a few ideas in this prompt:\\n\\nThe prompt is made up of six examples that demonstrate the task to the model before it encounters the input text we want to extract text from\\n\\nEach example demonstrates the task by showing an example input text and an example output text. Between the two is a task description explaining in what needs to be done (e.g. \"extract the movie title from the post:\")\\n\\nThe notebook provides a class that constructs the prompt and makes the string manipulation easier.\\n\\nSee prompt engineering for more details on creating prompts.\\n\\nGetting the data\\n\\nLet\\'s get the top ten posts in r/movies of 2021. We can preview the top three:\\n\\nHayao Miyazaki Got So Bored with Retirement He Started Directing Again ‚Äòin Order to Live‚Äô,\\n\\nFirst poster for Pixar\\'s Luca,\\n\\nNew images from Space Jam: A New Legacy\\'\\n\\nWe can then proceed with the extraction. We basically plug each post title into the input text part of the prompt, and retrieve the output of the model.\\n\\nThese are the model\\'s results:\\n\\nHayao Miyazaki Got So Bored with Retirement He Started Directing Again ‚Äòin Order to Live‚Äô\\n\\nnone\\n\\nFirst poster for Pixar\\'s Luca\\n\\nPixar\\'s Luca\\n\\nNew images from Space Jam: A New Legacy\\n\\nSpace Jam: A New Legacy\\n\\nOfficial Poster for \"Sonic the Hedgehog 2\"\\n\\nSonic the Hedgehog 2\\n\\nNg Man Tat, legendary HK actor and frequent collborator of Stephen Chow (Shaolin Soccer, God of Gambler) died at\\n        70\\n\\nnone\\n\\nZack Snyder‚Äôs Justice League has officially been Rated R for for violence and some language\\n\\nJustice League\\n\\nHBOMax and Disney+ NEED to improve their apps if they want to compete with Netflix.\\n\\nnone\\n\\nI want a sequel to Rat Race where John Cleese‚Äôs character dies and invites everyone from the first film to his\\n        funeral, BUT, he‚Äôs secretly set up a Rat Maze to trap them all in. A sort of post-mortem revenge on them for\\n        donating all his wealth to charity.\\n\\nRat Race\\n\\n\\'Trainspotting\\' at 25: How an Indie Film About Heroin Became a Feel-Good Classic\\n\\nTrainspotting\\n\\n‚ÄòAvatar: The Last Airbender‚Äô Franchise To Expand With Launch Of Nickelodeon‚Äôs Avatar Studios, Animated\\n        Theatrical Film To Start Production Later This Year\\n\\nAvatar: The Last Airbender\\n\\nThe model got 9/10 correctly. It didn\\'t pick up on Shaolin Soccer and God of Gambler in example #4. It also called the second example \"Pixar\\'s Luca\" instead of \"Luca\".\\n\\nSummary\\n\\nFind the full code in the notebook/colab. It proceeds to evaluate performance on a small test set.\\n\\nThis type of extraction is interesting because it doesn\\'t just blindly look at the text. The model has picked up on movie information during its pretraining process and that helps it understand the task from only a few examples.\\n\\nYou can think about extending this to other subreddits, to extract other kinds of entities and information. Join our Discord Community to share ideas and ask questions about NLP and ML and let us know what you are experimenting with and what kind of results you see!\\n\\nHappy building!\\n\\nUpdated 22 days ago\\n\\nTable of Contents\\n\\nExtracting movie names from text\\nPreparing examples for the prompt\\nCreating the extraction prompt\\nGetting the data\\nSummary', metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/entity-extraction'}),\n",
       " Document(page_content='Jump to Content\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nSearch\\n\\nGet Started\\n\\nThe Cohere Platform\\n\\nIntroduction to Large Language Models\\n\\nPlayground Overview\\n\\nQuickstart Tutorials\\n\\nGoing Live\\n\\nIntegrations\\n\\nLearn\\n\\nKey ConceptsEmbeddingsPrompt EngineeringTokens\\n\\nGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-p\\n\\nCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model Metrics\\n\\nMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported Languages\\n\\nRerankingReranking Best Practices\\n\\nGenerating Feedback\\n\\nIntroductory Guides\\n\\nSemantic Search\\n\\nContent Moderation\\n\\nEntity Extraction\\n\\nText ClassificationText Classification (Classify)Text Classification (Embed)\\n\\nCo.summarize (Beta)\\n\\nCo.rerank (Beta)\\n\\nResponsible Use\\n\\nOverviewUsage GuidelinesModel LimitationsData Statement\\n\\nModels\\n\\nSecurity\\n\\nEnvironmental Impact\\n\\nLLM University\\n\\nWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?\\n\\nModule 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language Models\\n\\nModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text Representation\\n\\nModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere\\'s Command ModelConclusion - Text Generation\\n\\nAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLP\\n\\nAppendix 2: Building AppsApp Examples\\n\\nText Classification (Classify)\\n\\nSuggest Edits\\n\\nðŸ“˜\\n\\nThis Guide Uses the Classify Endpoint.\\n\\nYou can find more information about the endpoint here.\\n\\nIn this section, we show how to use the Classify endpoint to do sentiment classification for customer satisfaction survey responses an e-commerce website may receive.\\n\\nThe Problem We Want to Solve\\n\\nFor this demo, let\\'s assume that we want to classify a set of reviews for a newly released feature into positive and negative classes. We might for instance have a review like this:\\n\\nThe item exceeded my expectations\\n\\nthat we want to classify as a positive review.\\n\\nNaturally, the same techniques that we\\'ll use for this problem can be used for any other task where we want to classify a given text according to a fixed set of classes.\\n\\nUsing Classify For Our Task\\n\\nClassify takes in example inputs with their labels, as well as the input texts we aim to classify. It then trains a classifier using the power of an embeddings model.\\n\\nExamples\\n\\nLabeled examples are used to demonstrate the classification task to the model so it grasps the task. Examples provide two important pieces of information:\\n1- The inputs and expected outputs for the task we\\'re interested in.\\n2- The number of output classes. Every class should appear in at least one example in the labeled examples.\\n\\nIn this case we will be passing in the following examples:\\n\\nTexts:\\n\\nThese are the input texts that we would like to classify:\\n\\nClassifying the Input Texts\\n\\nAdding everything above together, we can call the API with the following arguments:\\n\\nmodel: embed-english-v2.0\\n\\nexamples: [Example(\"The order is 5 days late\",\"negative\"), Example(\"The order came 5 days early\",\"positive\"), Example(\"I would recommend this to others\",\"positive\"), Example(\"The package was damaged\",\"negative\"), Example(\"The order was incorrect\",\"negative\"), Example(\"The item exceeded my expectations\",\"positive\"), Example(\"I want to return my item\",\"negative\"), Example(\"I ordered more for my friends\",\"positive\"), Example(\"The item\\'s material feels low quality\",\"negative\")]\\n\\ninputs: [\"This item was broken when it arrived\",\"This item broke after 3 weeks\"]\\n\\nThe corresponding code snippet for the API call is as follows.\\n\\nIt gives us the following values:\\n\\nwhich indicates that, as we would expect, our model thinks that both texts are negative.\\n\\nThe playground has a user interface to help you set up the classification prompts, which can then be exported as code.\\n\\nChoose Model\\n\\nIn the Cohere Playground, click on â€˜Classifyâ€™.\\nSelect the model size of your choice. Our smaller model is faster, while our larger model has a better grasp of language and are more able to capture and replicate the patterns in the input prompt.\\n\\nAdd Examples\\n\\nAdd your labeled examples in the â€˜Examplesâ€™ section. The first column is for the examples while the subsequent columns are for the associated labels. Our example here consists of 2 labels but there is no limit as to how many labels you can specify, depending on the task you have.\\n\\nYou can also add your labeled examples using a CSV file by selecting upload your labelled examples.\\n\\nAdd at least 2 examples for each label. The more examples you have, the higher the chance of getting more accurate outcomes.\\n\\nIf you are not sure, there are also some preset examples to help you get started.\\n\\nAdd Inputs\\n\\nAdd the inputs you want to classify in the â€˜Inputsâ€™ section. Once done, click on â€˜Classifyâ€™ to start the classification step.\\n\\nView Results\\n\\nOnce the classification step is completed, you will see the output labels next to the inputs you added.\\n\\nIn the â€˜Resultsâ€™ section, you will also see the confidence levels associated with each output. The confidence level represents the model\\'s degree of certainty that the query falls under a given label. The label with the highest confidence is chosen.\\n\\nExport Code\\n\\nNow the code is ready to be exported. Click on â€˜Export codeâ€™ and you can choose to export from a few different options. You can use this to start integrating the current API configuration to your application.\\n\\nTraining\\n\\nYou can opt to train a model if you have a dataset of at least 250 labeled examples (500 or more for best results) with at least 5 examples per label.\\n\\nA trained model can potentially lead to a better classification performance than a baseline model. See here  to get an overview of what model training is about.\\n\\nTo train a model for your classification task, navigate to the models page and click on Create a custom model.\\n\\nThe subsequent steps are the same as how you would train a representation model. For this, follow the steps described here.\\n\\nUpdated 22 days ago\\n\\nContent Moderation with Classify\\n\\nTable of Contents\\n\\nThe Problem We Want to Solve\\n\\n\\nUsing Classify For Our Task\\n\\nExamples\\nTexts:\\n\\n\\n\\nClassifying the Input Texts\\n\\nChoose Model\\nAdd Examples\\nAdd Inputs\\nView Results\\nExport Code\\nTraining', metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/text-classification-with-classify'}),\n",
       " Document(page_content=\"Jump to Content\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nSearch\\n\\nGet Started\\n\\nThe Cohere Platform\\n\\nIntroduction to Large Language Models\\n\\nPlayground Overview\\n\\nQuickstart Tutorials\\n\\nGoing Live\\n\\nIntegrations\\n\\nLearn\\n\\nKey ConceptsEmbeddingsPrompt EngineeringTokens\\n\\nGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-p\\n\\nCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model Metrics\\n\\nMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported Languages\\n\\nRerankingReranking Best Practices\\n\\nGenerating Feedback\\n\\nIntroductory Guides\\n\\nSemantic Search\\n\\nContent Moderation\\n\\nEntity Extraction\\n\\nText ClassificationText Classification (Classify)Text Classification (Embed)\\n\\nCo.summarize (Beta)\\n\\nCo.rerank (Beta)\\n\\nResponsible Use\\n\\nOverviewUsage GuidelinesModel LimitationsData Statement\\n\\nModels\\n\\nSecurity\\n\\nEnvironmental Impact\\n\\nLLM University\\n\\nWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?\\n\\nModule 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language Models\\n\\nModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text Representation\\n\\nModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere's Command ModelConclusion - Text Generation\\n\\nAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLP\\n\\nAppendix 2: Building AppsApp Examples\\n\\nText Classification (Embed)\\n\\nSuggest Edits\\n\\nðŸ“˜\\n\\nThis Guide Uses the Embed Endpoint.\\n\\nYou can find more information about the endpoint here.\\n\\nThis notebook shows how to build a classifiers using Cohere's embeddings. You can find the code in the notebook and colab.\\n\\nFirst we embed the text in the dataset, then we use that to train a classifier.\\n\\nThe example classification task here will be sentiment analysis of film reviews. We'll train a simple classifier to detect whether a film review is negative (class 0) or positive (class 1).\\n\\nWe'll go through the following steps:\\n\\nInstall Cohere\\n\\nGet the dataset\\n\\nGet the embeddings of the reviews (for both the training set and the test set).\\n\\nTrain a classifier using the training set\\n\\nEvaluate the performance of the classifier on the testing set\\n\\n1. Install Cohere and Other Dependencies\\n\\n2. Get the Dataset\\n\\n2a. Print an Example from the Dataset\\n\\nWe'll only use a subset of the training and testing datasets in this example. We'll only use 500 examples since this is a toy example. You'll want to increase the number to get better performance and evaluation.\\n\\nThe train_test_split method split arrays or matrices into random train and test subsets.\\n\\n2a. Set up the Cohere client to embed your reviews\\n\\n2b. Use Co.embed() to embed your test and training set\\n\\nWe are calling the co.embed() method to convert our text examples into numerical representations.\\n\\nWe now have two sets of embeddings, embeddings_train contains the embeddings of the training sentences while embeddings_test contains the embeddings of the testing sentences.\\n\\nCurious what an embedding looks like? we can print it:\\n\\nThe results look something like this\\n\\n3. Train a Classifier Using the Training Set\\n\\nNow that we have the embedding we can train our classifier. We'll use an SVM from sklearn. We call the make_pipeline which configures a pipeline. The purpose of the pipeline is to assemble several steps that can be cross-validated together while setting different parameters.\\n\\n4. Evaluate the Performance of the Classifier on The Testing Set\\n\\nValidation accuracy on Large is 88.8%!\\n\\nThis was a small scale example, meant as a proof of concept and designed to illustrate how you can build a custom classifier quickly using a small amount of labelled data and Cohere's embeddings. Increase the number of training examples to achieve better performance on this task.\\n\\nUpdated 22 days ago\\n\\nTable of Contents\\n\\n1. Install Cohere and Other Dependencies\\n\\n\\n2. Get the Dataset\\n\\n2a. Print an Example from the Dataset\\n\\n\\n\\n2a. Set up the Cohere client to embed your reviews\\n\\n\\n2b. Use Co.embed() to embed your test and training set\\n\\n\\n3. Train a Classifier Using the Training Set\\n\\n\\n4. Evaluate the Performance of the Classifier on The Testing Set\", metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/text-classification-with-embed'}),\n",
       " Document(page_content=\"Jump to Content\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nDashboard\\n\\nDocumentation\\n\\nPlayground\\n\\nCommunity\\n\\nLog In\\n\\nGuides and Concepts\\n\\nAPI Reference\\n\\nRelease Notes\\n\\nLLMU\\n\\nSearch\\n\\nGet Started\\n\\nThe Cohere Platform\\n\\nIntroduction to Large Language Models\\n\\nPlayground Overview\\n\\nQuickstart Tutorials\\n\\nGoing Live\\n\\nIntegrations\\n\\nLearn\\n\\nKey ConceptsEmbeddingsPrompt EngineeringTokens\\n\\nGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-p\\n\\nCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model Metrics\\n\\nMultilingual Embedding ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported Languages\\n\\nRerankingReranking Best Practices\\n\\nGenerating Feedback\\n\\nIntroductory Guides\\n\\nSemantic Search\\n\\nContent Moderation\\n\\nEntity Extraction\\n\\nText ClassificationText Classification (Classify)Text Classification (Embed)\\n\\nCo.summarize (Beta)\\n\\nCo.rerank (Beta)\\n\\nResponsible Use\\n\\nOverviewUsage GuidelinesModel LimitationsData Statement\\n\\nModels\\n\\nSecurity\\n\\nEnvironmental Impact\\n\\nLLM University\\n\\nWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?\\n\\nModule 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language Models\\n\\nModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text Representation\\n\\nModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere's Command ModelConclusion - Text Generation\\n\\nAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLP\\n\\nAppendix 2: Building AppsApp Examples\\n\\nCo.summarize (Beta)\\n\\nSuggest Edits\\n\\nThis endpoint generates a succinct version of the original text that relays the most important information.\\n\\nIdeal use cases include, but are not limited to: news articles, blogs, chat transcripts, scientific articles, meeting notes, and any text that you should like to see a summary of!\\n\\nThe endpoint can:\\n\\nSummarize a single document\\n\\nControl output length\\n\\nðŸš§\\n\\nExperimental Features\\n\\nThese features are extremely experimental. Using these feature could lead to a substantial decrease in performance over the overall model. It is included as a feature based on user feedback â€” and our team is actively working on delivering a better solution. Because it is critical for some applications, we have exposed an experimental version. If you do try it out, we welcome your feedback.\\n\\nAbility to format chosen output\\n\\nLong document summaries\\n\\nAbility to provide additional instructions to focus the summary\\n\\nWe recommend to leverage the playground for quick use cases, but for any repeated utilizations we strongly recommend the API. An example is provided below.\\n\\nIn this example, we want to summarize a passage from a news article into its main point.\\n\\n1. Set up\\n\\nInstall the SDK, if you haven't already.\\n\\nNext, set up the Cohere client.\\n\\n2. Create prompt\\n\\nStore the document you want to summarize into a variable\\n\\n3. Define model settings\\n\\nThe endpoint has a number of settings you can use to control the kind of output it generates. The full list is available in the API reference, but letâ€™s look at a few:\\n\\nmodel - summarize-xlarge or summarize-medium. Generally, medium models are faster while larger models will perform better.\\n\\ntemperature - Ranges from 1 to 5. Controls the randomness of the output. Higher values tend to generate more creative outcomes, and gives you the opportunity of generating various summaries for the same input text. It also might include more hallucinations. Use a higher value if for example you plan to perform a selection of various summaries afterwards\\n\\nlength - You can choose between short, medium and long. Short summaries are roughly up to 2 sentences long, medium between 3 and 5 and long might have more 6 or more sentences.\\n\\nformat - You can choose between paragraph and bullets. Paragraph generates a coherent sequence of sentences, while bullets outputs the summary in bullet points\\n\\nextractiveness -low, medium, high\\n\\n4. Generate the summary\\n\\nCall the endpoint via the co.summarize() method, specifying the prompt and the rest of the model settings.\\n\\n5. Limitations\\n\\nAs any work building on top of statistical large language models, there is the risk that the output contains facts not present in the original document. Those hallucinations might be innocuous, in the sense that they enrich the summary with additional facts, but can also contain inaccuracies.\\n\\nUpdated 16 days ago\\n\\nTable of Contents\\n\\n1. Set up\\n2. Create prompt\\n3. Define model settings\\n4. Generate the summary\\n5. Limitations\", metadata={'source': 'https://docs.cohere.com/cohere-ai/docs/summarize'})]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import UnstructuredURLLoader\n",
    "\n",
    "loader_2 = UnstructuredURLLoader(urls=urls)\n",
    "data = loader_2.load()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import CohereEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(data)\n",
    "embeddings = CohereEmbeddings(model_name=\"your_model_name\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "\n",
    "# initialize pinecone\n",
    "pinecone.init(\n",
    "    api_key=PINECONE_API_KEY,  # find at app.pinecone.io\n",
    "    environment=PINECONE_ENV,  # next to api key in console\n",
    ")\n",
    "\n",
    "index_name = \"langchain-demo\"\n",
    "\n",
    "docsearch = Pinecone.from_documents(docs, embeddings, index_name=index_name)\n",
    "\n",
    "# if you already have an index, you can load it like this\n",
    "# docsearch = Pinecone.from_existing_index(index_name, embeddings)\n",
    "\n",
    "query = \"What did the president say about Ketanji Brown Jackson\"\n",
    "docs = docsearch.similarity_search(query)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
